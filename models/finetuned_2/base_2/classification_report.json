{
    "Aeroplane": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 22
    },
    "Anthus trivialis_Tree Pipit": {
        "precision": 0.7727272727272727,
        "recall": 0.6375,
        "f1-score": 0.6986301369863013,
        "support": 160
    },
    "Certhia familiaris_Eurasian Treecreeper": {
        "precision": 0.43333333333333335,
        "recall": 0.14130434782608695,
        "f1-score": 0.21311475409836064,
        "support": 92
    },
    "Coccothraustes coccothraustes_Hawfinch": {
        "precision": 0.6,
        "recall": 0.034482758620689655,
        "f1-score": 0.06521739130434784,
        "support": 87
    },
    "Cuculus canorus_Common Cuckoo": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 3
    },
    "Erithacus rubecula_European Robin": {
        "precision": 0.4947916666666667,
        "recall": 0.6834532374100719,
        "f1-score": 0.5740181268882175,
        "support": 556
    },
    "Fringilla coelebs_Common Chaffinch": {
        "precision": 0.5510534846029174,
        "recall": 0.7445255474452555,
        "f1-score": 0.6333436820863086,
        "support": 1370
    },
    "Lophophanes cristatus_Crested Tit": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 23
    },
    "Loxia curvirostra_Common Crossbill": {
        "precision": 0.75,
        "recall": 0.08333333333333333,
        "f1-score": 0.15,
        "support": 36
    },
    "Muscicapa striata_Spotted Flycatcher": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 173
    },
    "None": {
        "precision": 0.7373458792991564,
        "recall": 0.9705317104420244,
        "f1-score": 0.8380197289573155,
        "support": 4683
    },
    "Parus major_Great Tit": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 14
    },
    "Periparus ater_Coal Tit": {
        "precision": 0.8461538461538461,
        "recall": 0.25943396226415094,
        "f1-score": 0.3971119133574007,
        "support": 212
    },
    "Phylloscopus collybita_Common Chiffchaff": {
        "precision": 0.9144144144144144,
        "recall": 0.30118694362017806,
        "f1-score": 0.453125,
        "support": 674
    },
    "Regulus ignicapilla_Common Firecrest": {
        "precision": 0.8212765957446808,
        "recall": 0.3356521739130435,
        "f1-score": 0.4765432098765432,
        "support": 575
    },
    "Regulus regulus_Goldcrest": {
        "precision": 0.2916666666666667,
        "recall": 0.051470588235294115,
        "f1-score": 0.08750000000000001,
        "support": 136
    },
    "Sylvia atricapilla_Eurasian Blackcap": {
        "precision": 0.2815338042381433,
        "recall": 0.565922920892495,
        "f1-score": 0.3760107816711591,
        "support": 493
    },
    "Troglodytes troglodytes_Eurasian Wren": {
        "precision": 1.0,
        "recall": 0.0625,
        "f1-score": 0.11764705882352941,
        "support": 208
    },
    "Turdus merula_Eurasian Blackbird": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 315
    },
    "Vegetation": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 45
    },
    "Wind": {
        "precision": 0.016129032258064516,
        "recall": 0.015463917525773196,
        "f1-score": 0.015789473684210527,
        "support": 194
    },
    "micro avg": {
        "precision": 0.6318569310600445,
        "recall": 0.6770926422400954,
        "f1-score": 0.6536931409672626,
        "support": 10071
    },
    "macro avg": {
        "precision": 0.4052583807669125,
        "recall": 0.23270292578706647,
        "f1-score": 0.24267005989208063,
        "support": 10071
    },
    "weighted avg": {
        "precision": 0.6338265377123324,
        "recall": 0.6770926422400954,
        "f1-score": 0.6098854124573756,
        "support": 10071
    },
    "samples avg": {
        "precision": 0.6723491179201485,
        "recall": 0.7014020427112349,
        "f1-score": 0.6742995092187293,
        "support": 10071
    }
}