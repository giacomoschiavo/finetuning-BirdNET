{
    "Aeroplane": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 22
    },
    "Anthus trivialis_Tree Pipit": {
        "precision": 0.7404580152671756,
        "recall": 0.60625,
        "f1-score": 0.6666666666666666,
        "support": 160
    },
    "Certhia familiaris_Eurasian Treecreeper": {
        "precision": 0.3333333333333333,
        "recall": 0.08695652173913043,
        "f1-score": 0.13793103448275862,
        "support": 92
    },
    "Coccothraustes coccothraustes_Hawfinch": {
        "precision": 0.8,
        "recall": 0.04597701149425287,
        "f1-score": 0.08695652173913043,
        "support": 87
    },
    "Erithacus rubecula_European Robin": {
        "precision": 0.4217479674796748,
        "recall": 0.7464028776978417,
        "f1-score": 0.5389610389610389,
        "support": 556
    },
    "Fringilla coelebs_Common Chaffinch": {
        "precision": 0.5414610069101679,
        "recall": 0.8007299270072993,
        "f1-score": 0.6460541813898705,
        "support": 1370
    },
    "Lophophanes cristatus_Crested Tit": {
        "precision": 0.03571428571428571,
        "recall": 0.043478260869565216,
        "f1-score": 0.0392156862745098,
        "support": 23
    },
    "Loxia curvirostra_Common Crossbill": {
        "precision": 0.6363636363636364,
        "recall": 0.19444444444444445,
        "f1-score": 0.29787234042553196,
        "support": 36
    },
    "Muscicapa striata_Spotted Flycatcher": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 173
    },
    "None": {
        "precision": 0.8025594149908593,
        "recall": 0.9374332692718343,
        "f1-score": 0.8647690337831183,
        "support": 4683
    },
    "Parus major_Great Tit": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 14
    },
    "Periparus ater_Coal Tit": {
        "precision": 0.8018867924528302,
        "recall": 0.4009433962264151,
        "f1-score": 0.5345911949685535,
        "support": 212
    },
    "Phylloscopus collybita_Common Chiffchaff": {
        "precision": 0.42805755395683454,
        "recall": 0.7062314540059347,
        "f1-score": 0.5330347144456886,
        "support": 674
    },
    "Regulus ignicapilla_Common Firecrest": {
        "precision": 0.8248587570621468,
        "recall": 0.2539130434782609,
        "f1-score": 0.38829787234042556,
        "support": 575
    },
    "Regulus regulus_Goldcrest": {
        "precision": 0.3170731707317073,
        "recall": 0.09558823529411764,
        "f1-score": 0.14689265536723164,
        "support": 136
    },
    "Sylvia atricapilla_Eurasian Blackcap": {
        "precision": 0.22623178348369188,
        "recall": 0.6612576064908722,
        "f1-score": 0.33712512926577043,
        "support": 493
    },
    "Troglodytes troglodytes_Eurasian Wren": {
        "precision": 1.0,
        "recall": 0.10576923076923077,
        "f1-score": 0.19130434782608693,
        "support": 208
    },
    "Turdus merula_Eurasian Blackbird": {
        "precision": 0.1,
        "recall": 0.006349206349206349,
        "f1-score": 0.011940298507462685,
        "support": 315
    },
    "Vegetation": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 45
    },
    "Wind": {
        "precision": 0.06280193236714976,
        "recall": 0.06701030927835051,
        "f1-score": 0.06483790523690774,
        "support": 194
    },
    "micro avg": {
        "precision": 0.5978617728765048,
        "recall": 0.7054032578466428,
        "f1-score": 0.6471955164714994,
        "support": 10068
    },
    "macro avg": {
        "precision": 0.4036273825056746,
        "recall": 0.28793673972083783,
        "f1-score": 0.27432253108403754,
        "support": 10068
    },
    "weighted avg": {
        "precision": 0.6273631337317837,
        "recall": 0.7054032578466428,
        "f1-score": 0.6268571717282377,
        "support": 10068
    },
    "samples avg": {
        "precision": 0.668848653667595,
        "recall": 0.7239554317548746,
        "f1-score": 0.6796885528584694,
        "support": 10068
    }
}