{
    "Aeroplane": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 22
    },
    "Muscicapa striata_Spotted Flycatcher": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 173
    },
    "Periparus ater_Coal Tit": {
        "precision": 0.616822429906542,
        "recall": 0.30414746543778803,
        "f1-score": 0.40740740740740744,
        "support": 217
    },
    "Cuculus canorus_Common Cuckoo": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 3
    },
    "Regulus regulus_Goldcrest": {
        "precision": 0.7391304347826086,
        "recall": 0.25,
        "f1-score": 0.37362637362637363,
        "support": 136
    },
    "Anthus trivialis_Tree Pipit": {
        "precision": 0.8869047619047619,
        "recall": 0.7801047120418848,
        "f1-score": 0.83008356545961,
        "support": 191
    },
    "Vegetation": {
        "precision": 0.3103448275862069,
        "recall": 0.16666666666666666,
        "f1-score": 0.21686746987951805,
        "support": 54
    },
    "Troglodytes troglodytes_Eurasian Wren": {
        "precision": 0.36693548387096775,
        "recall": 0.4312796208530806,
        "f1-score": 0.39651416122004357,
        "support": 211
    },
    "Erithacus rubecula_European Robin": {
        "precision": 0.6658415841584159,
        "recall": 0.3898550724637681,
        "f1-score": 0.4917733089579525,
        "support": 690
    },
    "None": {
        "precision": 0.8508771929824561,
        "recall": 0.683536194746957,
        "f1-score": 0.7580817051509768,
        "support": 4683
    },
    "Parus major_Great Tit": {
        "precision": 0.75,
        "recall": 0.5333333333333333,
        "f1-score": 0.6233766233766235,
        "support": 45
    },
    "Certhia familiaris_Eurasian Treecreeper": {
        "precision": 0.5871559633027523,
        "recall": 0.5818181818181818,
        "f1-score": 0.5844748858447488,
        "support": 110
    },
    "Phylloscopus collybita_Common Chiffchaff": {
        "precision": 0.5851063829787234,
        "recall": 0.40145985401459855,
        "f1-score": 0.4761904761904762,
        "support": 685
    },
    "Coccothraustes coccothraustes_Hawfinch": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 87
    },
    "Wind": {
        "precision": 0.09001636661211129,
        "recall": 0.28350515463917525,
        "f1-score": 0.13664596273291924,
        "support": 194
    },
    "Turdus merula_Eurasian Blackbird": {
        "precision": 0.6896551724137931,
        "recall": 0.11661807580174927,
        "f1-score": 0.19950124688279303,
        "support": 343
    },
    "Loxia curvirostra_Common Crossbill": {
        "precision": 0.8,
        "recall": 0.2222222222222222,
        "f1-score": 0.3478260869565218,
        "support": 36
    },
    "Regulus ignicapilla_Common Firecrest": {
        "precision": 0.7504424778761062,
        "recall": 0.7373913043478261,
        "f1-score": 0.743859649122807,
        "support": 575
    },
    "Sylvia atricapilla_Eurasian Blackcap": {
        "precision": 0.25022341376228774,
        "recall": 0.56,
        "f1-score": 0.34589252625077205,
        "support": 500
    },
    "Lophophanes cristatus_Crested Tit": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 23
    },
    "Fringilla coelebs_Common Chaffinch": {
        "precision": 0.5897079276773296,
        "recall": 0.8117421825143587,
        "f1-score": 0.6831364124597207,
        "support": 1567
    },
    "micro avg": {
        "precision": 0.6289301858362631,
        "recall": 0.5937411095305832,
        "f1-score": 0.6108292682926829,
        "support": 10545
    },
    "macro avg": {
        "precision": 0.45376973427690775,
        "recall": 0.3454133352810281,
        "f1-score": 0.36263132673901255,
        "support": 10545
    },
    "weighted avg": {
        "precision": 0.6832318628194625,
        "recall": 0.5937411095305832,
        "f1-score": 0.6144805177789914,
        "support": 10545
    },
    "samples avg": {
        "precision": 0.5748319405756732,
        "recall": 0.5924048282265553,
        "f1-score": 0.5743292213821463,
        "support": 10545
    }
}