{
    "Aeroplane": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 22
    },
    "Muscicapa striata_Spotted Flycatcher": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 173
    },
    "Periparus ater_Coal Tit": {
        "precision": 0.7227722772277227,
        "recall": 0.33640552995391704,
        "f1-score": 0.45911949685534587,
        "support": 217
    },
    "Regulus regulus_Goldcrest": {
        "precision": 0.24338624338624337,
        "recall": 0.3382352941176471,
        "f1-score": 0.28307692307692306,
        "support": 136
    },
    "Anthus trivialis_Tree Pipit": {
        "precision": 0.9526627218934911,
        "recall": 0.8429319371727748,
        "f1-score": 0.8944444444444444,
        "support": 191
    },
    "Vegetation": {
        "precision": 0.11538461538461539,
        "recall": 0.16666666666666666,
        "f1-score": 0.13636363636363638,
        "support": 54
    },
    "Troglodytes troglodytes_Eurasian Wren": {
        "precision": 0.34615384615384615,
        "recall": 0.2132701421800948,
        "f1-score": 0.26392961876832843,
        "support": 211
    },
    "Erithacus rubecula_European Robin": {
        "precision": 0.6402640264026402,
        "recall": 0.2811594202898551,
        "f1-score": 0.3907351460221551,
        "support": 690
    },
    "None": {
        "precision": 0.8031496062992126,
        "recall": 0.32671364509929535,
        "f1-score": 0.4644808743169399,
        "support": 4683
    },
    "Parus major_Great Tit": {
        "precision": 0.5681818181818182,
        "recall": 0.5555555555555556,
        "f1-score": 0.5617977528089888,
        "support": 45
    },
    "Certhia familiaris_Eurasian Treecreeper": {
        "precision": 0.5042735042735043,
        "recall": 0.5363636363636364,
        "f1-score": 0.5198237885462555,
        "support": 110
    },
    "Phylloscopus collybita_Common Chiffchaff": {
        "precision": 0.6654804270462633,
        "recall": 0.272992700729927,
        "f1-score": 0.3871635610766045,
        "support": 685
    },
    "Coccothraustes coccothraustes_Hawfinch": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 87
    },
    "Wind": {
        "precision": 0.08974358974358974,
        "recall": 0.6494845360824743,
        "f1-score": 0.15769712140175218,
        "support": 194
    },
    "Turdus merula_Eurasian Blackbird": {
        "precision": 0.6842105263157895,
        "recall": 0.11370262390670553,
        "f1-score": 0.19499999999999998,
        "support": 343
    },
    "Loxia curvirostra_Common Crossbill": {
        "precision": 0.9166666666666666,
        "recall": 0.3055555555555556,
        "f1-score": 0.4583333333333333,
        "support": 36
    },
    "Regulus ignicapilla_Common Firecrest": {
        "precision": 0.7784810126582279,
        "recall": 0.42782608695652175,
        "f1-score": 0.5521885521885522,
        "support": 575
    },
    "Sylvia atricapilla_Eurasian Blackcap": {
        "precision": 0.2278738555442523,
        "recall": 0.448,
        "f1-score": 0.3020903573836818,
        "support": 500
    },
    "Lophophanes cristatus_Crested Tit": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 23
    },
    "Fringilla coelebs_Common Chaffinch": {
        "precision": 0.48,
        "recall": 0.4151967435549525,
        "f1-score": 0.44525281920698434,
        "support": 1474
    },
    "micro avg": {
        "precision": 0.4844678552133982,
        "recall": 0.34328643889367405,
        "f1-score": 0.4018372262364869,
        "support": 10449
    },
    "macro avg": {
        "precision": 0.4369342368588942,
        "recall": 0.311503003709279,
        "f1-score": 0.32357487128969625,
        "support": 10449
    },
    "weighted avg": {
        "precision": 0.6455327825848411,
        "recall": 0.34328643889367405,
        "f1-score": 0.42140810609316587,
        "support": 10449
    },
    "samples avg": {
        "precision": 0.3248467966573816,
        "recall": 0.32878365831012074,
        "f1-score": 0.3193850643321396,
        "support": 10449
    }
}