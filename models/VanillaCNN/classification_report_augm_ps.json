{
    "Aeroplane": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 22
    },
    "Muscicapa striata_Spotted Flycatcher": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 173
    },
    "Periparus ater_Coal Tit": {
        "precision": 0.5925925925925926,
        "recall": 0.14746543778801843,
        "f1-score": 0.2361623616236162,
        "support": 217
    },
    "Regulus regulus_Goldcrest": {
        "precision": 0.16279069767441862,
        "recall": 0.3602941176470588,
        "f1-score": 0.2242562929061785,
        "support": 136
    },
    "Anthus trivialis_Tree Pipit": {
        "precision": 0.9738562091503268,
        "recall": 0.7801047120418848,
        "f1-score": 0.8662790697674418,
        "support": 191
    },
    "Vegetation": {
        "precision": 0.391304347826087,
        "recall": 0.16666666666666666,
        "f1-score": 0.23376623376623373,
        "support": 54
    },
    "Troglodytes troglodytes_Eurasian Wren": {
        "precision": 0.5280898876404494,
        "recall": 0.22274881516587677,
        "f1-score": 0.31333333333333335,
        "support": 211
    },
    "Erithacus rubecula_European Robin": {
        "precision": 0.7677419354838709,
        "recall": 0.17246376811594202,
        "f1-score": 0.28165680473372784,
        "support": 690
    },
    "None": {
        "precision": 0.7167381974248928,
        "recall": 0.8558616271620756,
        "f1-score": 0.7801459854014599,
        "support": 4683
    },
    "Parus major_Great Tit": {
        "precision": 0.7307692307692307,
        "recall": 0.4222222222222222,
        "f1-score": 0.5352112676056338,
        "support": 45
    },
    "Certhia familiaris_Eurasian Treecreeper": {
        "precision": 0.5754716981132075,
        "recall": 0.5545454545454546,
        "f1-score": 0.5648148148148148,
        "support": 110
    },
    "Phylloscopus collybita_Common Chiffchaff": {
        "precision": 0.7428571428571429,
        "recall": 0.22773722627737225,
        "f1-score": 0.34860335195530723,
        "support": 685
    },
    "Coccothraustes coccothraustes_Hawfinch": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 87
    },
    "Wind": {
        "precision": 0.10359408033826638,
        "recall": 0.25257731958762886,
        "f1-score": 0.14692653673163417,
        "support": 194
    },
    "Turdus merula_Eurasian Blackbird": {
        "precision": 0.717948717948718,
        "recall": 0.08163265306122448,
        "f1-score": 0.14659685863874344,
        "support": 343
    },
    "Loxia curvirostra_Common Crossbill": {
        "precision": 0.21839080459770116,
        "recall": 0.5277777777777778,
        "f1-score": 0.3089430894308943,
        "support": 36
    },
    "Regulus ignicapilla_Common Firecrest": {
        "precision": 0.8153846153846154,
        "recall": 0.4608695652173913,
        "f1-score": 0.5888888888888889,
        "support": 575
    },
    "Sylvia atricapilla_Eurasian Blackcap": {
        "precision": 0.29338103756708406,
        "recall": 0.328,
        "f1-score": 0.3097261567516525,
        "support": 500
    },
    "Lophophanes cristatus_Crested Tit": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 23
    },
    "Fringilla coelebs_Common Chaffinch": {
        "precision": 0.5356921166977033,
        "recall": 0.5507338864071474,
        "f1-score": 0.5431088735053493,
        "support": 1567
    },
    "micro avg": {
        "precision": 0.6119614799797263,
        "recall": 0.5726617340163157,
        "f1-score": 0.5916597246043024,
        "support": 10542
    },
    "macro avg": {
        "precision": 0.4433301656033154,
        "recall": 0.3055850624841871,
        "f1-score": 0.3214209959927455,
        "support": 10542
    },
    "weighted avg": {
        "precision": 0.6345805894384531,
        "recall": 0.5726617340163157,
        "f1-score": 0.5628107184956167,
        "support": 10542
    },
    "samples avg": {
        "precision": 0.5928950789229341,
        "recall": 0.5957288765088208,
        "f1-score": 0.5872943361188486,
        "support": 10542
    }
}