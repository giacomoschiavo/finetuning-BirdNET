{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Information Creation\n",
    "Create a json file to represent the files inside the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from birdlib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sudo modprobe nvidia_uvm\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"dataset\"\n",
    "MODEL_NAME = 'MoreDeeperCNN'\n",
    "DATASET_VAR = 'augm_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = f'../segments/{DATASET_NAME}'\n",
    "TRAIN_PATH = f\"{DATASET_PATH}/train\"\n",
    "VALID_PATH = f\"{DATASET_PATH}/valid\"\n",
    "TEST_PATH = f\"{DATASET_PATH}/test\"\n",
    "MODEL_PATH = f'./models/{MODEL_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_config(dataset_name, config_file_name='dataset_config.json'):\n",
    "    saving_path = f\"utils/{dataset_name}/{config_file_name}\"\n",
    "    if os.path.exists(saving_path):\n",
    "        print(\"Dataset config already created!\")\n",
    "        with open(saving_path) as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    mappings = utils.get_mappings(TRAIN_PATH)\n",
    "    samples = utils.collect_samples(TRAIN_PATH, VALID_PATH, TEST_PATH, mappings)\n",
    "\n",
    "    dataset_config = {\n",
    "        \"mappings\": mappings,\n",
    "        \"samples\": samples\n",
    "    }\n",
    "    with open(saving_path, \"w\") as f:\n",
    "        json.dump(dataset_config, f)\n",
    "    print(\"Saved new dataset config\")\n",
    "    return dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset config already created!\n"
     ]
    }
   ],
   "source": [
    "dataset_config = create_dataset_config(DATASET_NAME, f'dataset_config_{DATASET_VAR}.json')\n",
    "mappings = dataset_config[\"mappings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = utils.load_model_class(MODEL_NAME)\n",
    "model = model_class(len(mappings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectograms Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Aeroplane\n",
      "Processing: Muscicapa striata_Spotted Flycatcher\n",
      "Processing: Periparus ater_Coal Tit\n",
      "Processing: Cuculus canorus_Common Cuckoo\n",
      "Processing: Regulus regulus_Goldcrest\n",
      "Processing: Anthus trivialis_Tree Pipit\n",
      "Processing: Vegetation\n",
      "Processing: Troglodytes troglodytes_Eurasian Wren\n",
      "Processing: Erithacus rubecula_European Robin\n",
      "Processing: None\n",
      "Processing: Parus major_Great Tit\n",
      "Processing: Certhia familiaris_Eurasian Treecreeper\n",
      "Processing: Phylloscopus collybita_Common Chiffchaff\n",
      "Processing: Coccothraustes coccothraustes_Hawfinch\n",
      "Processing: Wind\n",
      "Processing: Turdus merula_Eurasian Blackbird\n",
      "Processing: Loxia curvirostra_Common Crossbill\n",
      "Processing: Regulus ignicapilla_Common Firecrest\n",
      "Processing: Sylvia atricapilla_Eurasian Blackcap\n",
      "Processing: Lophophanes cristatus_Crested Tit\n",
      "Processing: Fringilla coelebs_Common Chaffinch\n",
      "Processing: Aeroplane\n",
      "Processing: Muscicapa striata_Spotted Flycatcher\n",
      "Processing: Periparus ater_Coal Tit\n",
      "Processing: Cuculus canorus_Common Cuckoo\n",
      "Processing: Regulus regulus_Goldcrest\n",
      "Processing: Anthus trivialis_Tree Pipit\n",
      "Processing: Vegetation\n",
      "Processing: Troglodytes troglodytes_Eurasian Wren\n",
      "Processing: Erithacus rubecula_European Robin\n",
      "Processing: None\n",
      "Processing: Parus major_Great Tit\n",
      "Processing: Certhia familiaris_Eurasian Treecreeper\n",
      "Processing: Phylloscopus collybita_Common Chiffchaff\n",
      "Processing: Coccothraustes coccothraustes_Hawfinch\n",
      "Processing: Wind\n",
      "Processing: Turdus merula_Eurasian Blackbird\n",
      "Processing: Loxia curvirostra_Common Crossbill\n",
      "Processing: Regulus ignicapilla_Common Firecrest\n",
      "Processing: Sylvia atricapilla_Eurasian Blackcap\n",
      "Processing: Lophophanes cristatus_Crested Tit\n",
      "Processing: Fringilla coelebs_Common Chaffinch\n",
      "Processing: Aeroplane\n",
      "Processing: Muscicapa striata_Spotted Flycatcher\n",
      "Processing: Periparus ater_Coal Tit\n",
      "Processing: Cuculus canorus_Common Cuckoo\n",
      "Processing: Regulus regulus_Goldcrest\n",
      "Processing: Anthus trivialis_Tree Pipit\n",
      "Processing: Vegetation\n",
      "Processing: Troglodytes troglodytes_Eurasian Wren\n",
      "Processing: Erithacus rubecula_European Robin\n",
      "Processing: None\n",
      "Processing: Parus major_Great Tit\n",
      "Processing: Certhia familiaris_Eurasian Treecreeper\n",
      "Processing: Phylloscopus collybita_Common Chiffchaff\n",
      "Processing: Coccothraustes coccothraustes_Hawfinch\n",
      "Processing: Wind\n",
      "Processing: Turdus merula_Eurasian Blackbird\n",
      "Processing: Loxia curvirostra_Common Crossbill\n",
      "Processing: Regulus ignicapilla_Common Firecrest\n",
      "Processing: Sylvia atricapilla_Eurasian Blackcap\n",
      "Processing: Lophophanes cristatus_Crested Tit\n",
      "Processing: Fringilla coelebs_Common Chaffinch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'‚úÖ Spettrogrammi generati e salvati.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPECS_TRAIN_PATH = f\"{DATASET_PATH}/train_specs\"\n",
    "SPECS_VALID_PATH = f\"{DATASET_PATH}/valid_specs\"\n",
    "SPECS_TEST_PATH = f\"{DATASET_PATH}/test_specs\"\n",
    "os.makedirs(SPECS_TRAIN_PATH, exist_ok=True)\n",
    "os.makedirs(SPECS_VALID_PATH, exist_ok=True)\n",
    "os.makedirs(SPECS_TEST_PATH, exist_ok=True)\n",
    "utils.specs_generation(TRAIN_PATH, SPECS_TRAIN_PATH, dataset_config['mappings'])\n",
    "utils.specs_generation(VALID_PATH, SPECS_VALID_PATH, dataset_config['mappings'])\n",
    "utils.specs_generation(TEST_PATH, SPECS_TEST_PATH, dataset_config['mappings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset_config, model, epochs=10, batch_size=100, lr=1e-5, patience=3, early_stop_patience=5, print_freq=100, load_weights=False, checkpoint_name='checkpoint.pth'):\n",
    "    history_loss = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training {MODEL_NAME} on: {device}\")\n",
    "\n",
    "    print(\"Loading training data...\")\n",
    "    train_loader = utils.get_dataloader(dataset_config, split=\"train\", batch_size=batch_size)\n",
    "    print(\"Loaded!\")\n",
    "\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=patience, threshold=1e-4\n",
    "    )\n",
    "    history_loss = []\n",
    "    best_loss = float(\"inf\")\n",
    "    starting_epoch = 0\n",
    "\n",
    "    saving_path = f'models/{MODEL_NAME}/{checkpoint_name}'\n",
    "    if load_weights:\n",
    "        if not os.path.exists(saving_path):\n",
    "            print(\"No weights found!\")\n",
    "            return None\n",
    "        checkpoint = torch.load(saving_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        history_loss = checkpoint['history_loss']\n",
    "        best_loss = checkpoint['avg_loss']\n",
    "        starting_epoch = len(history_loss)\n",
    "        epochs += starting_epoch\n",
    "        print(f\"Model Loaded!\")\n",
    "    print(f\"Starting from epoch {starting_epoch} for {epochs} epochs\")\n",
    "        \n",
    "    early_stop_counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch += starting_epoch\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        print(f\"\\nüéØ Starting epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        for batch_index, (mel_spec, labels, _) in enumerate(train_loader):\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(mel_spec)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch = len(history_loss)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if batch_index % print_freq == 0:\n",
    "                print('Epoch: [{0}][{1}/{2}], Loss: {loss:.5f}'.format(epoch, batch_index, len(train_loader), loss=loss))\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        history_loss.append(running_loss)\n",
    "        scheduler.step(running_loss)\n",
    "\n",
    "        np.save(f'models/{MODEL_NAME}/history_loss_{DATASET_VAR}.npy', history_loss)\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            early_stop_counter = 0\n",
    "            print(f\"üíæ Saving improved model at epoch {epoch+1} with avg_loss={avg_loss:.5f}\")\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'avg_loss': avg_loss,\n",
    "                'history_loss': history_loss\n",
    "            }, saving_path)\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            print(f\"üõë No improvement ‚Äî early stop counter: {early_stop_counter}/{early_stop_patience}\")\n",
    "\n",
    "        print(f\"üîÅ Epoch {epoch+1} completed - Avg loss: {avg_loss:.7f} - LR: {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(f\"\\nüö® Early stopping triggered after {early_stop_patience} epochs without improvement.\")\n",
    "            break\n",
    "\n",
    "    print(\"‚úÖ Training completed\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MoreDeeperCNN on: cuda\n",
      "Loading training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded!\n",
      "Starting from epoch 0 for 200 epochs\n",
      "\n",
      "üéØ Starting epoch 1/200\n",
      "Epoch: [0][0/731], Loss: 0.69123\n",
      "Epoch: [0][100/731], Loss: 0.19053\n",
      "Epoch: [0][200/731], Loss: 0.20045\n",
      "Epoch: [0][300/731], Loss: 0.12900\n",
      "Epoch: [0][400/731], Loss: 0.11651\n",
      "Epoch: [0][500/731], Loss: 0.10991\n",
      "Epoch: [0][600/731], Loss: 0.09120\n",
      "Epoch: [0][700/731], Loss: 0.10012\n",
      "üíæ Saving improved model at epoch 1 with avg_loss=0.13959\n",
      "üîÅ Epoch 1 completed - Avg loss: 0.1395890 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 2/200\n",
      "Epoch: [1][0/731], Loss: 0.08235\n",
      "Epoch: [1][100/731], Loss: 0.06657\n",
      "Epoch: [1][200/731], Loss: 0.06281\n",
      "Epoch: [1][300/731], Loss: 0.09161\n",
      "Epoch: [1][400/731], Loss: 0.06981\n",
      "Epoch: [1][500/731], Loss: 0.09021\n",
      "Epoch: [1][600/731], Loss: 0.11363\n",
      "Epoch: [1][700/731], Loss: 0.06722\n",
      "üíæ Saving improved model at epoch 2 with avg_loss=0.08219\n",
      "üîÅ Epoch 2 completed - Avg loss: 0.0821947 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 3/200\n",
      "Epoch: [2][0/731], Loss: 0.07285\n",
      "Epoch: [2][100/731], Loss: 0.07210\n",
      "Epoch: [2][200/731], Loss: 0.07433\n",
      "Epoch: [2][300/731], Loss: 0.06327\n",
      "Epoch: [2][400/731], Loss: 0.09504\n",
      "Epoch: [2][500/731], Loss: 0.08693\n",
      "Epoch: [2][600/731], Loss: 0.07725\n",
      "Epoch: [2][700/731], Loss: 0.06047\n",
      "üíæ Saving improved model at epoch 3 with avg_loss=0.06816\n",
      "üîÅ Epoch 3 completed - Avg loss: 0.0681649 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 4/200\n",
      "Epoch: [3][0/731], Loss: 0.06657\n",
      "Epoch: [3][100/731], Loss: 0.06901\n",
      "Epoch: [3][200/731], Loss: 0.05336\n",
      "Epoch: [3][300/731], Loss: 0.04924\n",
      "Epoch: [3][400/731], Loss: 0.04089\n",
      "Epoch: [3][500/731], Loss: 0.04426\n",
      "Epoch: [3][600/731], Loss: 0.06893\n",
      "Epoch: [3][700/731], Loss: 0.05395\n",
      "üíæ Saving improved model at epoch 4 with avg_loss=0.05965\n",
      "üîÅ Epoch 4 completed - Avg loss: 0.0596458 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 5/200\n",
      "Epoch: [4][0/731], Loss: 0.04646\n",
      "Epoch: [4][100/731], Loss: 0.04789\n",
      "Epoch: [4][200/731], Loss: 0.06719\n",
      "Epoch: [4][300/731], Loss: 0.05128\n",
      "Epoch: [4][400/731], Loss: 0.06253\n",
      "Epoch: [4][500/731], Loss: 0.08595\n",
      "Epoch: [4][600/731], Loss: 0.05858\n",
      "Epoch: [4][700/731], Loss: 0.04121\n",
      "üíæ Saving improved model at epoch 5 with avg_loss=0.05311\n",
      "üîÅ Epoch 5 completed - Avg loss: 0.0531118 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 6/200\n",
      "Epoch: [5][0/731], Loss: 0.06396\n",
      "Epoch: [5][100/731], Loss: 0.04977\n",
      "Epoch: [5][200/731], Loss: 0.04384\n",
      "Epoch: [5][300/731], Loss: 0.04138\n",
      "Epoch: [5][400/731], Loss: 0.03992\n",
      "Epoch: [5][500/731], Loss: 0.05705\n",
      "Epoch: [5][600/731], Loss: 0.06238\n",
      "Epoch: [5][700/731], Loss: 0.04938\n",
      "üíæ Saving improved model at epoch 6 with avg_loss=0.04795\n",
      "üîÅ Epoch 6 completed - Avg loss: 0.0479501 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 7/200\n",
      "Epoch: [6][0/731], Loss: 0.04319\n",
      "Epoch: [6][100/731], Loss: 0.03333\n",
      "Epoch: [6][200/731], Loss: 0.05238\n",
      "Epoch: [6][300/731], Loss: 0.03888\n",
      "Epoch: [6][400/731], Loss: 0.04634\n",
      "Epoch: [6][500/731], Loss: 0.03651\n",
      "Epoch: [6][600/731], Loss: 0.03310\n",
      "Epoch: [6][700/731], Loss: 0.03785\n",
      "üíæ Saving improved model at epoch 7 with avg_loss=0.04329\n",
      "üîÅ Epoch 7 completed - Avg loss: 0.0432932 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 8/200\n",
      "Epoch: [7][0/731], Loss: 0.03169\n",
      "Epoch: [7][100/731], Loss: 0.02654\n",
      "Epoch: [7][200/731], Loss: 0.04367\n",
      "Epoch: [7][300/731], Loss: 0.03852\n",
      "Epoch: [7][400/731], Loss: 0.03116\n",
      "Epoch: [7][500/731], Loss: 0.03568\n",
      "Epoch: [7][600/731], Loss: 0.02834\n",
      "Epoch: [7][700/731], Loss: 0.04483\n",
      "üíæ Saving improved model at epoch 8 with avg_loss=0.03906\n",
      "üîÅ Epoch 8 completed - Avg loss: 0.0390645 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 9/200\n",
      "Epoch: [8][0/731], Loss: 0.03624\n",
      "Epoch: [8][100/731], Loss: 0.02861\n",
      "Epoch: [8][200/731], Loss: 0.02653\n",
      "Epoch: [8][300/731], Loss: 0.03096\n",
      "Epoch: [8][400/731], Loss: 0.03088\n",
      "Epoch: [8][500/731], Loss: 0.03987\n",
      "Epoch: [8][600/731], Loss: 0.03290\n",
      "Epoch: [8][700/731], Loss: 0.04005\n",
      "üíæ Saving improved model at epoch 9 with avg_loss=0.03562\n",
      "üîÅ Epoch 9 completed - Avg loss: 0.0356210 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 10/200\n",
      "Epoch: [9][0/731], Loss: 0.02858\n",
      "Epoch: [9][100/731], Loss: 0.02826\n",
      "Epoch: [9][200/731], Loss: 0.02834\n",
      "Epoch: [9][300/731], Loss: 0.03279\n",
      "Epoch: [9][400/731], Loss: 0.02474\n",
      "Epoch: [9][500/731], Loss: 0.04029\n",
      "Epoch: [9][600/731], Loss: 0.03655\n",
      "Epoch: [9][700/731], Loss: 0.03439\n",
      "üíæ Saving improved model at epoch 10 with avg_loss=0.03188\n",
      "üîÅ Epoch 10 completed - Avg loss: 0.0318783 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 11/200\n",
      "Epoch: [10][0/731], Loss: 0.02473\n",
      "Epoch: [10][100/731], Loss: 0.02777\n",
      "Epoch: [10][200/731], Loss: 0.02443\n",
      "Epoch: [10][300/731], Loss: 0.03608\n",
      "Epoch: [10][400/731], Loss: 0.03603\n",
      "Epoch: [10][500/731], Loss: 0.02017\n",
      "Epoch: [10][600/731], Loss: 0.02684\n",
      "Epoch: [10][700/731], Loss: 0.03362\n",
      "üíæ Saving improved model at epoch 11 with avg_loss=0.02852\n",
      "üîÅ Epoch 11 completed - Avg loss: 0.0285250 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 12/200\n",
      "Epoch: [11][0/731], Loss: 0.02091\n",
      "Epoch: [11][100/731], Loss: 0.01510\n",
      "Epoch: [11][200/731], Loss: 0.02470\n",
      "Epoch: [11][300/731], Loss: 0.03402\n",
      "Epoch: [11][400/731], Loss: 0.03252\n",
      "Epoch: [11][500/731], Loss: 0.02139\n",
      "Epoch: [11][600/731], Loss: 0.03033\n",
      "Epoch: [11][700/731], Loss: 0.04141\n",
      "üíæ Saving improved model at epoch 12 with avg_loss=0.02566\n",
      "üîÅ Epoch 12 completed - Avg loss: 0.0256551 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 13/200\n",
      "Epoch: [12][0/731], Loss: 0.02268\n",
      "Epoch: [12][100/731], Loss: 0.01914\n",
      "Epoch: [12][200/731], Loss: 0.02084\n",
      "Epoch: [12][300/731], Loss: 0.01676\n",
      "Epoch: [12][400/731], Loss: 0.02083\n",
      "Epoch: [12][500/731], Loss: 0.01968\n",
      "Epoch: [12][600/731], Loss: 0.02382\n",
      "Epoch: [12][700/731], Loss: 0.02114\n",
      "üíæ Saving improved model at epoch 13 with avg_loss=0.02243\n",
      "üîÅ Epoch 13 completed - Avg loss: 0.0224287 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 14/200\n",
      "Epoch: [13][0/731], Loss: 0.01864\n",
      "Epoch: [13][100/731], Loss: 0.01702\n",
      "Epoch: [13][200/731], Loss: 0.01389\n",
      "Epoch: [13][300/731], Loss: 0.01647\n",
      "Epoch: [13][400/731], Loss: 0.01127\n",
      "Epoch: [13][500/731], Loss: 0.01977\n",
      "Epoch: [13][600/731], Loss: 0.01668\n",
      "Epoch: [13][700/731], Loss: 0.01881\n",
      "üíæ Saving improved model at epoch 14 with avg_loss=0.02051\n",
      "üîÅ Epoch 14 completed - Avg loss: 0.0205129 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 15/200\n",
      "Epoch: [14][0/731], Loss: 0.01506\n",
      "Epoch: [14][100/731], Loss: 0.01347\n",
      "Epoch: [14][200/731], Loss: 0.01228\n",
      "Epoch: [14][300/731], Loss: 0.01793\n",
      "Epoch: [14][400/731], Loss: 0.01376\n",
      "Epoch: [14][500/731], Loss: 0.02462\n",
      "Epoch: [14][600/731], Loss: 0.00834\n",
      "Epoch: [14][700/731], Loss: 0.00822\n",
      "üíæ Saving improved model at epoch 15 with avg_loss=0.01788\n",
      "üîÅ Epoch 15 completed - Avg loss: 0.0178806 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 16/200\n",
      "Epoch: [15][0/731], Loss: 0.01953\n",
      "Epoch: [15][100/731], Loss: 0.01045\n",
      "Epoch: [15][200/731], Loss: 0.02866\n",
      "Epoch: [15][300/731], Loss: 0.01863\n",
      "Epoch: [15][400/731], Loss: 0.01628\n",
      "Epoch: [15][500/731], Loss: 0.01651\n",
      "Epoch: [15][600/731], Loss: 0.01249\n",
      "Epoch: [15][700/731], Loss: 0.01311\n",
      "üíæ Saving improved model at epoch 16 with avg_loss=0.01569\n",
      "üîÅ Epoch 16 completed - Avg loss: 0.0156927 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 17/200\n",
      "Epoch: [16][0/731], Loss: 0.01325\n",
      "Epoch: [16][100/731], Loss: 0.01370\n",
      "Epoch: [16][200/731], Loss: 0.01361\n",
      "Epoch: [16][300/731], Loss: 0.02269\n",
      "Epoch: [16][400/731], Loss: 0.02244\n",
      "Epoch: [16][500/731], Loss: 0.01016\n",
      "Epoch: [16][600/731], Loss: 0.02568\n",
      "Epoch: [16][700/731], Loss: 0.01645\n",
      "üíæ Saving improved model at epoch 17 with avg_loss=0.01470\n",
      "üîÅ Epoch 17 completed - Avg loss: 0.0146960 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 18/200\n",
      "Epoch: [17][0/731], Loss: 0.00874\n",
      "Epoch: [17][100/731], Loss: 0.00792\n",
      "Epoch: [17][200/731], Loss: 0.01346\n",
      "Epoch: [17][300/731], Loss: 0.01472\n",
      "Epoch: [17][400/731], Loss: 0.01292\n",
      "Epoch: [17][500/731], Loss: 0.00655\n",
      "Epoch: [17][600/731], Loss: 0.01577\n",
      "Epoch: [17][700/731], Loss: 0.00722\n",
      "üíæ Saving improved model at epoch 18 with avg_loss=0.01316\n",
      "üîÅ Epoch 18 completed - Avg loss: 0.0131573 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 19/200\n",
      "Epoch: [18][0/731], Loss: 0.00986\n",
      "Epoch: [18][100/731], Loss: 0.01185\n",
      "Epoch: [18][200/731], Loss: 0.01313\n",
      "Epoch: [18][300/731], Loss: 0.00965\n",
      "Epoch: [18][400/731], Loss: 0.00635\n",
      "Epoch: [18][500/731], Loss: 0.00811\n",
      "Epoch: [18][600/731], Loss: 0.01005\n",
      "Epoch: [18][700/731], Loss: 0.01287\n",
      "üíæ Saving improved model at epoch 19 with avg_loss=0.01213\n",
      "üîÅ Epoch 19 completed - Avg loss: 0.0121332 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 20/200\n",
      "Epoch: [19][0/731], Loss: 0.00405\n",
      "Epoch: [19][100/731], Loss: 0.01088\n",
      "Epoch: [19][200/731], Loss: 0.00576\n",
      "Epoch: [19][300/731], Loss: 0.00520\n",
      "Epoch: [19][400/731], Loss: 0.01039\n",
      "Epoch: [19][500/731], Loss: 0.00771\n",
      "Epoch: [19][600/731], Loss: 0.01210\n",
      "Epoch: [19][700/731], Loss: 0.01163\n",
      "üíæ Saving improved model at epoch 20 with avg_loss=0.01154\n",
      "üîÅ Epoch 20 completed - Avg loss: 0.0115406 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 21/200\n",
      "Epoch: [20][0/731], Loss: 0.00859\n",
      "Epoch: [20][100/731], Loss: 0.00784\n",
      "Epoch: [20][200/731], Loss: 0.01101\n",
      "Epoch: [20][300/731], Loss: 0.01755\n",
      "Epoch: [20][400/731], Loss: 0.01528\n",
      "Epoch: [20][500/731], Loss: 0.01702\n",
      "Epoch: [20][600/731], Loss: 0.00901\n",
      "Epoch: [20][700/731], Loss: 0.01305\n",
      "üíæ Saving improved model at epoch 21 with avg_loss=0.01109\n",
      "üîÅ Epoch 21 completed - Avg loss: 0.0110921 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 22/200\n",
      "Epoch: [21][0/731], Loss: 0.00841\n",
      "Epoch: [21][100/731], Loss: 0.00671\n",
      "Epoch: [21][200/731], Loss: 0.00765\n",
      "Epoch: [21][300/731], Loss: 0.01636\n",
      "Epoch: [21][400/731], Loss: 0.00777\n",
      "Epoch: [21][500/731], Loss: 0.01164\n",
      "Epoch: [21][600/731], Loss: 0.00696\n",
      "Epoch: [21][700/731], Loss: 0.01865\n",
      "üíæ Saving improved model at epoch 22 with avg_loss=0.01003\n",
      "üîÅ Epoch 22 completed - Avg loss: 0.0100315 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 23/200\n",
      "Epoch: [22][0/731], Loss: 0.00664\n",
      "Epoch: [22][100/731], Loss: 0.00495\n",
      "Epoch: [22][200/731], Loss: 0.00955\n",
      "Epoch: [22][300/731], Loss: 0.02043\n",
      "Epoch: [22][400/731], Loss: 0.00918\n",
      "Epoch: [22][500/731], Loss: 0.01343\n",
      "Epoch: [22][600/731], Loss: 0.01179\n",
      "Epoch: [22][700/731], Loss: 0.00707\n",
      "üíæ Saving improved model at epoch 23 with avg_loss=0.00957\n",
      "üîÅ Epoch 23 completed - Avg loss: 0.0095687 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 24/200\n",
      "Epoch: [23][0/731], Loss: 0.00530\n",
      "Epoch: [23][100/731], Loss: 0.00919\n",
      "Epoch: [23][200/731], Loss: 0.00839\n",
      "Epoch: [23][300/731], Loss: 0.01444\n",
      "Epoch: [23][400/731], Loss: 0.00319\n",
      "Epoch: [23][500/731], Loss: 0.00920\n",
      "Epoch: [23][600/731], Loss: 0.00586\n",
      "Epoch: [23][700/731], Loss: 0.00540\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 24 completed - Avg loss: 0.0096373 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 25/200\n",
      "Epoch: [24][0/731], Loss: 0.00588\n",
      "Epoch: [24][100/731], Loss: 0.00279\n",
      "Epoch: [24][200/731], Loss: 0.00369\n",
      "Epoch: [24][300/731], Loss: 0.01392\n",
      "Epoch: [24][400/731], Loss: 0.01196\n",
      "Epoch: [24][500/731], Loss: 0.00965\n",
      "Epoch: [24][600/731], Loss: 0.01059\n",
      "Epoch: [24][700/731], Loss: 0.01442\n",
      "üíæ Saving improved model at epoch 25 with avg_loss=0.00935\n",
      "üîÅ Epoch 25 completed - Avg loss: 0.0093488 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 26/200\n",
      "Epoch: [25][0/731], Loss: 0.00363\n",
      "Epoch: [25][100/731], Loss: 0.00624\n",
      "Epoch: [25][200/731], Loss: 0.01053\n",
      "Epoch: [25][300/731], Loss: 0.01691\n",
      "Epoch: [25][400/731], Loss: 0.01050\n",
      "Epoch: [25][500/731], Loss: 0.01154\n",
      "Epoch: [25][600/731], Loss: 0.01153\n",
      "Epoch: [25][700/731], Loss: 0.01055\n",
      "üíæ Saving improved model at epoch 26 with avg_loss=0.00831\n",
      "üîÅ Epoch 26 completed - Avg loss: 0.0083081 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 27/200\n",
      "Epoch: [26][0/731], Loss: 0.00379\n",
      "Epoch: [26][100/731], Loss: 0.00795\n",
      "Epoch: [26][200/731], Loss: 0.00337\n",
      "Epoch: [26][300/731], Loss: 0.00683\n",
      "Epoch: [26][400/731], Loss: 0.00782\n",
      "Epoch: [26][500/731], Loss: 0.00741\n",
      "Epoch: [26][600/731], Loss: 0.00785\n",
      "Epoch: [26][700/731], Loss: 0.00419\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 27 completed - Avg loss: 0.0087123 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 28/200\n",
      "Epoch: [27][0/731], Loss: 0.00106\n",
      "Epoch: [27][100/731], Loss: 0.00914\n",
      "Epoch: [27][200/731], Loss: 0.00888\n",
      "Epoch: [27][300/731], Loss: 0.00822\n",
      "Epoch: [27][400/731], Loss: 0.01733\n",
      "Epoch: [27][500/731], Loss: 0.00919\n",
      "Epoch: [27][600/731], Loss: 0.00786\n",
      "Epoch: [27][700/731], Loss: 0.00875\n",
      "üõë No improvement ‚Äî early stop counter: 2/5\n",
      "üîÅ Epoch 28 completed - Avg loss: 0.0083498 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 29/200\n",
      "Epoch: [28][0/731], Loss: 0.00596\n",
      "Epoch: [28][100/731], Loss: 0.01187\n",
      "Epoch: [28][200/731], Loss: 0.01388\n",
      "Epoch: [28][300/731], Loss: 0.00624\n",
      "Epoch: [28][400/731], Loss: 0.00828\n",
      "Epoch: [28][500/731], Loss: 0.01163\n",
      "Epoch: [28][600/731], Loss: 0.00782\n",
      "Epoch: [28][700/731], Loss: 0.01109\n",
      "üíæ Saving improved model at epoch 29 with avg_loss=0.00826\n",
      "üîÅ Epoch 29 completed - Avg loss: 0.0082632 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 30/200\n",
      "Epoch: [29][0/731], Loss: 0.00824\n",
      "Epoch: [29][100/731], Loss: 0.01315\n",
      "Epoch: [29][200/731], Loss: 0.00508\n",
      "Epoch: [29][300/731], Loss: 0.00462\n",
      "Epoch: [29][400/731], Loss: 0.00627\n",
      "Epoch: [29][500/731], Loss: 0.00397\n",
      "Epoch: [29][600/731], Loss: 0.00906\n",
      "Epoch: [29][700/731], Loss: 0.00966\n",
      "üíæ Saving improved model at epoch 30 with avg_loss=0.00813\n",
      "üîÅ Epoch 30 completed - Avg loss: 0.0081265 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 31/200\n",
      "Epoch: [30][0/731], Loss: 0.00352\n",
      "Epoch: [30][100/731], Loss: 0.00309\n",
      "Epoch: [30][200/731], Loss: 0.00123\n",
      "Epoch: [30][300/731], Loss: 0.00986\n",
      "Epoch: [30][400/731], Loss: 0.00193\n",
      "Epoch: [30][500/731], Loss: 0.01763\n",
      "Epoch: [30][600/731], Loss: 0.00555\n",
      "Epoch: [30][700/731], Loss: 0.00533\n",
      "üíæ Saving improved model at epoch 31 with avg_loss=0.00742\n",
      "üîÅ Epoch 31 completed - Avg loss: 0.0074236 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 32/200\n",
      "Epoch: [31][0/731], Loss: 0.00756\n",
      "Epoch: [31][100/731], Loss: 0.00725\n",
      "Epoch: [31][200/731], Loss: 0.00582\n",
      "Epoch: [31][300/731], Loss: 0.00691\n",
      "Epoch: [31][400/731], Loss: 0.00797\n",
      "Epoch: [31][500/731], Loss: 0.00475\n",
      "Epoch: [31][600/731], Loss: 0.01569\n",
      "Epoch: [31][700/731], Loss: 0.00846\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 32 completed - Avg loss: 0.0074760 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 33/200\n",
      "Epoch: [32][0/731], Loss: 0.00494\n",
      "Epoch: [32][100/731], Loss: 0.00619\n",
      "Epoch: [32][200/731], Loss: 0.00630\n",
      "Epoch: [32][300/731], Loss: 0.00821\n",
      "Epoch: [32][400/731], Loss: 0.00579\n",
      "Epoch: [32][500/731], Loss: 0.00376\n",
      "Epoch: [32][600/731], Loss: 0.00455\n",
      "Epoch: [32][700/731], Loss: 0.00626\n",
      "üõë No improvement ‚Äî early stop counter: 2/5\n",
      "üîÅ Epoch 33 completed - Avg loss: 0.0075723 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 34/200\n",
      "Epoch: [33][0/731], Loss: 0.00397\n",
      "Epoch: [33][100/731], Loss: 0.00616\n",
      "Epoch: [33][200/731], Loss: 0.00422\n",
      "Epoch: [33][300/731], Loss: 0.00810\n",
      "Epoch: [33][400/731], Loss: 0.00947\n",
      "Epoch: [33][500/731], Loss: 0.00831\n",
      "Epoch: [33][600/731], Loss: 0.00548\n",
      "Epoch: [33][700/731], Loss: 0.00531\n",
      "üõë No improvement ‚Äî early stop counter: 3/5\n",
      "üîÅ Epoch 34 completed - Avg loss: 0.0074252 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 35/200\n",
      "Epoch: [34][0/731], Loss: 0.00345\n",
      "Epoch: [34][100/731], Loss: 0.00738\n",
      "Epoch: [34][200/731], Loss: 0.00196\n",
      "Epoch: [34][300/731], Loss: 0.00541\n",
      "Epoch: [34][400/731], Loss: 0.00777\n",
      "Epoch: [34][500/731], Loss: 0.00820\n",
      "Epoch: [34][600/731], Loss: 0.00634\n",
      "Epoch: [34][700/731], Loss: 0.01229\n",
      "üíæ Saving improved model at epoch 35 with avg_loss=0.00726\n",
      "üîÅ Epoch 35 completed - Avg loss: 0.0072584 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 36/200\n",
      "Epoch: [35][0/731], Loss: 0.00206\n",
      "Epoch: [35][100/731], Loss: 0.00503\n",
      "Epoch: [35][200/731], Loss: 0.00326\n",
      "Epoch: [35][300/731], Loss: 0.00300\n",
      "Epoch: [35][400/731], Loss: 0.01075\n",
      "Epoch: [35][500/731], Loss: 0.00289\n",
      "Epoch: [35][600/731], Loss: 0.01406\n",
      "Epoch: [35][700/731], Loss: 0.00490\n",
      "üíæ Saving improved model at epoch 36 with avg_loss=0.00718\n",
      "üîÅ Epoch 36 completed - Avg loss: 0.0071813 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 37/200\n",
      "Epoch: [36][0/731], Loss: 0.00611\n",
      "Epoch: [36][100/731], Loss: 0.00158\n",
      "Epoch: [36][200/731], Loss: 0.00558\n",
      "Epoch: [36][300/731], Loss: 0.00726\n",
      "Epoch: [36][400/731], Loss: 0.00268\n",
      "Epoch: [36][500/731], Loss: 0.01816\n",
      "Epoch: [36][600/731], Loss: 0.00705\n",
      "Epoch: [36][700/731], Loss: 0.00561\n",
      "üíæ Saving improved model at epoch 37 with avg_loss=0.00691\n",
      "üîÅ Epoch 37 completed - Avg loss: 0.0069120 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 38/200\n",
      "Epoch: [37][0/731], Loss: 0.00378\n",
      "Epoch: [37][100/731], Loss: 0.00430\n",
      "Epoch: [37][200/731], Loss: 0.00408\n",
      "Epoch: [37][300/731], Loss: 0.00399\n",
      "Epoch: [37][400/731], Loss: 0.00934\n",
      "Epoch: [37][500/731], Loss: 0.00408\n",
      "Epoch: [37][600/731], Loss: 0.01233\n",
      "Epoch: [37][700/731], Loss: 0.00489\n",
      "üíæ Saving improved model at epoch 38 with avg_loss=0.00640\n",
      "üîÅ Epoch 38 completed - Avg loss: 0.0063953 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 39/200\n",
      "Epoch: [38][0/731], Loss: 0.00944\n",
      "Epoch: [38][100/731], Loss: 0.00752\n",
      "Epoch: [38][200/731], Loss: 0.00299\n",
      "Epoch: [38][300/731], Loss: 0.00865\n",
      "Epoch: [38][400/731], Loss: 0.01114\n",
      "Epoch: [38][500/731], Loss: 0.00315\n",
      "Epoch: [38][600/731], Loss: 0.00947\n",
      "Epoch: [38][700/731], Loss: 0.00568\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 39 completed - Avg loss: 0.0069562 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 40/200\n",
      "Epoch: [39][0/731], Loss: 0.00362\n",
      "Epoch: [39][100/731], Loss: 0.00781\n",
      "Epoch: [39][200/731], Loss: 0.00136\n",
      "Epoch: [39][300/731], Loss: 0.00214\n",
      "Epoch: [39][400/731], Loss: 0.01164\n",
      "Epoch: [39][500/731], Loss: 0.00458\n",
      "Epoch: [39][600/731], Loss: 0.00197\n",
      "Epoch: [39][700/731], Loss: 0.00348\n",
      "üõë No improvement ‚Äî early stop counter: 2/5\n",
      "üîÅ Epoch 40 completed - Avg loss: 0.0067674 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 41/200\n",
      "Epoch: [40][0/731], Loss: 0.00577\n",
      "Epoch: [40][100/731], Loss: 0.00391\n",
      "Epoch: [40][200/731], Loss: 0.00496\n",
      "Epoch: [40][300/731], Loss: 0.01237\n",
      "Epoch: [40][400/731], Loss: 0.00559\n",
      "Epoch: [40][500/731], Loss: 0.00912\n",
      "Epoch: [40][600/731], Loss: 0.00544\n",
      "Epoch: [40][700/731], Loss: 0.01206\n",
      "üõë No improvement ‚Äî early stop counter: 3/5\n",
      "üîÅ Epoch 41 completed - Avg loss: 0.0065615 - LR: 1.0e-03\n",
      "\n",
      "üéØ Starting epoch 42/200\n",
      "Epoch: [41][0/731], Loss: 0.00327\n",
      "Epoch: [41][100/731], Loss: 0.00665\n",
      "Epoch: [41][200/731], Loss: 0.00289\n",
      "Epoch: [41][300/731], Loss: 0.01407\n",
      "Epoch: [41][400/731], Loss: 0.00768\n",
      "Epoch: [41][500/731], Loss: 0.00322\n",
      "Epoch: [41][600/731], Loss: 0.00631\n",
      "Epoch: [41][700/731], Loss: 0.00172\n",
      "üõë No improvement ‚Äî early stop counter: 4/5\n",
      "üîÅ Epoch 42 completed - Avg loss: 0.0064067 - LR: 5.0e-04\n",
      "\n",
      "üéØ Starting epoch 43/200\n",
      "Epoch: [42][0/731], Loss: 0.00555\n",
      "Epoch: [42][100/731], Loss: 0.00492\n",
      "Epoch: [42][200/731], Loss: 0.00604\n",
      "Epoch: [42][300/731], Loss: 0.00495\n",
      "Epoch: [42][400/731], Loss: 0.00506\n",
      "Epoch: [42][500/731], Loss: 0.00471\n",
      "Epoch: [42][600/731], Loss: 0.00653\n",
      "Epoch: [42][700/731], Loss: 0.00130\n",
      "üíæ Saving improved model at epoch 43 with avg_loss=0.00455\n",
      "üîÅ Epoch 43 completed - Avg loss: 0.0045519 - LR: 5.0e-04\n",
      "\n",
      "üéØ Starting epoch 44/200\n",
      "Epoch: [43][0/731], Loss: 0.00267\n",
      "Epoch: [43][100/731], Loss: 0.00214\n",
      "Epoch: [43][200/731], Loss: 0.00512\n",
      "Epoch: [43][300/731], Loss: 0.00185\n",
      "Epoch: [43][400/731], Loss: 0.00287\n",
      "Epoch: [43][500/731], Loss: 0.00664\n",
      "Epoch: [43][600/731], Loss: 0.00629\n",
      "Epoch: [43][700/731], Loss: 0.00521\n",
      "üíæ Saving improved model at epoch 44 with avg_loss=0.00413\n",
      "üîÅ Epoch 44 completed - Avg loss: 0.0041331 - LR: 5.0e-04\n",
      "\n",
      "üéØ Starting epoch 45/200\n",
      "Epoch: [44][0/731], Loss: 0.00098\n",
      "Epoch: [44][100/731], Loss: 0.00748\n",
      "Epoch: [44][200/731], Loss: 0.00416\n",
      "Epoch: [44][300/731], Loss: 0.00267\n",
      "Epoch: [44][400/731], Loss: 0.00321\n",
      "Epoch: [44][500/731], Loss: 0.00352\n",
      "Epoch: [44][600/731], Loss: 0.00278\n",
      "Epoch: [44][700/731], Loss: 0.00164\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 45 completed - Avg loss: 0.0041343 - LR: 5.0e-04\n",
      "\n",
      "üéØ Starting epoch 46/200\n",
      "Epoch: [45][0/731], Loss: 0.00330\n",
      "Epoch: [45][100/731], Loss: 0.00286\n",
      "Epoch: [45][200/731], Loss: 0.00369\n",
      "Epoch: [45][300/731], Loss: 0.00310\n",
      "Epoch: [45][400/731], Loss: 0.00047\n",
      "Epoch: [45][500/731], Loss: 0.00050\n",
      "Epoch: [45][600/731], Loss: 0.00184\n",
      "Epoch: [45][700/731], Loss: 0.00257\n",
      "üõë No improvement ‚Äî early stop counter: 2/5\n",
      "üîÅ Epoch 46 completed - Avg loss: 0.0041513 - LR: 5.0e-04\n",
      "\n",
      "üéØ Starting epoch 47/200\n",
      "Epoch: [46][0/731], Loss: 0.00316\n",
      "Epoch: [46][100/731], Loss: 0.00083\n",
      "Epoch: [46][200/731], Loss: 0.00165\n",
      "Epoch: [46][300/731], Loss: 0.00385\n",
      "Epoch: [46][400/731], Loss: 0.00532\n",
      "Epoch: [46][500/731], Loss: 0.00220\n",
      "Epoch: [46][600/731], Loss: 0.00556\n",
      "Epoch: [46][700/731], Loss: 0.00352\n",
      "üõë No improvement ‚Äî early stop counter: 3/5\n",
      "üîÅ Epoch 47 completed - Avg loss: 0.0041786 - LR: 5.0e-04\n",
      "\n",
      "üéØ Starting epoch 48/200\n",
      "Epoch: [47][0/731], Loss: 0.00349\n",
      "Epoch: [47][100/731], Loss: 0.00156\n",
      "Epoch: [47][200/731], Loss: 0.00489\n",
      "Epoch: [47][300/731], Loss: 0.00459\n",
      "Epoch: [47][400/731], Loss: 0.00660\n",
      "Epoch: [47][500/731], Loss: 0.00258\n",
      "Epoch: [47][600/731], Loss: 0.00379\n",
      "Epoch: [47][700/731], Loss: 0.00091\n",
      "üõë No improvement ‚Äî early stop counter: 4/5\n",
      "üîÅ Epoch 48 completed - Avg loss: 0.0043048 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 49/200\n",
      "Epoch: [48][0/731], Loss: 0.00384\n",
      "Epoch: [48][100/731], Loss: 0.00462\n",
      "Epoch: [48][200/731], Loss: 0.00041\n",
      "Epoch: [48][300/731], Loss: 0.00360\n",
      "Epoch: [48][400/731], Loss: 0.01265\n",
      "Epoch: [48][500/731], Loss: 0.00131\n",
      "Epoch: [48][600/731], Loss: 0.00341\n",
      "Epoch: [48][700/731], Loss: 0.00743\n",
      "üíæ Saving improved model at epoch 49 with avg_loss=0.00375\n",
      "üîÅ Epoch 49 completed - Avg loss: 0.0037520 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 50/200\n",
      "Epoch: [49][0/731], Loss: 0.00257\n",
      "Epoch: [49][100/731], Loss: 0.01100\n",
      "Epoch: [49][200/731], Loss: 0.00239\n",
      "Epoch: [49][300/731], Loss: 0.00501\n",
      "Epoch: [49][400/731], Loss: 0.00407\n",
      "Epoch: [49][500/731], Loss: 0.00264\n",
      "Epoch: [49][600/731], Loss: 0.00346\n",
      "Epoch: [49][700/731], Loss: 0.00057\n",
      "üíæ Saving improved model at epoch 50 with avg_loss=0.00344\n",
      "üîÅ Epoch 50 completed - Avg loss: 0.0034406 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 51/200\n",
      "Epoch: [50][0/731], Loss: 0.00193\n",
      "Epoch: [50][100/731], Loss: 0.00489\n",
      "Epoch: [50][200/731], Loss: 0.00251\n",
      "Epoch: [50][300/731], Loss: 0.00164\n",
      "Epoch: [50][400/731], Loss: 0.00318\n",
      "Epoch: [50][500/731], Loss: 0.00738\n",
      "Epoch: [50][600/731], Loss: 0.00403\n",
      "Epoch: [50][700/731], Loss: 0.00485\n",
      "üíæ Saving improved model at epoch 51 with avg_loss=0.00344\n",
      "üîÅ Epoch 51 completed - Avg loss: 0.0034374 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 52/200\n",
      "Epoch: [51][0/731], Loss: 0.00134\n",
      "Epoch: [51][100/731], Loss: 0.00350\n",
      "Epoch: [51][200/731], Loss: 0.00575\n",
      "Epoch: [51][300/731], Loss: 0.00974\n",
      "Epoch: [51][400/731], Loss: 0.00172\n",
      "Epoch: [51][500/731], Loss: 0.00786\n",
      "Epoch: [51][600/731], Loss: 0.00340\n",
      "Epoch: [51][700/731], Loss: 0.00280\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 52 completed - Avg loss: 0.0034504 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 53/200\n",
      "Epoch: [52][0/731], Loss: 0.00482\n",
      "Epoch: [52][100/731], Loss: 0.00106\n",
      "Epoch: [52][200/731], Loss: 0.00208\n",
      "Epoch: [52][300/731], Loss: 0.00280\n",
      "Epoch: [52][400/731], Loss: 0.00122\n",
      "Epoch: [52][500/731], Loss: 0.00139\n",
      "Epoch: [52][600/731], Loss: 0.00064\n",
      "Epoch: [52][700/731], Loss: 0.00287\n",
      "üõë No improvement ‚Äî early stop counter: 2/5\n",
      "üîÅ Epoch 53 completed - Avg loss: 0.0034588 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 54/200\n",
      "Epoch: [53][0/731], Loss: 0.00115\n",
      "Epoch: [53][100/731], Loss: 0.00086\n",
      "Epoch: [53][200/731], Loss: 0.00409\n",
      "Epoch: [53][300/731], Loss: 0.00224\n",
      "Epoch: [53][400/731], Loss: 0.00404\n",
      "Epoch: [53][500/731], Loss: 0.00579\n",
      "Epoch: [53][600/731], Loss: 0.00672\n",
      "Epoch: [53][700/731], Loss: 0.00092\n",
      "üõë No improvement ‚Äî early stop counter: 3/5\n",
      "üîÅ Epoch 54 completed - Avg loss: 0.0034568 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 55/200\n",
      "Epoch: [54][0/731], Loss: 0.00218\n",
      "Epoch: [54][100/731], Loss: 0.00258\n",
      "Epoch: [54][200/731], Loss: 0.00705\n",
      "Epoch: [54][300/731], Loss: 0.00007\n",
      "Epoch: [54][400/731], Loss: 0.00288\n",
      "Epoch: [54][500/731], Loss: 0.00119\n",
      "Epoch: [54][600/731], Loss: 0.00143\n",
      "Epoch: [54][700/731], Loss: 0.00286\n",
      "üíæ Saving improved model at epoch 55 with avg_loss=0.00343\n",
      "üîÅ Epoch 55 completed - Avg loss: 0.0034340 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 56/200\n",
      "Epoch: [55][0/731], Loss: 0.00362\n",
      "Epoch: [55][100/731], Loss: 0.00086\n",
      "Epoch: [55][200/731], Loss: 0.00761\n",
      "Epoch: [55][300/731], Loss: 0.00108\n",
      "Epoch: [55][400/731], Loss: 0.00366\n",
      "Epoch: [55][500/731], Loss: 0.00512\n",
      "Epoch: [55][600/731], Loss: 0.00112\n",
      "Epoch: [55][700/731], Loss: 0.00404\n",
      "üíæ Saving improved model at epoch 56 with avg_loss=0.00342\n",
      "üîÅ Epoch 56 completed - Avg loss: 0.0034213 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 57/200\n",
      "Epoch: [56][0/731], Loss: 0.00182\n",
      "Epoch: [56][100/731], Loss: 0.00644\n",
      "Epoch: [56][200/731], Loss: 0.00018\n",
      "Epoch: [56][300/731], Loss: 0.00361\n",
      "Epoch: [56][400/731], Loss: 0.00078\n",
      "Epoch: [56][500/731], Loss: 0.00237\n",
      "Epoch: [56][600/731], Loss: 0.00236\n",
      "Epoch: [56][700/731], Loss: 0.00044\n",
      "üíæ Saving improved model at epoch 57 with avg_loss=0.00340\n",
      "üîÅ Epoch 57 completed - Avg loss: 0.0034004 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 58/200\n",
      "Epoch: [57][0/731], Loss: 0.00431\n",
      "Epoch: [57][100/731], Loss: 0.00213\n",
      "Epoch: [57][200/731], Loss: 0.00253\n",
      "Epoch: [57][300/731], Loss: 0.00218\n",
      "Epoch: [57][400/731], Loss: 0.00616\n",
      "Epoch: [57][500/731], Loss: 0.00029\n",
      "Epoch: [57][600/731], Loss: 0.00945\n",
      "Epoch: [57][700/731], Loss: 0.00227\n",
      "üíæ Saving improved model at epoch 58 with avg_loss=0.00338\n",
      "üîÅ Epoch 58 completed - Avg loss: 0.0033803 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 59/200\n",
      "Epoch: [58][0/731], Loss: 0.00595\n",
      "Epoch: [58][100/731], Loss: 0.00421\n",
      "Epoch: [58][200/731], Loss: 0.00196\n",
      "Epoch: [58][300/731], Loss: 0.00062\n",
      "Epoch: [58][400/731], Loss: 0.00245\n",
      "Epoch: [58][500/731], Loss: 0.00994\n",
      "Epoch: [58][600/731], Loss: 0.00086\n",
      "Epoch: [58][700/731], Loss: 0.00314\n",
      "üíæ Saving improved model at epoch 59 with avg_loss=0.00337\n",
      "üîÅ Epoch 59 completed - Avg loss: 0.0033681 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 60/200\n",
      "Epoch: [59][0/731], Loss: 0.00186\n",
      "Epoch: [59][100/731], Loss: 0.00375\n",
      "Epoch: [59][200/731], Loss: 0.00299\n",
      "Epoch: [59][300/731], Loss: 0.00173\n",
      "Epoch: [59][400/731], Loss: 0.00503\n",
      "Epoch: [59][500/731], Loss: 0.00777\n",
      "Epoch: [59][600/731], Loss: 0.00682\n",
      "Epoch: [59][700/731], Loss: 0.00190\n",
      "üíæ Saving improved model at epoch 60 with avg_loss=0.00336\n",
      "üîÅ Epoch 60 completed - Avg loss: 0.0033571 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 61/200\n",
      "Epoch: [60][0/731], Loss: 0.00325\n",
      "Epoch: [60][100/731], Loss: 0.00304\n",
      "Epoch: [60][200/731], Loss: 0.00268\n",
      "Epoch: [60][300/731], Loss: 0.00409\n",
      "Epoch: [60][400/731], Loss: 0.00232\n",
      "Epoch: [60][500/731], Loss: 0.00681\n",
      "Epoch: [60][600/731], Loss: 0.00283\n",
      "Epoch: [60][700/731], Loss: 0.00756\n",
      "üíæ Saving improved model at epoch 61 with avg_loss=0.00334\n",
      "üîÅ Epoch 61 completed - Avg loss: 0.0033407 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 62/200\n",
      "Epoch: [61][0/731], Loss: 0.00040\n",
      "Epoch: [61][100/731], Loss: 0.00888\n",
      "Epoch: [61][200/731], Loss: 0.00018\n",
      "Epoch: [61][300/731], Loss: 0.00016\n",
      "Epoch: [61][400/731], Loss: 0.00458\n",
      "Epoch: [61][500/731], Loss: 0.00602\n",
      "Epoch: [61][600/731], Loss: 0.00352\n",
      "Epoch: [61][700/731], Loss: 0.00183\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 62 completed - Avg loss: 0.0033493 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 63/200\n",
      "Epoch: [62][0/731], Loss: 0.00238\n",
      "Epoch: [62][100/731], Loss: 0.00075\n",
      "Epoch: [62][200/731], Loss: 0.00362\n",
      "Epoch: [62][300/731], Loss: 0.00143\n",
      "Epoch: [62][400/731], Loss: 0.00232\n",
      "Epoch: [62][500/731], Loss: 0.00486\n",
      "Epoch: [62][600/731], Loss: 0.00275\n",
      "Epoch: [62][700/731], Loss: 0.00057\n",
      "üíæ Saving improved model at epoch 63 with avg_loss=0.00333\n",
      "üîÅ Epoch 63 completed - Avg loss: 0.0033279 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 64/200\n",
      "Epoch: [63][0/731], Loss: 0.00137\n",
      "Epoch: [63][100/731], Loss: 0.00172\n",
      "Epoch: [63][200/731], Loss: 0.00363\n",
      "Epoch: [63][300/731], Loss: 0.00411\n",
      "Epoch: [63][400/731], Loss: 0.00416\n",
      "Epoch: [63][500/731], Loss: 0.00397\n",
      "Epoch: [63][600/731], Loss: 0.00561\n",
      "Epoch: [63][700/731], Loss: 0.00268\n",
      "üíæ Saving improved model at epoch 64 with avg_loss=0.00329\n",
      "üîÅ Epoch 64 completed - Avg loss: 0.0032856 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 65/200\n",
      "Epoch: [64][0/731], Loss: 0.00413\n",
      "Epoch: [64][100/731], Loss: 0.00251\n",
      "Epoch: [64][200/731], Loss: 0.00557\n",
      "Epoch: [64][300/731], Loss: 0.00092\n",
      "Epoch: [64][400/731], Loss: 0.00664\n",
      "Epoch: [64][500/731], Loss: 0.00306\n",
      "Epoch: [64][600/731], Loss: 0.00235\n",
      "Epoch: [64][700/731], Loss: 0.00310\n",
      "üíæ Saving improved model at epoch 65 with avg_loss=0.00326\n",
      "üîÅ Epoch 65 completed - Avg loss: 0.0032645 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 66/200\n",
      "Epoch: [65][0/731], Loss: 0.00119\n",
      "Epoch: [65][100/731], Loss: 0.00123\n",
      "Epoch: [65][200/731], Loss: 0.00349\n",
      "Epoch: [65][300/731], Loss: 0.00066\n",
      "Epoch: [65][400/731], Loss: 0.00415\n",
      "Epoch: [65][500/731], Loss: 0.00491\n",
      "Epoch: [65][600/731], Loss: 0.00048\n",
      "Epoch: [65][700/731], Loss: 0.00130\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 66 completed - Avg loss: 0.0032692 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 67/200\n",
      "Epoch: [66][0/731], Loss: 0.00580\n",
      "Epoch: [66][100/731], Loss: 0.00278\n",
      "Epoch: [66][200/731], Loss: 0.00326\n",
      "Epoch: [66][300/731], Loss: 0.00203\n",
      "Epoch: [66][400/731], Loss: 0.00240\n",
      "Epoch: [66][500/731], Loss: 0.00832\n",
      "Epoch: [66][600/731], Loss: 0.00487\n",
      "Epoch: [66][700/731], Loss: 0.00258\n",
      "üíæ Saving improved model at epoch 67 with avg_loss=0.00326\n",
      "üîÅ Epoch 67 completed - Avg loss: 0.0032557 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 68/200\n",
      "Epoch: [67][0/731], Loss: 0.00155\n",
      "Epoch: [67][100/731], Loss: 0.00518\n",
      "Epoch: [67][200/731], Loss: 0.00186\n",
      "Epoch: [67][300/731], Loss: 0.00004\n",
      "Epoch: [67][400/731], Loss: 0.00704\n",
      "Epoch: [67][500/731], Loss: 0.00206\n",
      "Epoch: [67][600/731], Loss: 0.00224\n",
      "Epoch: [67][700/731], Loss: 0.00126\n",
      "üíæ Saving improved model at epoch 68 with avg_loss=0.00323\n",
      "üîÅ Epoch 68 completed - Avg loss: 0.0032291 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 69/200\n",
      "Epoch: [68][0/731], Loss: 0.00500\n",
      "Epoch: [68][100/731], Loss: 0.00464\n",
      "Epoch: [68][200/731], Loss: 0.00239\n",
      "Epoch: [68][300/731], Loss: 0.00769\n",
      "Epoch: [68][400/731], Loss: 0.00843\n",
      "Epoch: [68][500/731], Loss: 0.00659\n",
      "Epoch: [68][600/731], Loss: 0.00115\n",
      "Epoch: [68][700/731], Loss: 0.00260\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 69 completed - Avg loss: 0.0032419 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 70/200\n",
      "Epoch: [69][0/731], Loss: 0.00171\n",
      "Epoch: [69][100/731], Loss: 0.00189\n",
      "Epoch: [69][200/731], Loss: 0.00302\n",
      "Epoch: [69][300/731], Loss: 0.00122\n",
      "Epoch: [69][400/731], Loss: 0.00311\n",
      "Epoch: [69][500/731], Loss: 0.00187\n",
      "Epoch: [69][600/731], Loss: 0.00132\n",
      "Epoch: [69][700/731], Loss: 0.00376\n",
      "üõë No improvement ‚Äî early stop counter: 2/5\n",
      "üîÅ Epoch 70 completed - Avg loss: 0.0032571 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 71/200\n",
      "Epoch: [70][0/731], Loss: 0.00006\n",
      "Epoch: [70][100/731], Loss: 0.00192\n",
      "Epoch: [70][200/731], Loss: 0.00057\n",
      "Epoch: [70][300/731], Loss: 0.00103\n",
      "Epoch: [70][400/731], Loss: 0.00549\n",
      "Epoch: [70][500/731], Loss: 0.00453\n",
      "Epoch: [70][600/731], Loss: 0.00197\n",
      "Epoch: [70][700/731], Loss: 0.00337\n",
      "üíæ Saving improved model at epoch 71 with avg_loss=0.00322\n",
      "üîÅ Epoch 71 completed - Avg loss: 0.0032160 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 72/200\n",
      "Epoch: [71][0/731], Loss: 0.00434\n",
      "Epoch: [71][100/731], Loss: 0.00138\n",
      "Epoch: [71][200/731], Loss: 0.00186\n",
      "Epoch: [71][300/731], Loss: 0.00485\n",
      "Epoch: [71][400/731], Loss: 0.00807\n",
      "Epoch: [71][500/731], Loss: 0.00010\n",
      "Epoch: [71][600/731], Loss: 0.00187\n",
      "Epoch: [71][700/731], Loss: 0.00106\n",
      "üíæ Saving improved model at epoch 72 with avg_loss=0.00319\n",
      "üîÅ Epoch 72 completed - Avg loss: 0.0031930 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 73/200\n",
      "Epoch: [72][0/731], Loss: 0.00471\n",
      "Epoch: [72][100/731], Loss: 0.00315\n",
      "Epoch: [72][200/731], Loss: 0.00182\n",
      "Epoch: [72][300/731], Loss: 0.00508\n",
      "Epoch: [72][400/731], Loss: 0.00070\n",
      "Epoch: [72][500/731], Loss: 0.00384\n",
      "Epoch: [72][600/731], Loss: 0.00362\n",
      "Epoch: [72][700/731], Loss: 0.00184\n",
      "üíæ Saving improved model at epoch 73 with avg_loss=0.00317\n",
      "üîÅ Epoch 73 completed - Avg loss: 0.0031698 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 74/200\n",
      "Epoch: [73][0/731], Loss: 0.00440\n",
      "Epoch: [73][100/731], Loss: 0.00706\n",
      "Epoch: [73][200/731], Loss: 0.00195\n",
      "Epoch: [73][300/731], Loss: 0.00130\n",
      "Epoch: [73][400/731], Loss: 0.00379\n",
      "Epoch: [73][500/731], Loss: 0.00244\n",
      "Epoch: [73][600/731], Loss: 0.00481\n",
      "Epoch: [73][700/731], Loss: 0.00648\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 74 completed - Avg loss: 0.0031808 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 75/200\n",
      "Epoch: [74][0/731], Loss: 0.00215\n",
      "Epoch: [74][100/731], Loss: 0.00274\n",
      "Epoch: [74][200/731], Loss: 0.00375\n",
      "Epoch: [74][300/731], Loss: 0.00213\n",
      "Epoch: [74][400/731], Loss: 0.00180\n",
      "Epoch: [74][500/731], Loss: 0.00431\n",
      "Epoch: [74][600/731], Loss: 0.00161\n",
      "Epoch: [74][700/731], Loss: 0.00477\n",
      "üõë No improvement ‚Äî early stop counter: 2/5\n",
      "üîÅ Epoch 75 completed - Avg loss: 0.0032297 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 76/200\n",
      "Epoch: [75][0/731], Loss: 0.00248\n",
      "Epoch: [75][100/731], Loss: 0.00169\n",
      "Epoch: [75][200/731], Loss: 0.00249\n",
      "Epoch: [75][300/731], Loss: 0.00177\n",
      "Epoch: [75][400/731], Loss: 0.00247\n",
      "Epoch: [75][500/731], Loss: 0.00530\n",
      "Epoch: [75][600/731], Loss: 0.00367\n",
      "Epoch: [75][700/731], Loss: 0.00395\n",
      "üõë No improvement ‚Äî early stop counter: 3/5\n",
      "üîÅ Epoch 76 completed - Avg loss: 0.0031810 - LR: 2.5e-04\n",
      "\n",
      "üéØ Starting epoch 77/200\n",
      "Epoch: [76][0/731], Loss: 0.00643\n",
      "Epoch: [76][100/731], Loss: 0.00087\n",
      "Epoch: [76][200/731], Loss: 0.00583\n",
      "Epoch: [76][300/731], Loss: 0.00267\n",
      "Epoch: [76][400/731], Loss: 0.00363\n",
      "Epoch: [76][500/731], Loss: 0.00495\n",
      "Epoch: [76][600/731], Loss: 0.00110\n",
      "Epoch: [76][700/731], Loss: 0.00248\n",
      "üõë No improvement ‚Äî early stop counter: 4/5\n",
      "üîÅ Epoch 77 completed - Avg loss: 0.0031855 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 78/200\n",
      "Epoch: [77][0/731], Loss: 0.00297\n",
      "Epoch: [77][100/731], Loss: 0.00098\n",
      "Epoch: [77][200/731], Loss: 0.00080\n",
      "Epoch: [77][300/731], Loss: 0.00480\n",
      "Epoch: [77][400/731], Loss: 0.00212\n",
      "Epoch: [77][500/731], Loss: 0.00269\n",
      "Epoch: [77][600/731], Loss: 0.00170\n",
      "Epoch: [77][700/731], Loss: 0.00916\n",
      "üíæ Saving improved model at epoch 78 with avg_loss=0.00290\n",
      "üîÅ Epoch 78 completed - Avg loss: 0.0029045 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 79/200\n",
      "Epoch: [78][0/731], Loss: 0.00217\n",
      "Epoch: [78][100/731], Loss: 0.00089\n",
      "Epoch: [78][200/731], Loss: 0.00193\n",
      "Epoch: [78][300/731], Loss: 0.00081\n",
      "Epoch: [78][400/731], Loss: 0.00200\n",
      "Epoch: [78][500/731], Loss: 0.00284\n",
      "Epoch: [78][600/731], Loss: 0.00273\n",
      "Epoch: [78][700/731], Loss: 0.00006\n",
      "üíæ Saving improved model at epoch 79 with avg_loss=0.00288\n",
      "üîÅ Epoch 79 completed - Avg loss: 0.0028794 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 80/200\n",
      "Epoch: [79][0/731], Loss: 0.00330\n",
      "Epoch: [79][100/731], Loss: 0.00627\n",
      "Epoch: [79][200/731], Loss: 0.00277\n",
      "Epoch: [79][300/731], Loss: 0.00128\n",
      "Epoch: [79][400/731], Loss: 0.00090\n",
      "Epoch: [79][500/731], Loss: 0.00473\n",
      "Epoch: [79][600/731], Loss: 0.00088\n",
      "Epoch: [79][700/731], Loss: 0.00844\n",
      "üíæ Saving improved model at epoch 80 with avg_loss=0.00286\n",
      "üîÅ Epoch 80 completed - Avg loss: 0.0028612 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 81/200\n",
      "Epoch: [80][0/731], Loss: 0.00300\n",
      "Epoch: [80][100/731], Loss: 0.00080\n",
      "Epoch: [80][200/731], Loss: 0.00091\n",
      "Epoch: [80][300/731], Loss: 0.00097\n",
      "Epoch: [80][400/731], Loss: 0.00061\n",
      "Epoch: [80][500/731], Loss: 0.00311\n",
      "Epoch: [80][600/731], Loss: 0.00002\n",
      "Epoch: [80][700/731], Loss: 0.00473\n",
      "üíæ Saving improved model at epoch 81 with avg_loss=0.00286\n",
      "üîÅ Epoch 81 completed - Avg loss: 0.0028560 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 82/200\n",
      "Epoch: [81][0/731], Loss: 0.00204\n",
      "Epoch: [81][100/731], Loss: 0.00289\n",
      "Epoch: [81][200/731], Loss: 0.00900\n",
      "Epoch: [81][300/731], Loss: 0.00773\n",
      "Epoch: [81][400/731], Loss: 0.00166\n",
      "Epoch: [81][500/731], Loss: 0.00055\n",
      "Epoch: [81][600/731], Loss: 0.00275\n",
      "Epoch: [81][700/731], Loss: 0.00152\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 82 completed - Avg loss: 0.0028644 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 83/200\n",
      "Epoch: [82][0/731], Loss: 0.00398\n",
      "Epoch: [82][100/731], Loss: 0.00400\n",
      "Epoch: [82][200/731], Loss: 0.00132\n",
      "Epoch: [82][300/731], Loss: 0.00456\n",
      "Epoch: [82][400/731], Loss: 0.00314\n",
      "Epoch: [82][500/731], Loss: 0.00310\n",
      "Epoch: [82][600/731], Loss: 0.00331\n",
      "Epoch: [82][700/731], Loss: 0.00381\n",
      "üíæ Saving improved model at epoch 83 with avg_loss=0.00285\n",
      "üîÅ Epoch 83 completed - Avg loss: 0.0028521 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 84/200\n",
      "Epoch: [83][0/731], Loss: 0.00256\n",
      "Epoch: [83][100/731], Loss: 0.00175\n",
      "Epoch: [83][200/731], Loss: 0.00059\n",
      "Epoch: [83][300/731], Loss: 0.00159\n",
      "Epoch: [83][400/731], Loss: 0.00539\n",
      "Epoch: [83][500/731], Loss: 0.00169\n",
      "Epoch: [83][600/731], Loss: 0.00356\n",
      "Epoch: [83][700/731], Loss: 0.00191\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 84 completed - Avg loss: 0.0028582 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 85/200\n",
      "Epoch: [84][0/731], Loss: 0.00100\n",
      "Epoch: [84][100/731], Loss: 0.00085\n",
      "Epoch: [84][200/731], Loss: 0.00021\n",
      "Epoch: [84][300/731], Loss: 0.00123\n",
      "Epoch: [84][400/731], Loss: 0.00219\n",
      "Epoch: [84][500/731], Loss: 0.00788\n",
      "Epoch: [84][600/731], Loss: 0.00185\n",
      "Epoch: [84][700/731], Loss: 0.00264\n",
      "üõë No improvement ‚Äî early stop counter: 2/5\n",
      "üîÅ Epoch 85 completed - Avg loss: 0.0028574 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 86/200\n",
      "Epoch: [85][0/731], Loss: 0.00282\n",
      "Epoch: [85][100/731], Loss: 0.00129\n",
      "Epoch: [85][200/731], Loss: 0.00216\n",
      "Epoch: [85][300/731], Loss: 0.00134\n",
      "Epoch: [85][400/731], Loss: 0.00339\n",
      "Epoch: [85][500/731], Loss: 0.00116\n",
      "Epoch: [85][600/731], Loss: 0.00072\n",
      "Epoch: [85][700/731], Loss: 0.00548\n",
      "üíæ Saving improved model at epoch 86 with avg_loss=0.00284\n",
      "üîÅ Epoch 86 completed - Avg loss: 0.0028395 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 87/200\n",
      "Epoch: [86][0/731], Loss: 0.00129\n",
      "Epoch: [86][100/731], Loss: 0.00468\n",
      "Epoch: [86][200/731], Loss: 0.00216\n",
      "Epoch: [86][300/731], Loss: 0.00563\n",
      "Epoch: [86][400/731], Loss: 0.00555\n",
      "Epoch: [86][500/731], Loss: 0.00308\n",
      "Epoch: [86][600/731], Loss: 0.00548\n",
      "Epoch: [86][700/731], Loss: 0.00005\n",
      "üíæ Saving improved model at epoch 87 with avg_loss=0.00284\n",
      "üîÅ Epoch 87 completed - Avg loss: 0.0028373 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 88/200\n",
      "Epoch: [87][0/731], Loss: 0.00621\n",
      "Epoch: [87][100/731], Loss: 0.00214\n",
      "Epoch: [87][200/731], Loss: 0.00117\n",
      "Epoch: [87][300/731], Loss: 0.00047\n",
      "Epoch: [87][400/731], Loss: 0.00616\n",
      "Epoch: [87][500/731], Loss: 0.00182\n",
      "Epoch: [87][600/731], Loss: 0.00652\n",
      "Epoch: [87][700/731], Loss: 0.00236\n",
      "üíæ Saving improved model at epoch 88 with avg_loss=0.00283\n",
      "üîÅ Epoch 88 completed - Avg loss: 0.0028339 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 89/200\n",
      "Epoch: [88][0/731], Loss: 0.00290\n",
      "Epoch: [88][100/731], Loss: 0.00566\n",
      "Epoch: [88][200/731], Loss: 0.00170\n",
      "Epoch: [88][300/731], Loss: 0.00456\n",
      "Epoch: [88][400/731], Loss: 0.00186\n",
      "Epoch: [88][500/731], Loss: 0.00396\n",
      "Epoch: [88][600/731], Loss: 0.00142\n",
      "Epoch: [88][700/731], Loss: 0.00362\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 89 completed - Avg loss: 0.0028468 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 90/200\n",
      "Epoch: [89][0/731], Loss: 0.00118\n",
      "Epoch: [89][100/731], Loss: 0.00028\n",
      "Epoch: [89][200/731], Loss: 0.00300\n",
      "Epoch: [89][300/731], Loss: 0.00285\n",
      "Epoch: [89][400/731], Loss: 0.00385\n",
      "Epoch: [89][500/731], Loss: 0.00517\n",
      "Epoch: [89][600/731], Loss: 0.00190\n",
      "Epoch: [89][700/731], Loss: 0.00259\n",
      "üíæ Saving improved model at epoch 90 with avg_loss=0.00283\n",
      "üîÅ Epoch 90 completed - Avg loss: 0.0028288 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 91/200\n",
      "Epoch: [90][0/731], Loss: 0.00231\n",
      "Epoch: [90][100/731], Loss: 0.00215\n",
      "Epoch: [90][200/731], Loss: 0.00362\n",
      "Epoch: [90][300/731], Loss: 0.00258\n",
      "Epoch: [90][400/731], Loss: 0.00248\n",
      "Epoch: [90][500/731], Loss: 0.00227\n",
      "Epoch: [90][600/731], Loss: 0.00188\n",
      "Epoch: [90][700/731], Loss: 0.00228\n",
      "üíæ Saving improved model at epoch 91 with avg_loss=0.00283\n",
      "üîÅ Epoch 91 completed - Avg loss: 0.0028256 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 92/200\n",
      "Epoch: [91][0/731], Loss: 0.00487\n",
      "Epoch: [91][100/731], Loss: 0.00488\n",
      "Epoch: [91][200/731], Loss: 0.00004\n",
      "Epoch: [91][300/731], Loss: 0.00498\n",
      "Epoch: [91][400/731], Loss: 0.00082\n",
      "Epoch: [91][500/731], Loss: 0.00092\n",
      "Epoch: [91][600/731], Loss: 0.00057\n",
      "Epoch: [91][700/731], Loss: 0.00340\n",
      "üíæ Saving improved model at epoch 92 with avg_loss=0.00282\n",
      "üîÅ Epoch 92 completed - Avg loss: 0.0028240 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 93/200\n",
      "Epoch: [92][0/731], Loss: 0.00077\n",
      "Epoch: [92][100/731], Loss: 0.00071\n",
      "Epoch: [92][200/731], Loss: 0.00163\n",
      "Epoch: [92][300/731], Loss: 0.00484\n",
      "Epoch: [92][400/731], Loss: 0.00385\n",
      "Epoch: [92][500/731], Loss: 0.00189\n",
      "Epoch: [92][600/731], Loss: 0.00136\n",
      "Epoch: [92][700/731], Loss: 0.00004\n",
      "üíæ Saving improved model at epoch 93 with avg_loss=0.00281\n",
      "üîÅ Epoch 93 completed - Avg loss: 0.0028084 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 94/200\n",
      "Epoch: [93][0/731], Loss: 0.00263\n",
      "Epoch: [93][100/731], Loss: 0.00010\n",
      "Epoch: [93][200/731], Loss: 0.00627\n",
      "Epoch: [93][300/731], Loss: 0.00084\n",
      "Epoch: [93][400/731], Loss: 0.00270\n",
      "Epoch: [93][500/731], Loss: 0.00389\n",
      "Epoch: [93][600/731], Loss: 0.00261\n",
      "Epoch: [93][700/731], Loss: 0.00270\n",
      "üõë No improvement ‚Äî early stop counter: 1/5\n",
      "üîÅ Epoch 94 completed - Avg loss: 0.0028165 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 95/200\n",
      "Epoch: [94][0/731], Loss: 0.00071\n",
      "Epoch: [94][100/731], Loss: 0.00191\n",
      "Epoch: [94][200/731], Loss: 0.00121\n",
      "Epoch: [94][300/731], Loss: 0.00208\n",
      "Epoch: [94][400/731], Loss: 0.00218\n",
      "Epoch: [94][500/731], Loss: 0.00276\n",
      "Epoch: [94][600/731], Loss: 0.00323\n",
      "Epoch: [94][700/731], Loss: 0.00740\n",
      "üõë No improvement ‚Äî early stop counter: 2/5\n",
      "üîÅ Epoch 95 completed - Avg loss: 0.0028294 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 96/200\n",
      "Epoch: [95][0/731], Loss: 0.00254\n",
      "Epoch: [95][100/731], Loss: 0.00390\n",
      "Epoch: [95][200/731], Loss: 0.00523\n",
      "Epoch: [95][300/731], Loss: 0.00400\n",
      "Epoch: [95][400/731], Loss: 0.00586\n",
      "Epoch: [95][500/731], Loss: 0.00124\n",
      "Epoch: [95][600/731], Loss: 0.00189\n",
      "Epoch: [95][700/731], Loss: 0.00064\n",
      "üõë No improvement ‚Äî early stop counter: 3/5\n",
      "üîÅ Epoch 96 completed - Avg loss: 0.0028169 - LR: 1.3e-04\n",
      "\n",
      "üéØ Starting epoch 97/200\n",
      "Epoch: [96][0/731], Loss: 0.00397\n",
      "Epoch: [96][100/731], Loss: 0.00161\n"
     ]
    }
   ],
   "source": [
    "model = train_model(dataset_config, model, epochs=200, batch_size=64, lr=1e-3, load_weights=False, checkpoint_name=f'checkpoint_{DATASET_VAR}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_loss = np.load(f'models/{MODEL_NAME}/history_loss_{DATASET_VAR}.npy')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history_loss, linestyle='-', color='tomato', label=\"Loss\")\n",
    "# plt.title(title)\n",
    "plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(ylabel)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22165"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "os.getpid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
