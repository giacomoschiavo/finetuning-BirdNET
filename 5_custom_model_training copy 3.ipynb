{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Information Creation\n",
    "Create a json file to represent the files inside the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from birdlib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sudo modprobe nvidia_uvm\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"dataset\"\n",
    "MODEL_NAME = 'VanillaCNN'\n",
    "DATASET_VAR = 'augm_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = f'../segments/{DATASET_NAME}'\n",
    "TRAIN_PATH = f\"{DATASET_PATH}/train\"\n",
    "VALID_PATH = f\"{DATASET_PATH}/valid\"\n",
    "TEST_PATH = f\"{DATASET_PATH}/test\"\n",
    "MODEL_PATH = f'./models/{MODEL_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_config(dataset_name, config_file_name='dataset_config.json'):\n",
    "    saving_path = f\"utils/{dataset_name}/{config_file_name}\"\n",
    "    if os.path.exists(saving_path):\n",
    "        print(\"Dataset config already created!\")\n",
    "        with open(saving_path) as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    mappings = utils.get_mappings(TRAIN_PATH)\n",
    "    samples = utils.collect_samples(TRAIN_PATH, VALID_PATH, TEST_PATH, mappings)\n",
    "\n",
    "    dataset_config = {\n",
    "        \"mappings\": mappings,\n",
    "        \"samples\": samples\n",
    "    }\n",
    "    with open(saving_path, \"w\") as f:\n",
    "        json.dump(dataset_config, f)\n",
    "    print(\"Saved new dataset config\")\n",
    "    return dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset config already created!\n"
     ]
    }
   ],
   "source": [
    "dataset_config = create_dataset_config(DATASET_NAME, f'dataset_config_{DATASET_VAR}.json')\n",
    "mappings = dataset_config[\"mappings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = utils.load_model_class(MODEL_NAME)\n",
    "model = model_class(len(mappings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectograms Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Aeroplane\n",
      "Processing: Muscicapa striata_Spotted Flycatcher\n",
      "Processing: Periparus ater_Coal Tit\n",
      "Processing: Regulus regulus_Goldcrest\n",
      "Processing: Anthus trivialis_Tree Pipit\n",
      "Processing: Vegetation\n",
      "Processing: Troglodytes troglodytes_Eurasian Wren\n",
      "Processing: Erithacus rubecula_European Robin\n",
      "Processing: None\n",
      "Processing: Parus major_Great Tit\n",
      "Processing: Certhia familiaris_Eurasian Treecreeper\n",
      "Processing: Phylloscopus collybita_Common Chiffchaff\n",
      "Processing: Coccothraustes coccothraustes_Hawfinch\n",
      "Processing: Wind\n",
      "Processing: Turdus merula_Eurasian Blackbird\n",
      "Processing: Loxia curvirostra_Common Crossbill\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Regulus ignicapilla_Common Firecrest\n",
      "Processing: Sylvia atricapilla_Eurasian Blackcap\n",
      "Processing: Lophophanes cristatus_Crested Tit\n",
      "Processing: Fringilla coelebs_Common Chaffinch\n",
      "Processing: Aeroplane\n",
      "Processing: Muscicapa striata_Spotted Flycatcher\n",
      "Processing: Periparus ater_Coal Tit\n",
      "Processing: Regulus regulus_Goldcrest\n",
      "Processing: Anthus trivialis_Tree Pipit\n",
      "Processing: Vegetation\n",
      "Processing: Troglodytes troglodytes_Eurasian Wren\n",
      "Processing: Erithacus rubecula_European Robin\n",
      "Processing: None\n",
      "Processing: Parus major_Great Tit\n",
      "Processing: Certhia familiaris_Eurasian Treecreeper\n",
      "Processing: Phylloscopus collybita_Common Chiffchaff\n",
      "Processing: Coccothraustes coccothraustes_Hawfinch\n",
      "Processing: Wind\n",
      "Processing: Turdus merula_Eurasian Blackbird\n",
      "Processing: Loxia curvirostra_Common Crossbill\n",
      "Processing: Regulus ignicapilla_Common Firecrest\n",
      "Processing: Sylvia atricapilla_Eurasian Blackcap\n",
      "Processing: Lophophanes cristatus_Crested Tit\n",
      "Processing: Fringilla coelebs_Common Chaffinch\n",
      "Processing: Aeroplane\n",
      "Processing: Muscicapa striata_Spotted Flycatcher\n",
      "Processing: Periparus ater_Coal Tit\n",
      "Processing: Regulus regulus_Goldcrest\n",
      "Processing: Anthus trivialis_Tree Pipit\n",
      "Processing: Vegetation\n",
      "Processing: Troglodytes troglodytes_Eurasian Wren\n",
      "Processing: Erithacus rubecula_European Robin\n",
      "Processing: None\n",
      "Processing: Parus major_Great Tit\n",
      "Processing: Certhia familiaris_Eurasian Treecreeper\n",
      "Processing: Phylloscopus collybita_Common Chiffchaff\n",
      "Processing: Coccothraustes coccothraustes_Hawfinch\n",
      "Processing: Wind\n",
      "Processing: Turdus merula_Eurasian Blackbird\n",
      "Processing: Loxia curvirostra_Common Crossbill\n",
      "Processing: Regulus ignicapilla_Common Firecrest\n",
      "Processing: Sylvia atricapilla_Eurasian Blackcap\n",
      "Processing: Lophophanes cristatus_Crested Tit\n",
      "Processing: Fringilla coelebs_Common Chaffinch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'âœ… Spettrogrammi generati e salvati.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPECS_TRAIN_PATH = f\"{DATASET_PATH}/train_specs\"\n",
    "SPECS_VALID_PATH = f\"{DATASET_PATH}/valid_specs\"\n",
    "SPECS_TEST_PATH = f\"{DATASET_PATH}/test_specs\"\n",
    "os.makedirs(SPECS_TRAIN_PATH, exist_ok=True)\n",
    "os.makedirs(SPECS_VALID_PATH, exist_ok=True)\n",
    "os.makedirs(SPECS_TEST_PATH, exist_ok=True)\n",
    "utils.specs_generation(TRAIN_PATH, SPECS_TRAIN_PATH, dataset_config['mappings'])\n",
    "utils.specs_generation(VALID_PATH, SPECS_VALID_PATH, dataset_config['mappings'])\n",
    "utils.specs_generation(TEST_PATH, SPECS_TEST_PATH, dataset_config['mappings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def train_model(dataset_config, model, epochs=10, batch_size=100, lr=1e-5, patience=3, early_stop_patience=10, early_stop_tollerance=1e-5, print_freq=100, load_weights=False, checkpoint_name='checkpoint.pth'):\n",
    "    history_loss = []\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training {MODEL_NAME} on: {device}\")\n",
    "\n",
    "    model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=patience, threshold=1e-4\n",
    "    )\n",
    "    history_loss = []\n",
    "    best_loss = float(\"inf\")\n",
    "    starting_epoch = 0\n",
    "\n",
    "    saving_path = f'models/{MODEL_NAME}/{checkpoint_name}'\n",
    "    if load_weights:\n",
    "        if not os.path.exists(saving_path):\n",
    "            print(\"No weights found!\")\n",
    "            return None\n",
    "        checkpoint = torch.load(saving_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        history_loss = checkpoint['history_loss']\n",
    "        best_loss = checkpoint['avg_loss']\n",
    "        starting_epoch = len(history_loss)\n",
    "        epochs += starting_epoch\n",
    "        print(f\"Model Loaded!\")\n",
    "    print(f\"Starting from epoch {starting_epoch} for {epochs} epochs\")\n",
    "        \n",
    "    print(\"Loading training data...\")\n",
    "    train_loader = utils.get_dataloader(dataset_config, split=\"train\", batch_size=batch_size)\n",
    "    print(\"Loaded!\")\n",
    "    \n",
    "    early_stop_counter = 0\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            epoch += starting_epoch\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            print(f\"\\nğŸ¯ Starting epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "            for batch_index, (mel_spec, labels, _) in enumerate(train_loader):\n",
    "                mel_spec = mel_spec.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(mel_spec)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch = len(history_loss)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                if batch_index % print_freq == 0:\n",
    "                    print('Epoch: [{0}][{1}/{2}], Loss: {loss:.5f}'.format(epoch, batch_index, len(train_loader), loss=loss))\n",
    "\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            history_loss.append(avg_loss)\n",
    "            scheduler.step(avg_loss)\n",
    "            np.save(f'models/{MODEL_NAME}/history_loss_{DATASET_VAR}.npy', history_loss)\n",
    "            if avg_loss < best_loss - early_stop_tollerance:\n",
    "                best_loss = avg_loss\n",
    "                early_stop_counter = 0\n",
    "                print(f\"ğŸ’¾ Saving improved model at epoch {epoch+1} with avg_loss={avg_loss:.5f}\")\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'avg_loss': avg_loss,\n",
    "                    'history_loss': history_loss\n",
    "                }, saving_path)\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "                print(f\"ğŸ›‘ No improvement â€” early stop counter: {early_stop_counter}/{early_stop_patience}\")\n",
    "\n",
    "            print(f\"ğŸ” Epoch {epoch+1} completed - Avg loss: {avg_loss:.7f} - LR: {optimizer.param_groups[0]['lr']:.1e}\")\n",
    "\n",
    "            if early_stop_counter >= early_stop_patience:\n",
    "                print(f\"\\nğŸš¨ Early stopping triggered after {early_stop_patience} epochs without improvement.\")\n",
    "                break\n",
    "\n",
    "        print(\"âœ… Training completed\")\n",
    "    finally:\n",
    "        print(\"Freeing memory...\")\n",
    "        del train_loader\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VanillaCNN on: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from epoch 0 for 200 epochs\n",
      "Loading training data...\n",
      "Loaded!\n",
      "\n",
      "ğŸ¯ Starting epoch 1/200\n",
      "Epoch: [0][0/406], Loss: 0.69594\n",
      "Epoch: [0][100/406], Loss: 0.16766\n",
      "Epoch: [0][200/406], Loss: 0.12907\n",
      "Epoch: [0][300/406], Loss: 0.13246\n",
      "Epoch: [0][400/406], Loss: 0.14668\n",
      "ğŸ’¾ Saving improved model at epoch 1 with avg_loss=0.14540\n",
      "ğŸ” Epoch 1 completed - Avg loss: 0.1454020 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 2/200\n",
      "Epoch: [1][0/406], Loss: 0.11274\n",
      "Epoch: [1][100/406], Loss: 0.09830\n",
      "Epoch: [1][200/406], Loss: 0.10804\n",
      "Epoch: [1][300/406], Loss: 0.12368\n",
      "Epoch: [1][400/406], Loss: 0.11198\n",
      "ğŸ’¾ Saving improved model at epoch 2 with avg_loss=0.10631\n",
      "ğŸ” Epoch 2 completed - Avg loss: 0.1063102 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 3/200\n",
      "Epoch: [2][0/406], Loss: 0.10217\n",
      "Epoch: [2][100/406], Loss: 0.10773\n",
      "Epoch: [2][200/406], Loss: 0.10426\n",
      "Epoch: [2][300/406], Loss: 0.09635\n",
      "Epoch: [2][400/406], Loss: 0.08555\n",
      "ğŸ’¾ Saving improved model at epoch 3 with avg_loss=0.09485\n",
      "ğŸ” Epoch 3 completed - Avg loss: 0.0948467 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 4/200\n",
      "Epoch: [3][0/406], Loss: 0.09532\n",
      "Epoch: [3][100/406], Loss: 0.08452\n",
      "Epoch: [3][200/406], Loss: 0.08842\n",
      "Epoch: [3][300/406], Loss: 0.09959\n",
      "Epoch: [3][400/406], Loss: 0.11266\n",
      "ğŸ’¾ Saving improved model at epoch 4 with avg_loss=0.08612\n",
      "ğŸ” Epoch 4 completed - Avg loss: 0.0861192 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 5/200\n",
      "Epoch: [4][0/406], Loss: 0.07241\n",
      "Epoch: [4][100/406], Loss: 0.08663\n",
      "Epoch: [4][200/406], Loss: 0.08275\n",
      "Epoch: [4][300/406], Loss: 0.07494\n",
      "Epoch: [4][400/406], Loss: 0.09483\n",
      "ğŸ’¾ Saving improved model at epoch 5 with avg_loss=0.07842\n",
      "ğŸ” Epoch 5 completed - Avg loss: 0.0784211 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 6/200\n",
      "Epoch: [5][0/406], Loss: 0.06452\n",
      "Epoch: [5][100/406], Loss: 0.07116\n",
      "Epoch: [5][200/406], Loss: 0.05105\n",
      "Epoch: [5][300/406], Loss: 0.06003\n",
      "Epoch: [5][400/406], Loss: 0.05705\n",
      "ğŸ’¾ Saving improved model at epoch 6 with avg_loss=0.07203\n",
      "ğŸ” Epoch 6 completed - Avg loss: 0.0720317 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 7/200\n",
      "Epoch: [6][0/406], Loss: 0.07475\n",
      "Epoch: [6][100/406], Loss: 0.04789\n",
      "Epoch: [6][200/406], Loss: 0.07617\n",
      "Epoch: [6][300/406], Loss: 0.06207\n",
      "Epoch: [6][400/406], Loss: 0.09154\n",
      "ğŸ’¾ Saving improved model at epoch 7 with avg_loss=0.06590\n",
      "ğŸ” Epoch 7 completed - Avg loss: 0.0659020 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 8/200\n",
      "Epoch: [7][0/406], Loss: 0.06013\n",
      "Epoch: [7][100/406], Loss: 0.05607\n",
      "Epoch: [7][200/406], Loss: 0.07155\n",
      "Epoch: [7][300/406], Loss: 0.06220\n",
      "Epoch: [7][400/406], Loss: 0.08311\n",
      "ğŸ’¾ Saving improved model at epoch 8 with avg_loss=0.06057\n",
      "ğŸ” Epoch 8 completed - Avg loss: 0.0605686 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 9/200\n",
      "Epoch: [8][0/406], Loss: 0.05676\n",
      "Epoch: [8][100/406], Loss: 0.06332\n",
      "Epoch: [8][200/406], Loss: 0.04939\n",
      "Epoch: [8][300/406], Loss: 0.06500\n",
      "Epoch: [8][400/406], Loss: 0.05800\n",
      "ğŸ’¾ Saving improved model at epoch 9 with avg_loss=0.05586\n",
      "ğŸ” Epoch 9 completed - Avg loss: 0.0558561 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 10/200\n",
      "Epoch: [9][0/406], Loss: 0.04231\n",
      "Epoch: [9][100/406], Loss: 0.04341\n",
      "Epoch: [9][200/406], Loss: 0.04521\n",
      "Epoch: [9][300/406], Loss: 0.04913\n",
      "Epoch: [9][400/406], Loss: 0.06104\n",
      "ğŸ’¾ Saving improved model at epoch 10 with avg_loss=0.05096\n",
      "ğŸ” Epoch 10 completed - Avg loss: 0.0509623 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 11/200\n",
      "Epoch: [10][0/406], Loss: 0.04984\n",
      "Epoch: [10][100/406], Loss: 0.04380\n",
      "Epoch: [10][200/406], Loss: 0.05240\n",
      "Epoch: [10][300/406], Loss: 0.05977\n",
      "Epoch: [10][400/406], Loss: 0.05852\n",
      "ğŸ’¾ Saving improved model at epoch 11 with avg_loss=0.04750\n",
      "ğŸ” Epoch 11 completed - Avg loss: 0.0474953 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 12/200\n",
      "Epoch: [11][0/406], Loss: 0.03853\n",
      "Epoch: [11][100/406], Loss: 0.03017\n",
      "Epoch: [11][200/406], Loss: 0.03269\n",
      "Epoch: [11][300/406], Loss: 0.05421\n",
      "Epoch: [11][400/406], Loss: 0.06898\n",
      "ğŸ’¾ Saving improved model at epoch 12 with avg_loss=0.04390\n",
      "ğŸ” Epoch 12 completed - Avg loss: 0.0438985 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 13/200\n",
      "Epoch: [12][0/406], Loss: 0.03413\n",
      "Epoch: [12][100/406], Loss: 0.04203\n",
      "Epoch: [12][200/406], Loss: 0.03608\n",
      "Epoch: [12][300/406], Loss: 0.03554\n",
      "Epoch: [12][400/406], Loss: 0.04807\n",
      "ğŸ’¾ Saving improved model at epoch 13 with avg_loss=0.04076\n",
      "ğŸ” Epoch 13 completed - Avg loss: 0.0407641 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 14/200\n",
      "Epoch: [13][0/406], Loss: 0.04433\n",
      "Epoch: [13][100/406], Loss: 0.02751\n",
      "Epoch: [13][200/406], Loss: 0.03716\n",
      "Epoch: [13][300/406], Loss: 0.04518\n",
      "Epoch: [13][400/406], Loss: 0.04478\n",
      "ğŸ’¾ Saving improved model at epoch 14 with avg_loss=0.03839\n",
      "ğŸ” Epoch 14 completed - Avg loss: 0.0383932 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 15/200\n",
      "Epoch: [14][0/406], Loss: 0.03233\n",
      "Epoch: [14][100/406], Loss: 0.02358\n",
      "Epoch: [14][200/406], Loss: 0.04367\n",
      "Epoch: [14][300/406], Loss: 0.03418\n",
      "Epoch: [14][400/406], Loss: 0.03101\n",
      "ğŸ’¾ Saving improved model at epoch 15 with avg_loss=0.03542\n",
      "ğŸ” Epoch 15 completed - Avg loss: 0.0354245 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 16/200\n",
      "Epoch: [15][0/406], Loss: 0.01913\n",
      "Epoch: [15][100/406], Loss: 0.03980\n",
      "Epoch: [15][200/406], Loss: 0.02881\n",
      "Epoch: [15][300/406], Loss: 0.03762\n",
      "Epoch: [15][400/406], Loss: 0.03120\n",
      "ğŸ’¾ Saving improved model at epoch 16 with avg_loss=0.03407\n",
      "ğŸ” Epoch 16 completed - Avg loss: 0.0340676 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 17/200\n",
      "Epoch: [16][0/406], Loss: 0.02620\n",
      "Epoch: [16][100/406], Loss: 0.04141\n",
      "Epoch: [16][200/406], Loss: 0.02721\n",
      "Epoch: [16][300/406], Loss: 0.05829\n",
      "Epoch: [16][400/406], Loss: 0.03628\n",
      "ğŸ’¾ Saving improved model at epoch 17 with avg_loss=0.03285\n",
      "ğŸ” Epoch 17 completed - Avg loss: 0.0328545 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 18/200\n",
      "Epoch: [17][0/406], Loss: 0.03399\n",
      "Epoch: [17][100/406], Loss: 0.02976\n",
      "Epoch: [17][200/406], Loss: 0.03148\n",
      "Epoch: [17][300/406], Loss: 0.05086\n",
      "Epoch: [17][400/406], Loss: 0.04701\n",
      "ğŸ’¾ Saving improved model at epoch 18 with avg_loss=0.03006\n",
      "ğŸ” Epoch 18 completed - Avg loss: 0.0300587 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 19/200\n",
      "Epoch: [18][0/406], Loss: 0.02755\n",
      "Epoch: [18][100/406], Loss: 0.02542\n",
      "Epoch: [18][200/406], Loss: 0.03430\n",
      "Epoch: [18][300/406], Loss: 0.02438\n",
      "Epoch: [18][400/406], Loss: 0.02679\n",
      "ğŸ’¾ Saving improved model at epoch 19 with avg_loss=0.02999\n",
      "ğŸ” Epoch 19 completed - Avg loss: 0.0299852 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 20/200\n",
      "Epoch: [19][0/406], Loss: 0.03142\n",
      "Epoch: [19][100/406], Loss: 0.01836\n",
      "Epoch: [19][200/406], Loss: 0.02953\n",
      "Epoch: [19][300/406], Loss: 0.02303\n",
      "Epoch: [19][400/406], Loss: 0.03740\n",
      "ğŸ’¾ Saving improved model at epoch 20 with avg_loss=0.02849\n",
      "ğŸ” Epoch 20 completed - Avg loss: 0.0284902 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 21/200\n",
      "Epoch: [20][0/406], Loss: 0.01611\n",
      "Epoch: [20][100/406], Loss: 0.02163\n",
      "Epoch: [20][200/406], Loss: 0.03365\n",
      "Epoch: [20][300/406], Loss: 0.05533\n",
      "Epoch: [20][400/406], Loss: 0.03244\n",
      "ğŸ’¾ Saving improved model at epoch 21 with avg_loss=0.02616\n",
      "ğŸ” Epoch 21 completed - Avg loss: 0.0261585 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 22/200\n",
      "Epoch: [21][0/406], Loss: 0.02188\n",
      "Epoch: [21][100/406], Loss: 0.01584\n",
      "Epoch: [21][200/406], Loss: 0.01664\n",
      "Epoch: [21][300/406], Loss: 0.02689\n",
      "Epoch: [21][400/406], Loss: 0.02963\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 22 completed - Avg loss: 0.0272945 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 23/200\n",
      "Epoch: [22][0/406], Loss: 0.01840\n",
      "Epoch: [22][100/406], Loss: 0.01025\n",
      "Epoch: [22][200/406], Loss: 0.02362\n",
      "Epoch: [22][300/406], Loss: 0.03052\n",
      "Epoch: [22][400/406], Loss: 0.03479\n",
      "ğŸ’¾ Saving improved model at epoch 23 with avg_loss=0.02595\n",
      "ğŸ” Epoch 23 completed - Avg loss: 0.0259549 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 24/200\n",
      "Epoch: [23][0/406], Loss: 0.01910\n",
      "Epoch: [23][100/406], Loss: 0.01944\n",
      "Epoch: [23][200/406], Loss: 0.03840\n",
      "Epoch: [23][300/406], Loss: 0.03890\n",
      "Epoch: [23][400/406], Loss: 0.04309\n",
      "ğŸ’¾ Saving improved model at epoch 24 with avg_loss=0.02438\n",
      "ğŸ” Epoch 24 completed - Avg loss: 0.0243753 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 25/200\n",
      "Epoch: [24][0/406], Loss: 0.01571\n",
      "Epoch: [24][100/406], Loss: 0.02505\n",
      "Epoch: [24][200/406], Loss: 0.03743\n",
      "Epoch: [24][300/406], Loss: 0.03134\n",
      "Epoch: [24][400/406], Loss: 0.04540\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 25 completed - Avg loss: 0.0255245 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 26/200\n",
      "Epoch: [25][0/406], Loss: 0.01908\n",
      "Epoch: [25][100/406], Loss: 0.02142\n",
      "Epoch: [25][200/406], Loss: 0.02915\n",
      "Epoch: [25][300/406], Loss: 0.03565\n",
      "Epoch: [25][400/406], Loss: 0.02663\n",
      "ğŸ’¾ Saving improved model at epoch 26 with avg_loss=0.02371\n",
      "ğŸ” Epoch 26 completed - Avg loss: 0.0237119 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 27/200\n",
      "Epoch: [26][0/406], Loss: 0.01936\n",
      "Epoch: [26][100/406], Loss: 0.01897\n",
      "Epoch: [26][200/406], Loss: 0.02640\n",
      "Epoch: [26][300/406], Loss: 0.02415\n",
      "Epoch: [26][400/406], Loss: 0.02683\n",
      "ğŸ’¾ Saving improved model at epoch 27 with avg_loss=0.02325\n",
      "ğŸ” Epoch 27 completed - Avg loss: 0.0232452 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 28/200\n",
      "Epoch: [27][0/406], Loss: 0.01709\n",
      "Epoch: [27][100/406], Loss: 0.01857\n",
      "Epoch: [27][200/406], Loss: 0.01794\n",
      "Epoch: [27][300/406], Loss: 0.02517\n",
      "Epoch: [27][400/406], Loss: 0.02318\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 28 completed - Avg loss: 0.0233572 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 29/200\n",
      "Epoch: [28][0/406], Loss: 0.01394\n",
      "Epoch: [28][100/406], Loss: 0.01324\n",
      "Epoch: [28][200/406], Loss: 0.02291\n",
      "Epoch: [28][300/406], Loss: 0.03467\n",
      "Epoch: [28][400/406], Loss: 0.02108\n",
      "ğŸ’¾ Saving improved model at epoch 29 with avg_loss=0.02185\n",
      "ğŸ” Epoch 29 completed - Avg loss: 0.0218534 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 30/200\n",
      "Epoch: [29][0/406], Loss: 0.01156\n",
      "Epoch: [29][100/406], Loss: 0.01331\n",
      "Epoch: [29][200/406], Loss: 0.01683\n",
      "Epoch: [29][300/406], Loss: 0.02466\n",
      "Epoch: [29][400/406], Loss: 0.04569\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 30 completed - Avg loss: 0.0227238 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 31/200\n",
      "Epoch: [30][0/406], Loss: 0.01543\n",
      "Epoch: [30][100/406], Loss: 0.01885\n",
      "Epoch: [30][200/406], Loss: 0.02395\n",
      "Epoch: [30][300/406], Loss: 0.02903\n",
      "Epoch: [30][400/406], Loss: 0.03353\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 31 completed - Avg loss: 0.0225874 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 32/200\n",
      "Epoch: [31][0/406], Loss: 0.01060\n",
      "Epoch: [31][100/406], Loss: 0.01195\n",
      "Epoch: [31][200/406], Loss: 0.01893\n",
      "Epoch: [31][300/406], Loss: 0.01893\n",
      "Epoch: [31][400/406], Loss: 0.02246\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 32 completed - Avg loss: 0.0223912 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 33/200\n",
      "Epoch: [32][0/406], Loss: 0.01661\n",
      "Epoch: [32][100/406], Loss: 0.01387\n",
      "Epoch: [32][200/406], Loss: 0.03329\n",
      "Epoch: [32][300/406], Loss: 0.01837\n",
      "Epoch: [32][400/406], Loss: 0.01981\n",
      "ğŸ’¾ Saving improved model at epoch 33 with avg_loss=0.02167\n",
      "ğŸ” Epoch 33 completed - Avg loss: 0.0216694 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 34/200\n",
      "Epoch: [33][0/406], Loss: 0.01832\n",
      "Epoch: [33][100/406], Loss: 0.01899\n",
      "Epoch: [33][200/406], Loss: 0.02024\n",
      "Epoch: [33][300/406], Loss: 0.02789\n",
      "Epoch: [33][400/406], Loss: 0.03829\n",
      "ğŸ’¾ Saving improved model at epoch 34 with avg_loss=0.02112\n",
      "ğŸ” Epoch 34 completed - Avg loss: 0.0211205 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 35/200\n",
      "Epoch: [34][0/406], Loss: 0.02237\n",
      "Epoch: [34][100/406], Loss: 0.02233\n",
      "Epoch: [34][200/406], Loss: 0.02370\n",
      "Epoch: [34][300/406], Loss: 0.01900\n",
      "Epoch: [34][400/406], Loss: 0.02876\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 35 completed - Avg loss: 0.0212402 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 36/200\n",
      "Epoch: [35][0/406], Loss: 0.01766\n",
      "Epoch: [35][100/406], Loss: 0.01484\n",
      "Epoch: [35][200/406], Loss: 0.01517\n",
      "Epoch: [35][300/406], Loss: 0.02917\n",
      "Epoch: [35][400/406], Loss: 0.02698\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 36 completed - Avg loss: 0.0222079 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 37/200\n",
      "Epoch: [36][0/406], Loss: 0.01505\n",
      "Epoch: [36][100/406], Loss: 0.02276\n",
      "Epoch: [36][200/406], Loss: 0.03145\n",
      "Epoch: [36][300/406], Loss: 0.02858\n",
      "Epoch: [36][400/406], Loss: 0.03125\n",
      "ğŸ’¾ Saving improved model at epoch 37 with avg_loss=0.02042\n",
      "ğŸ” Epoch 37 completed - Avg loss: 0.0204155 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 38/200\n",
      "Epoch: [37][0/406], Loss: 0.01439\n",
      "Epoch: [37][100/406], Loss: 0.01062\n",
      "Epoch: [37][200/406], Loss: 0.01798\n",
      "Epoch: [37][300/406], Loss: 0.02802\n",
      "Epoch: [37][400/406], Loss: 0.02689\n",
      "ğŸ’¾ Saving improved model at epoch 38 with avg_loss=0.01970\n",
      "ğŸ” Epoch 38 completed - Avg loss: 0.0197028 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 39/200\n",
      "Epoch: [38][0/406], Loss: 0.01586\n",
      "Epoch: [38][100/406], Loss: 0.02723\n",
      "Epoch: [38][200/406], Loss: 0.01609\n",
      "Epoch: [38][300/406], Loss: 0.03018\n",
      "Epoch: [38][400/406], Loss: 0.02332\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 39 completed - Avg loss: 0.0205949 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 40/200\n",
      "Epoch: [39][0/406], Loss: 0.01846\n",
      "Epoch: [39][100/406], Loss: 0.00999\n",
      "Epoch: [39][200/406], Loss: 0.01550\n",
      "Epoch: [39][300/406], Loss: 0.03303\n",
      "Epoch: [39][400/406], Loss: 0.01645\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 40 completed - Avg loss: 0.0203974 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 41/200\n",
      "Epoch: [40][0/406], Loss: 0.00977\n",
      "Epoch: [40][100/406], Loss: 0.01206\n",
      "Epoch: [40][200/406], Loss: 0.01796\n",
      "Epoch: [40][300/406], Loss: 0.02230\n",
      "Epoch: [40][400/406], Loss: 0.02922\n",
      "ğŸ’¾ Saving improved model at epoch 41 with avg_loss=0.01941\n",
      "ğŸ” Epoch 41 completed - Avg loss: 0.0194116 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 42/200\n",
      "Epoch: [41][0/406], Loss: 0.01034\n",
      "Epoch: [41][100/406], Loss: 0.01563\n",
      "Epoch: [41][200/406], Loss: 0.01670\n",
      "Epoch: [41][300/406], Loss: 0.03163\n",
      "Epoch: [41][400/406], Loss: 0.02190\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 42 completed - Avg loss: 0.0203634 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 43/200\n",
      "Epoch: [42][0/406], Loss: 0.01509\n",
      "Epoch: [42][100/406], Loss: 0.01617\n",
      "Epoch: [42][200/406], Loss: 0.01274\n",
      "Epoch: [42][300/406], Loss: 0.04013\n",
      "Epoch: [42][400/406], Loss: 0.02697\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 43 completed - Avg loss: 0.0199584 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 44/200\n",
      "Epoch: [43][0/406], Loss: 0.02576\n",
      "Epoch: [43][100/406], Loss: 0.02052\n",
      "Epoch: [43][200/406], Loss: 0.02457\n",
      "Epoch: [43][300/406], Loss: 0.02004\n",
      "Epoch: [43][400/406], Loss: 0.02295\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 44 completed - Avg loss: 0.0200418 - LR: 1.0e-03\n",
      "\n",
      "ğŸ¯ Starting epoch 45/200\n",
      "Epoch: [44][0/406], Loss: 0.02148\n",
      "Epoch: [44][100/406], Loss: 0.01521\n",
      "Epoch: [44][200/406], Loss: 0.01980\n",
      "Epoch: [44][300/406], Loss: 0.02299\n",
      "Epoch: [44][400/406], Loss: 0.02522\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 45 completed - Avg loss: 0.0197950 - LR: 5.0e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 46/200\n",
      "Epoch: [45][0/406], Loss: 0.01675\n",
      "Epoch: [45][100/406], Loss: 0.01179\n",
      "Epoch: [45][200/406], Loss: 0.02653\n",
      "Epoch: [45][300/406], Loss: 0.00906\n",
      "Epoch: [45][400/406], Loss: 0.03449\n",
      "ğŸ’¾ Saving improved model at epoch 46 with avg_loss=0.01150\n",
      "ğŸ” Epoch 46 completed - Avg loss: 0.0114971 - LR: 5.0e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 47/200\n",
      "Epoch: [46][0/406], Loss: 0.00669\n",
      "Epoch: [46][100/406], Loss: 0.02847\n",
      "Epoch: [46][200/406], Loss: 0.00432\n",
      "Epoch: [46][300/406], Loss: 0.00908\n",
      "Epoch: [46][400/406], Loss: 0.00563\n",
      "ğŸ’¾ Saving improved model at epoch 47 with avg_loss=0.00823\n",
      "ğŸ” Epoch 47 completed - Avg loss: 0.0082305 - LR: 5.0e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 48/200\n",
      "Epoch: [47][0/406], Loss: 0.00559\n",
      "Epoch: [47][100/406], Loss: 0.00516\n",
      "Epoch: [47][200/406], Loss: 0.00504\n",
      "Epoch: [47][300/406], Loss: 0.00528\n",
      "Epoch: [47][400/406], Loss: 0.02363\n",
      "ğŸ’¾ Saving improved model at epoch 48 with avg_loss=0.00784\n",
      "ğŸ” Epoch 48 completed - Avg loss: 0.0078391 - LR: 5.0e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 49/200\n",
      "Epoch: [48][0/406], Loss: 0.00550\n",
      "Epoch: [48][100/406], Loss: 0.00731\n",
      "Epoch: [48][200/406], Loss: 0.00481\n",
      "Epoch: [48][300/406], Loss: 0.00950\n",
      "Epoch: [48][400/406], Loss: 0.00730\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 49 completed - Avg loss: 0.0091336 - LR: 5.0e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 50/200\n",
      "Epoch: [49][0/406], Loss: 0.00977\n",
      "Epoch: [49][100/406], Loss: 0.00465\n",
      "Epoch: [49][200/406], Loss: 0.00573\n",
      "Epoch: [49][300/406], Loss: 0.00358\n",
      "Epoch: [49][400/406], Loss: 0.01590\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 50 completed - Avg loss: 0.0100481 - LR: 5.0e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 51/200\n",
      "Epoch: [50][0/406], Loss: 0.00533\n",
      "Epoch: [50][100/406], Loss: 0.01404\n",
      "Epoch: [50][200/406], Loss: 0.00870\n",
      "Epoch: [50][300/406], Loss: 0.01033\n",
      "Epoch: [50][400/406], Loss: 0.01342\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 51 completed - Avg loss: 0.0119917 - LR: 5.0e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 52/200\n",
      "Epoch: [51][0/406], Loss: 0.00795\n",
      "Epoch: [51][100/406], Loss: 0.00797\n",
      "Epoch: [51][200/406], Loss: 0.01203\n",
      "Epoch: [51][300/406], Loss: 0.00640\n",
      "Epoch: [51][400/406], Loss: 0.01766\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 52 completed - Avg loss: 0.0112320 - LR: 2.5e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 53/200\n",
      "Epoch: [52][0/406], Loss: 0.00535\n",
      "Epoch: [52][100/406], Loss: 0.00409\n",
      "Epoch: [52][200/406], Loss: 0.00404\n",
      "Epoch: [52][300/406], Loss: 0.00449\n",
      "Epoch: [52][400/406], Loss: 0.00383\n",
      "ğŸ’¾ Saving improved model at epoch 53 with avg_loss=0.00707\n",
      "ğŸ” Epoch 53 completed - Avg loss: 0.0070702 - LR: 2.5e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 54/200\n",
      "Epoch: [53][0/406], Loss: 0.00387\n",
      "Epoch: [53][100/406], Loss: 0.00424\n",
      "Epoch: [53][200/406], Loss: 0.00270\n",
      "Epoch: [53][300/406], Loss: 0.01651\n",
      "Epoch: [53][400/406], Loss: 0.00313\n",
      "ğŸ’¾ Saving improved model at epoch 54 with avg_loss=0.00523\n",
      "ğŸ” Epoch 54 completed - Avg loss: 0.0052338 - LR: 2.5e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 55/200\n",
      "Epoch: [54][0/406], Loss: 0.00351\n",
      "Epoch: [54][100/406], Loss: 0.00369\n",
      "Epoch: [54][200/406], Loss: 0.00513\n",
      "Epoch: [54][300/406], Loss: 0.00393\n",
      "Epoch: [54][400/406], Loss: 0.00458\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 55 completed - Avg loss: 0.0054812 - LR: 2.5e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 56/200\n",
      "Epoch: [55][0/406], Loss: 0.00540\n",
      "Epoch: [55][100/406], Loss: 0.00320\n",
      "Epoch: [55][200/406], Loss: 0.00344\n",
      "Epoch: [55][300/406], Loss: 0.00549\n",
      "Epoch: [55][400/406], Loss: 0.00535\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 56 completed - Avg loss: 0.0056335 - LR: 2.5e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 57/200\n",
      "Epoch: [56][0/406], Loss: 0.00278\n",
      "Epoch: [56][100/406], Loss: 0.00758\n",
      "Epoch: [56][200/406], Loss: 0.00431\n",
      "Epoch: [56][300/406], Loss: 0.00408\n",
      "Epoch: [56][400/406], Loss: 0.00458\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 57 completed - Avg loss: 0.0058042 - LR: 2.5e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 58/200\n",
      "Epoch: [57][0/406], Loss: 0.00376\n",
      "Epoch: [57][100/406], Loss: 0.00559\n",
      "Epoch: [57][200/406], Loss: 0.00883\n",
      "Epoch: [57][300/406], Loss: 0.00358\n",
      "Epoch: [57][400/406], Loss: 0.00453\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 58 completed - Avg loss: 0.0063689 - LR: 1.3e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 59/200\n",
      "Epoch: [58][0/406], Loss: 0.01579\n",
      "Epoch: [58][100/406], Loss: 0.00296\n",
      "Epoch: [58][200/406], Loss: 0.00354\n",
      "Epoch: [58][300/406], Loss: 0.00272\n",
      "Epoch: [58][400/406], Loss: 0.00304\n",
      "ğŸ’¾ Saving improved model at epoch 59 with avg_loss=0.00461\n",
      "ğŸ” Epoch 59 completed - Avg loss: 0.0046085 - LR: 1.3e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 60/200\n",
      "Epoch: [59][0/406], Loss: 0.00289\n",
      "Epoch: [59][100/406], Loss: 0.00630\n",
      "Epoch: [59][200/406], Loss: 0.00185\n",
      "Epoch: [59][300/406], Loss: 0.00322\n",
      "Epoch: [59][400/406], Loss: 0.00803\n",
      "ğŸ’¾ Saving improved model at epoch 60 with avg_loss=0.00411\n",
      "ğŸ” Epoch 60 completed - Avg loss: 0.0041120 - LR: 1.3e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 61/200\n",
      "Epoch: [60][0/406], Loss: 0.00283\n",
      "Epoch: [60][100/406], Loss: 0.00262\n",
      "Epoch: [60][200/406], Loss: 0.00321\n",
      "Epoch: [60][300/406], Loss: 0.00302\n",
      "Epoch: [60][400/406], Loss: 0.00270\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 61 completed - Avg loss: 0.0042079 - LR: 1.3e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 62/200\n",
      "Epoch: [61][0/406], Loss: 0.00258\n",
      "Epoch: [61][100/406], Loss: 0.00939\n",
      "Epoch: [61][200/406], Loss: 0.00227\n",
      "Epoch: [61][300/406], Loss: 0.00314\n",
      "Epoch: [61][400/406], Loss: 0.00396\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 62 completed - Avg loss: 0.0043719 - LR: 1.3e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 63/200\n",
      "Epoch: [62][0/406], Loss: 0.00470\n",
      "Epoch: [62][100/406], Loss: 0.00400\n",
      "Epoch: [62][200/406], Loss: 0.00277\n",
      "Epoch: [62][300/406], Loss: 0.00501\n",
      "Epoch: [62][400/406], Loss: 0.00363\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 63 completed - Avg loss: 0.0045466 - LR: 1.3e-04\n",
      "\n",
      "ğŸ¯ Starting epoch 64/200\n",
      "Epoch: [63][0/406], Loss: 0.00242\n",
      "Epoch: [63][100/406], Loss: 0.00545\n",
      "Epoch: [63][200/406], Loss: 0.01050\n",
      "Epoch: [63][300/406], Loss: 0.00327\n",
      "Epoch: [63][400/406], Loss: 0.00295\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 64 completed - Avg loss: 0.0044298 - LR: 6.3e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 65/200\n",
      "Epoch: [64][0/406], Loss: 0.00304\n",
      "Epoch: [64][100/406], Loss: 0.00225\n",
      "Epoch: [64][200/406], Loss: 0.00296\n",
      "Epoch: [64][300/406], Loss: 0.00427\n",
      "Epoch: [64][400/406], Loss: 0.00521\n",
      "ğŸ’¾ Saving improved model at epoch 65 with avg_loss=0.00358\n",
      "ğŸ” Epoch 65 completed - Avg loss: 0.0035849 - LR: 6.3e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 66/200\n",
      "Epoch: [65][0/406], Loss: 0.00209\n",
      "Epoch: [65][100/406], Loss: 0.00241\n",
      "Epoch: [65][200/406], Loss: 0.00368\n",
      "Epoch: [65][300/406], Loss: 0.00351\n",
      "Epoch: [65][400/406], Loss: 0.00523\n",
      "ğŸ’¾ Saving improved model at epoch 66 with avg_loss=0.00340\n",
      "ğŸ” Epoch 66 completed - Avg loss: 0.0033998 - LR: 6.3e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 67/200\n",
      "Epoch: [66][0/406], Loss: 0.00219\n",
      "Epoch: [66][100/406], Loss: 0.00200\n",
      "Epoch: [66][200/406], Loss: 0.00617\n",
      "Epoch: [66][300/406], Loss: 0.00299\n",
      "Epoch: [66][400/406], Loss: 0.00250\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 67 completed - Avg loss: 0.0034247 - LR: 6.3e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 68/200\n",
      "Epoch: [67][0/406], Loss: 0.00420\n",
      "Epoch: [67][100/406], Loss: 0.00219\n",
      "Epoch: [67][200/406], Loss: 0.00407\n",
      "Epoch: [67][300/406], Loss: 0.00407\n",
      "Epoch: [67][400/406], Loss: 0.00192\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 68 completed - Avg loss: 0.0034320 - LR: 6.3e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 69/200\n",
      "Epoch: [68][0/406], Loss: 0.00216\n",
      "Epoch: [68][100/406], Loss: 0.00298\n",
      "Epoch: [68][200/406], Loss: 0.00295\n",
      "Epoch: [68][300/406], Loss: 0.00229\n",
      "Epoch: [68][400/406], Loss: 0.00331\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 69 completed - Avg loss: 0.0034458 - LR: 6.3e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 70/200\n",
      "Epoch: [69][0/406], Loss: 0.00211\n",
      "Epoch: [69][100/406], Loss: 0.00233\n",
      "Epoch: [69][200/406], Loss: 0.00399\n",
      "Epoch: [69][300/406], Loss: 0.00273\n",
      "Epoch: [69][400/406], Loss: 0.00250\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 70 completed - Avg loss: 0.0034113 - LR: 3.1e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 71/200\n",
      "Epoch: [70][0/406], Loss: 0.00344\n",
      "Epoch: [70][100/406], Loss: 0.00246\n",
      "Epoch: [70][200/406], Loss: 0.00251\n",
      "Epoch: [70][300/406], Loss: 0.00258\n",
      "Epoch: [70][400/406], Loss: 0.00248\n",
      "ğŸ’¾ Saving improved model at epoch 71 with avg_loss=0.00306\n",
      "ğŸ” Epoch 71 completed - Avg loss: 0.0030551 - LR: 3.1e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 72/200\n",
      "Epoch: [71][0/406], Loss: 0.00143\n",
      "Epoch: [71][100/406], Loss: 0.00203\n",
      "Epoch: [71][200/406], Loss: 0.00249\n",
      "Epoch: [71][300/406], Loss: 0.00385\n",
      "Epoch: [71][400/406], Loss: 0.00228\n",
      "ğŸ’¾ Saving improved model at epoch 72 with avg_loss=0.00293\n",
      "ğŸ” Epoch 72 completed - Avg loss: 0.0029298 - LR: 3.1e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 73/200\n",
      "Epoch: [72][0/406], Loss: 0.00206\n",
      "Epoch: [72][100/406], Loss: 0.00322\n",
      "Epoch: [72][200/406], Loss: 0.00232\n",
      "Epoch: [72][300/406], Loss: 0.00217\n",
      "Epoch: [72][400/406], Loss: 0.00201\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 73 completed - Avg loss: 0.0029935 - LR: 3.1e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 74/200\n",
      "Epoch: [73][0/406], Loss: 0.00263\n",
      "Epoch: [73][100/406], Loss: 0.00275\n",
      "Epoch: [73][200/406], Loss: 0.00249\n",
      "Epoch: [73][300/406], Loss: 0.00310\n",
      "Epoch: [73][400/406], Loss: 0.00287\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 74 completed - Avg loss: 0.0029737 - LR: 3.1e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 75/200\n",
      "Epoch: [74][0/406], Loss: 0.00242\n",
      "Epoch: [74][100/406], Loss: 0.00217\n",
      "Epoch: [74][200/406], Loss: 0.01428\n",
      "Epoch: [74][300/406], Loss: 0.00588\n",
      "Epoch: [74][400/406], Loss: 0.00328\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 75 completed - Avg loss: 0.0029891 - LR: 3.1e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 76/200\n",
      "Epoch: [75][0/406], Loss: 0.00252\n",
      "Epoch: [75][100/406], Loss: 0.00202\n",
      "Epoch: [75][200/406], Loss: 0.00196\n",
      "Epoch: [75][300/406], Loss: 0.00362\n",
      "Epoch: [75][400/406], Loss: 0.00355\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 76 completed - Avg loss: 0.0030032 - LR: 1.6e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 77/200\n",
      "Epoch: [76][0/406], Loss: 0.00303\n",
      "Epoch: [76][100/406], Loss: 0.00208\n",
      "Epoch: [76][200/406], Loss: 0.00350\n",
      "Epoch: [76][300/406], Loss: 0.00176\n",
      "Epoch: [76][400/406], Loss: 0.00276\n",
      "ğŸ’¾ Saving improved model at epoch 77 with avg_loss=0.00278\n",
      "ğŸ” Epoch 77 completed - Avg loss: 0.0027833 - LR: 1.6e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 78/200\n",
      "Epoch: [77][0/406], Loss: 0.00248\n",
      "Epoch: [77][100/406], Loss: 0.00264\n",
      "Epoch: [77][200/406], Loss: 0.00162\n",
      "Epoch: [77][300/406], Loss: 0.00530\n",
      "Epoch: [77][400/406], Loss: 0.00318\n",
      "ğŸ’¾ Saving improved model at epoch 78 with avg_loss=0.00275\n",
      "ğŸ” Epoch 78 completed - Avg loss: 0.0027454 - LR: 1.6e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 79/200\n",
      "Epoch: [78][0/406], Loss: 0.00151\n",
      "Epoch: [78][100/406], Loss: 0.00222\n",
      "Epoch: [78][200/406], Loss: 0.00334\n",
      "Epoch: [78][300/406], Loss: 0.00191\n",
      "Epoch: [78][400/406], Loss: 0.00464\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 79 completed - Avg loss: 0.0027587 - LR: 1.6e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 80/200\n",
      "Epoch: [79][0/406], Loss: 0.00314\n",
      "Epoch: [79][100/406], Loss: 0.00216\n",
      "Epoch: [79][200/406], Loss: 0.00229\n",
      "Epoch: [79][300/406], Loss: 0.00373\n",
      "Epoch: [79][400/406], Loss: 0.00146\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 80 completed - Avg loss: 0.0027742 - LR: 1.6e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 81/200\n",
      "Epoch: [80][0/406], Loss: 0.00379\n",
      "Epoch: [80][100/406], Loss: 0.00195\n",
      "Epoch: [80][200/406], Loss: 0.00184\n",
      "Epoch: [80][300/406], Loss: 0.00234\n",
      "Epoch: [80][400/406], Loss: 0.00187\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 81 completed - Avg loss: 0.0027603 - LR: 1.6e-05\n",
      "\n",
      "ğŸ¯ Starting epoch 82/200\n",
      "Epoch: [81][0/406], Loss: 0.00461\n",
      "Epoch: [81][100/406], Loss: 0.00557\n",
      "Epoch: [81][200/406], Loss: 0.00231\n",
      "Epoch: [81][300/406], Loss: 0.00200\n",
      "Epoch: [81][400/406], Loss: 0.00219\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 82 completed - Avg loss: 0.0027533 - LR: 7.8e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 83/200\n",
      "Epoch: [82][0/406], Loss: 0.00399\n",
      "Epoch: [82][100/406], Loss: 0.00203\n",
      "Epoch: [82][200/406], Loss: 0.00404\n",
      "Epoch: [82][300/406], Loss: 0.00232\n",
      "Epoch: [82][400/406], Loss: 0.00186\n",
      "ğŸ’¾ Saving improved model at epoch 83 with avg_loss=0.00264\n",
      "ğŸ” Epoch 83 completed - Avg loss: 0.0026410 - LR: 7.8e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 84/200\n",
      "Epoch: [83][0/406], Loss: 0.00248\n",
      "Epoch: [83][100/406], Loss: 0.00495\n",
      "Epoch: [83][200/406], Loss: 0.00208\n",
      "Epoch: [83][300/406], Loss: 0.00150\n",
      "Epoch: [83][400/406], Loss: 0.00226\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 84 completed - Avg loss: 0.0026407 - LR: 7.8e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 85/200\n",
      "Epoch: [84][0/406], Loss: 0.00221\n",
      "Epoch: [84][100/406], Loss: 0.00253\n",
      "Epoch: [84][200/406], Loss: 0.00170\n",
      "Epoch: [84][300/406], Loss: 0.00246\n",
      "Epoch: [84][400/406], Loss: 0.00222\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 85 completed - Avg loss: 0.0026401 - LR: 7.8e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 86/200\n",
      "Epoch: [85][0/406], Loss: 0.00197\n",
      "Epoch: [85][100/406], Loss: 0.00194\n",
      "Epoch: [85][200/406], Loss: 0.00224\n",
      "Epoch: [85][300/406], Loss: 0.00192\n",
      "Epoch: [85][400/406], Loss: 0.00205\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 86 completed - Avg loss: 0.0026521 - LR: 7.8e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 87/200\n",
      "Epoch: [86][0/406], Loss: 0.00192\n",
      "Epoch: [86][100/406], Loss: 0.00289\n",
      "Epoch: [86][200/406], Loss: 0.00192\n",
      "Epoch: [86][300/406], Loss: 0.00214\n",
      "Epoch: [86][400/406], Loss: 0.00274\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 87 completed - Avg loss: 0.0026435 - LR: 7.8e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 88/200\n",
      "Epoch: [87][0/406], Loss: 0.00197\n",
      "Epoch: [87][100/406], Loss: 0.00240\n",
      "Epoch: [87][200/406], Loss: 0.00179\n",
      "Epoch: [87][300/406], Loss: 0.00294\n",
      "Epoch: [87][400/406], Loss: 0.00175\n",
      "ğŸ›‘ No improvement â€” early stop counter: 5/10\n",
      "ğŸ” Epoch 88 completed - Avg loss: 0.0026458 - LR: 7.8e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 89/200\n",
      "Epoch: [88][0/406], Loss: 0.00252\n",
      "Epoch: [88][100/406], Loss: 0.00452\n",
      "Epoch: [88][200/406], Loss: 0.00301\n",
      "Epoch: [88][300/406], Loss: 0.00176\n",
      "Epoch: [88][400/406], Loss: 0.00236\n",
      "ğŸ›‘ No improvement â€” early stop counter: 6/10\n",
      "ğŸ” Epoch 89 completed - Avg loss: 0.0026449 - LR: 3.9e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 90/200\n",
      "Epoch: [89][0/406], Loss: 0.00164\n",
      "Epoch: [89][100/406], Loss: 0.00215\n",
      "Epoch: [89][200/406], Loss: 0.00478\n",
      "Epoch: [89][300/406], Loss: 0.00437\n",
      "Epoch: [89][400/406], Loss: 0.00413\n",
      "ğŸ’¾ Saving improved model at epoch 90 with avg_loss=0.00258\n",
      "ğŸ” Epoch 90 completed - Avg loss: 0.0025845 - LR: 3.9e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 91/200\n",
      "Epoch: [90][0/406], Loss: 0.00164\n",
      "Epoch: [90][100/406], Loss: 0.00324\n",
      "Epoch: [90][200/406], Loss: 0.00287\n",
      "Epoch: [90][300/406], Loss: 0.00156\n",
      "Epoch: [90][400/406], Loss: 0.00492\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 91 completed - Avg loss: 0.0025828 - LR: 3.9e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 92/200\n",
      "Epoch: [91][0/406], Loss: 0.00456\n",
      "Epoch: [91][100/406], Loss: 0.00320\n",
      "Epoch: [91][200/406], Loss: 0.00426\n",
      "Epoch: [91][300/406], Loss: 0.00306\n",
      "Epoch: [91][400/406], Loss: 0.00264\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 92 completed - Avg loss: 0.0025811 - LR: 3.9e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 93/200\n",
      "Epoch: [92][0/406], Loss: 0.00206\n",
      "Epoch: [92][100/406], Loss: 0.00219\n",
      "Epoch: [92][200/406], Loss: 0.00217\n",
      "Epoch: [92][300/406], Loss: 0.00228\n",
      "Epoch: [92][400/406], Loss: 0.00310\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 93 completed - Avg loss: 0.0025887 - LR: 3.9e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 94/200\n",
      "Epoch: [93][0/406], Loss: 0.00292\n",
      "Epoch: [93][100/406], Loss: 0.00241\n",
      "Epoch: [93][200/406], Loss: 0.00239\n",
      "Epoch: [93][300/406], Loss: 0.00397\n",
      "Epoch: [93][400/406], Loss: 0.00292\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 94 completed - Avg loss: 0.0025870 - LR: 3.9e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 95/200\n",
      "Epoch: [94][0/406], Loss: 0.00207\n",
      "Epoch: [94][100/406], Loss: 0.00465\n",
      "Epoch: [94][200/406], Loss: 0.00494\n",
      "Epoch: [94][300/406], Loss: 0.00203\n",
      "Epoch: [94][400/406], Loss: 0.00237\n",
      "ğŸ›‘ No improvement â€” early stop counter: 5/10\n",
      "ğŸ” Epoch 95 completed - Avg loss: 0.0025865 - LR: 3.9e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 96/200\n",
      "Epoch: [95][0/406], Loss: 0.00219\n",
      "Epoch: [95][100/406], Loss: 0.00254\n",
      "Epoch: [95][200/406], Loss: 0.00269\n",
      "Epoch: [95][300/406], Loss: 0.00323\n",
      "Epoch: [95][400/406], Loss: 0.00276\n",
      "ğŸ›‘ No improvement â€” early stop counter: 6/10\n",
      "ğŸ” Epoch 96 completed - Avg loss: 0.0025874 - LR: 2.0e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 97/200\n",
      "Epoch: [96][0/406], Loss: 0.00500\n",
      "Epoch: [96][100/406], Loss: 0.00232\n",
      "Epoch: [96][200/406], Loss: 0.00312\n",
      "Epoch: [96][300/406], Loss: 0.00169\n",
      "Epoch: [96][400/406], Loss: 0.00187\n",
      "ğŸ’¾ Saving improved model at epoch 97 with avg_loss=0.00255\n",
      "ğŸ” Epoch 97 completed - Avg loss: 0.0025521 - LR: 2.0e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 98/200\n",
      "Epoch: [97][0/406], Loss: 0.00290\n",
      "Epoch: [97][100/406], Loss: 0.00172\n",
      "Epoch: [97][200/406], Loss: 0.00179\n",
      "Epoch: [97][300/406], Loss: 0.00216\n",
      "Epoch: [97][400/406], Loss: 0.00170\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 98 completed - Avg loss: 0.0025564 - LR: 2.0e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 99/200\n",
      "Epoch: [98][0/406], Loss: 0.00449\n",
      "Epoch: [98][100/406], Loss: 0.00185\n",
      "Epoch: [98][200/406], Loss: 0.00229\n",
      "Epoch: [98][300/406], Loss: 0.00411\n",
      "Epoch: [98][400/406], Loss: 0.00199\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 99 completed - Avg loss: 0.0025523 - LR: 2.0e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 100/200\n",
      "Epoch: [99][0/406], Loss: 0.00265\n",
      "Epoch: [99][100/406], Loss: 0.00235\n",
      "Epoch: [99][200/406], Loss: 0.00292\n",
      "Epoch: [99][300/406], Loss: 0.00239\n",
      "Epoch: [99][400/406], Loss: 0.00193\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 100 completed - Avg loss: 0.0025543 - LR: 2.0e-06\n",
      "\n",
      "ğŸ¯ Starting epoch 101/200\n",
      "Epoch: [100][0/406], Loss: 0.00220\n",
      "Epoch: [100][100/406], Loss: 0.00202\n",
      "Epoch: [100][200/406], Loss: 0.00271\n",
      "Epoch: [100][300/406], Loss: 0.00178\n",
      "Epoch: [100][400/406], Loss: 0.00379\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 101 completed - Avg loss: 0.0025542 - LR: 9.8e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 102/200\n",
      "Epoch: [101][0/406], Loss: 0.00226\n",
      "Epoch: [101][100/406], Loss: 0.00276\n",
      "Epoch: [101][200/406], Loss: 0.00291\n",
      "Epoch: [101][300/406], Loss: 0.00230\n",
      "Epoch: [101][400/406], Loss: 0.00412\n",
      "ğŸ’¾ Saving improved model at epoch 102 with avg_loss=0.00254\n",
      "ğŸ” Epoch 102 completed - Avg loss: 0.0025373 - LR: 9.8e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 103/200\n",
      "Epoch: [102][0/406], Loss: 0.00204\n",
      "Epoch: [102][100/406], Loss: 0.00190\n",
      "Epoch: [102][200/406], Loss: 0.00202\n",
      "Epoch: [102][300/406], Loss: 0.00518\n",
      "Epoch: [102][400/406], Loss: 0.00274\n",
      "ğŸ›‘ No improvement â€” early stop counter: 1/10\n",
      "ğŸ” Epoch 103 completed - Avg loss: 0.0025373 - LR: 9.8e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 104/200\n",
      "Epoch: [103][0/406], Loss: 0.00264\n",
      "Epoch: [103][100/406], Loss: 0.00495\n",
      "Epoch: [103][200/406], Loss: 0.00202\n",
      "Epoch: [103][300/406], Loss: 0.00226\n",
      "Epoch: [103][400/406], Loss: 0.00224\n",
      "ğŸ›‘ No improvement â€” early stop counter: 2/10\n",
      "ğŸ” Epoch 104 completed - Avg loss: 0.0025373 - LR: 9.8e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 105/200\n",
      "Epoch: [104][0/406], Loss: 0.00212\n",
      "Epoch: [104][100/406], Loss: 0.00344\n",
      "Epoch: [104][200/406], Loss: 0.00289\n",
      "Epoch: [104][300/406], Loss: 0.00161\n",
      "Epoch: [104][400/406], Loss: 0.00393\n",
      "ğŸ›‘ No improvement â€” early stop counter: 3/10\n",
      "ğŸ” Epoch 105 completed - Avg loss: 0.0025368 - LR: 9.8e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 106/200\n",
      "Epoch: [105][0/406], Loss: 0.00209\n",
      "Epoch: [105][100/406], Loss: 0.00200\n",
      "Epoch: [105][200/406], Loss: 0.00239\n",
      "Epoch: [105][300/406], Loss: 0.00309\n",
      "Epoch: [105][400/406], Loss: 0.00379\n",
      "ğŸ›‘ No improvement â€” early stop counter: 4/10\n",
      "ğŸ” Epoch 106 completed - Avg loss: 0.0025387 - LR: 9.8e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 107/200\n",
      "Epoch: [106][0/406], Loss: 0.00217\n",
      "Epoch: [106][100/406], Loss: 0.00262\n",
      "Epoch: [106][200/406], Loss: 0.00191\n",
      "Epoch: [106][300/406], Loss: 0.00192\n",
      "Epoch: [106][400/406], Loss: 0.00187\n",
      "ğŸ›‘ No improvement â€” early stop counter: 5/10\n",
      "ğŸ” Epoch 107 completed - Avg loss: 0.0025389 - LR: 9.8e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 108/200\n",
      "Epoch: [107][0/406], Loss: 0.00251\n",
      "Epoch: [107][100/406], Loss: 0.00223\n",
      "Epoch: [107][200/406], Loss: 0.00229\n",
      "Epoch: [107][300/406], Loss: 0.00202\n",
      "Epoch: [107][400/406], Loss: 0.00233\n",
      "ğŸ›‘ No improvement â€” early stop counter: 6/10\n",
      "ğŸ” Epoch 108 completed - Avg loss: 0.0025379 - LR: 9.8e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 109/200\n",
      "Epoch: [108][0/406], Loss: 0.00291\n",
      "Epoch: [108][100/406], Loss: 0.00171\n",
      "Epoch: [108][200/406], Loss: 0.00254\n",
      "Epoch: [108][300/406], Loss: 0.00268\n",
      "Epoch: [108][400/406], Loss: 0.00250\n",
      "ğŸ›‘ No improvement â€” early stop counter: 7/10\n",
      "ğŸ” Epoch 109 completed - Avg loss: 0.0025380 - LR: 4.9e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 110/200\n",
      "Epoch: [109][0/406], Loss: 0.00197\n",
      "Epoch: [109][100/406], Loss: 0.00248\n",
      "Epoch: [109][200/406], Loss: 0.00301\n",
      "Epoch: [109][300/406], Loss: 0.00698\n",
      "Epoch: [109][400/406], Loss: 0.00218\n",
      "ğŸ›‘ No improvement â€” early stop counter: 8/10\n",
      "ğŸ” Epoch 110 completed - Avg loss: 0.0025290 - LR: 4.9e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 111/200\n",
      "Epoch: [110][0/406], Loss: 0.00132\n",
      "Epoch: [110][100/406], Loss: 0.00204\n",
      "Epoch: [110][200/406], Loss: 0.00497\n",
      "Epoch: [110][300/406], Loss: 0.00268\n",
      "Epoch: [110][400/406], Loss: 0.00166\n",
      "ğŸ›‘ No improvement â€” early stop counter: 9/10\n",
      "ğŸ” Epoch 111 completed - Avg loss: 0.0025290 - LR: 4.9e-07\n",
      "\n",
      "ğŸ¯ Starting epoch 112/200\n",
      "Epoch: [111][0/406], Loss: 0.00214\n",
      "Epoch: [111][100/406], Loss: 0.00276\n",
      "Epoch: [111][200/406], Loss: 0.00305\n",
      "Epoch: [111][300/406], Loss: 0.00260\n",
      "Epoch: [111][400/406], Loss: 0.00269\n",
      "ğŸ›‘ No improvement â€” early stop counter: 10/10\n",
      "ğŸ” Epoch 112 completed - Avg loss: 0.0025288 - LR: 4.9e-07\n",
      "\n",
      "ğŸš¨ Early stopping triggered after 10 epochs without improvement.\n",
      "âœ… Training completed\n",
      "Freeing memory...\n"
     ]
    }
   ],
   "source": [
    "model = train_model(dataset_config, model, epochs=200, batch_size=64, lr=1e-3, load_weights=False, checkpoint_name=f'checkpoint_{DATASET_VAR}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "history_loss = np.load(f'models/{MODEL_NAME}/history_loss_{DATASET_VAR}.npy')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history_loss, linestyle='-', color='tomato', label=\"Loss\")\n",
    "# plt.title(title)\n",
    "plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(ylabel)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32607"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "os.getpid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
