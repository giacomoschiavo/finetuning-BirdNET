{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from birdlib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sudo modprobe nvidia_uvm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"dataset\"\n",
    "MODEL_NAME = 'VanillaCNN'\n",
    "DATASET_VAR = 'augm_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = f'../segments/{DATASET_NAME}'\n",
    "TRAIN_PATH = f\"{DATASET_PATH}/train\"\n",
    "TEST_PATH = f\"{DATASET_PATH}/test\"\n",
    "MODEL_PATH = f'./models/{MODEL_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./utils/{DATASET_NAME}/dataset_config_{DATASET_VAR}.json\") as f:\n",
    "    dataset_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = utils.get_dataloader(dataset_config, split=\"test\", batch_size=1, shuffle=False)\n",
    "valid_loader = utils.get_dataloader(dataset_config, split=\"valid\", batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = dataset_config[\"mappings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/home/giacomoschiavo/finetuning-BirdNET/configs/configs_1.json'\n",
    "with open(config_file) as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class = utils.load_model_class(MODEL_NAME)\n",
    "input_shape = (256, 256)\n",
    "model_class = utils.load_model_class(MODEL_NAME)\n",
    "model = model_class(len(mappings))\n",
    "model.to(device)\n",
    "saving_path = 'models/VanillaCNN/augm_final/checkpoint_augm_final.pth'\n",
    "checkpoint = torch.load(saving_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Thresholds Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_conf_scores(valid_loader, model, mappings):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    conf_scores = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, _, file_path in valid_loader:\n",
    "            mel_spec = mel_spec.to(device)\n",
    "\n",
    "            # Estraggo la specie corretta dal path\n",
    "            correct_species = file_path[0].split(\"/\")[-2]\n",
    "            outputs = model(mel_spec)\n",
    "            probs = torch.sigmoid(outputs)[0].cpu().numpy()\n",
    "\n",
    "            for i, prob in enumerate(probs):\n",
    "                species_name = list(mappings.keys())[i]\n",
    "                is_correct = species_name == correct_species\n",
    "                conf_scores[species_name].append((prob, is_correct))\n",
    "\n",
    "    return conf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_best_thresholds(conf_scores, num_thresholds=200, min_thresh=0.01, max_thresh=0.95):\n",
    "    thresholds = {}\n",
    "\n",
    "    for species, values in conf_scores.items():\n",
    "        probs, truths = zip(*values)\n",
    "        probs = np.array(probs)\n",
    "        truths = np.array(truths).astype(int)\n",
    "\n",
    "        best_thresh = 0.15\n",
    "        best_f1 = 0.0\n",
    "\n",
    "        for thresh in np.linspace(min_thresh, max_thresh, num_thresholds):\n",
    "            preds = (probs >= thresh).astype(int)\n",
    "            f1 = f1_score(truths, preds, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_thresh = thresh\n",
    "\n",
    "        thresholds[species] = best_thresh\n",
    "        print(f\"ðŸ“Š {species} -> {best_thresh:.3f}, F1-score: {best_f1:.3f}\")\n",
    "\n",
    "    return thresholds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Aeroplane -> 0.053, F1-score: 0.804\n",
      "ðŸ“Š Muscicapa striata_Spotted Flycatcher -> 0.865, F1-score: 0.743\n",
      "ðŸ“Š Periparus ater_Coal Tit -> 0.950, F1-score: 0.453\n",
      "ðŸ“Š Regulus regulus_Goldcrest -> 0.010, F1-score: 0.429\n",
      "ðŸ“Š Anthus trivialis_Tree Pipit -> 0.128, F1-score: 0.201\n",
      "ðŸ“Š Vegetation -> 0.010, F1-score: 0.595\n",
      "ðŸ“Š Troglodytes troglodytes_Eurasian Wren -> 0.851, F1-score: 0.372\n",
      "ðŸ“Š Erithacus rubecula_European Robin -> 0.936, F1-score: 0.440\n",
      "ðŸ“Š None -> 0.019, F1-score: 0.346\n",
      "ðŸ“Š Parus major_Great Tit -> 0.936, F1-score: 0.245\n",
      "ðŸ“Š Certhia familiaris_Eurasian Treecreeper -> 0.917, F1-score: 0.480\n",
      "ðŸ“Š Phylloscopus collybita_Common Chiffchaff -> 0.860, F1-score: 0.643\n",
      "ðŸ“Š Coccothraustes coccothraustes_Hawfinch -> 0.015, F1-score: 0.051\n",
      "ðŸ“Š Wind -> 0.090, F1-score: 0.667\n",
      "ðŸ“Š Turdus merula_Eurasian Blackbird -> 0.780, F1-score: 0.324\n",
      "ðŸ“Š Loxia curvirostra_Common Crossbill -> 0.015, F1-score: 0.294\n",
      "ðŸ“Š Regulus ignicapilla_Common Firecrest -> 0.879, F1-score: 0.851\n",
      "ðŸ“Š Sylvia atricapilla_Eurasian Blackcap -> 0.941, F1-score: 0.366\n",
      "ðŸ“Š Lophophanes cristatus_Crested Tit -> 0.150, F1-score: 0.000\n",
      "ðŸ“Š Fringilla coelebs_Common Chaffinch -> 0.893, F1-score: 0.434\n"
     ]
    }
   ],
   "source": [
    "conf_scores = calculate_conf_scores(valid_loader, model, dataset_config[\"mappings\"])\n",
    "best_thresholds = compute_best_thresholds(conf_scores)\n",
    "# best_thresholds = compute_distribution_based_thresholds(conf_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_samplewise_mAP(y_true, y_probs):\n",
    "    \"\"\"\n",
    "    Calcola la sample-wise mAP (media delle AP per ogni sample).\n",
    "    \"\"\"\n",
    "    ap_per_sample = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if np.sum(y_true[i]) == 0:\n",
    "            continue  # Evita sample senza label positive\n",
    "        ap = average_precision_score(y_true[i], y_probs[i])\n",
    "        ap_per_sample.append(ap)\n",
    "    return np.mean(ap_per_sample)\n",
    "\n",
    "def compute_classwise_mAP(y_true, y_probs):\n",
    "    \"\"\"\n",
    "    Calcola la class-wise mAP (media delle AP per ogni classe).\n",
    "    \"\"\"\n",
    "    ap_per_class = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        if np.sum(y_true[:, i]) == 0:\n",
    "            continue  # Evita classi mai presenti\n",
    "        ap = average_precision_score(y_true[:, i], y_probs[:, i])\n",
    "        ap_per_class.append(ap)\n",
    "    return np.mean(ap_per_class)\n",
    "\n",
    "def compute_f05(y_true, y_pred):\n",
    "    _, _, f05, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, beta=0.5, average='macro', zero_division=0\n",
    "    )\n",
    "    return f05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_mappings = {value: key for key, value in mappings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def test_model(model, dataset_config, test_loader, thresholds=0.2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\nðŸ§¬ Advanced testing on: {device}\")\n",
    "    test_pred_segments = {}\n",
    "\n",
    "    model.eval()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    class_names = list(dataset_config['mappings'].keys())\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    use_custom_threshold = isinstance(thresholds, dict)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels, file_path in test_loader:\n",
    "            basename = os.path.splitext(file_path[0].split(\"/\")[-1])[0]\n",
    "            date, time, segm1, segm2 = basename.split(\"_\")\n",
    "            audio_name = \"_\".join([date, time]) + \".WAV\"\n",
    "            segm = \"_\".join([segm1, segm2])\n",
    "            test_pred_segments.setdefault(audio_name, {})\n",
    "\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(mel_spec)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            if use_custom_threshold:\n",
    "                batch_preds = torch.zeros_like(probs)\n",
    "                for i, class_name in enumerate(class_names):\n",
    "                    thresh = thresholds.get(class_name, 0.5)\n",
    "                    batch_preds[:, i] = (probs[:, i] > thresh).float()\n",
    "            else:\n",
    "                batch_preds = (probs > thresholds).float()\n",
    "\n",
    "            correct_probs = probs * batch_preds\n",
    "            # already_added = False\n",
    "            if segm not in test_pred_segments:\n",
    "                test_pred_segments[audio_name][segm] = {}\n",
    "            # else:\n",
    "            #     already_added = True\n",
    "                \n",
    "            conf_scores = {\n",
    "                inverse_mappings[i]: correct_probs[0, i].item()\n",
    "                for i in range(correct_probs.size(1))\n",
    "                if correct_probs[0, i].item() != 0\n",
    "            }\n",
    "            test_pred_segments[audio_name][segm].update(conf_scores)\n",
    "\n",
    "            # if not already_added:\n",
    "            #     all_probs.append(probs.cpu())\n",
    "            #     all_preds.append(batch_preds.cpu())\n",
    "            #     all_labels.append(labels.cpu())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    # all_probs = torch.cat(all_probs).numpy()\n",
    "    # all_preds = torch.cat(all_preds).numpy()\n",
    "    # all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    # samplewise_map = compute_samplewise_mAP(all_labels, all_probs)  # chiamata mAP\n",
    "    # classwise_map = compute_classwise_mAP(all_labels, all_probs)    # chiamata cmAP\n",
    "    # f05_score = compute_f05(all_labels, all_preds)\n",
    "\n",
    "    # with open(f\"models/{MODEL_NAME}/{DATASET_VAR}/metrics_output.csv\", mode=\"w\", newline=\"\") as f:\n",
    "    #     writer = csv.writer(f)\n",
    "    #     writer.writerow([\"Metric\", \"Value\"])\n",
    "    #     writer.writerow([\"mAP (sample-wise)\", samplewise_map])\n",
    "    #     writer.writerow([\"cmAP (class-wise)\", classwise_map])\n",
    "    #     writer.writerow([\"F0.5 Score\", f05_score])\n",
    "\n",
    "    # return avg_loss, all_labels, all_preds, all_probs, test_pred_segments\n",
    "    return avg_loss, test_pred_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§¬ Advanced testing on: cuda\n"
     ]
    }
   ],
   "source": [
    "avg_loss, test_pred_segments = test_model(model, dataset_config, test_loader, thresholds=best_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "def get_true_segments(test_path):\n",
    "    test_species_list = os.listdir(test_path)\n",
    "    true_segments = defaultdict(dict)\n",
    "    for species in test_species_list:\n",
    "        for audio in os.listdir(os.path.join(test_path, species)):\n",
    "            audio = audio.split('.')[0]\n",
    "            date, time, segm1, segm2 = audio.split('_')\n",
    "            audio_name = '_'.join([date, time]) + '.WAV'\n",
    "            segm = '_'.join([segm1, segm2])\n",
    "            if segm not in true_segments[audio_name]:\n",
    "                true_segments[audio_name][segm] = []\n",
    "            true_segments[audio_name][segm].extend([species])\n",
    "    return true_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_segments = get_true_segments(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_proba_segments(test_pred_segments):\n",
    "    pred_segments = {}\n",
    "    pred_proba = {}\n",
    "\n",
    "    for audio, segments in test_pred_segments.items():\n",
    "        pred_segments.setdefault(audio, {})\n",
    "        pred_proba.setdefault(audio, {})\n",
    "        for segm, labels in segments.items():\n",
    "            pred_segments[audio].setdefault(segm, {})\n",
    "            pred_segments[audio][segm] = list(labels.keys())\n",
    "            pred_proba[audio].setdefault(segm, {})\n",
    "            pred_proba[audio][segm] = list(labels.values())\n",
    "    return pred_segments, pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract recognized labels\n",
    "pred_segments, pred_proba = get_pred_proba_segments(test_pred_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_pred_segments(true_segments, pred_segments, pred_proba):\n",
    "    for audio in true_segments.keys():\n",
    "        if audio in pred_segments:\n",
    "            for segm in true_segments[audio].keys():\n",
    "                if segm not in pred_segments[audio]:\n",
    "                    pred_segments[audio][segm] = {}\n",
    "                    pred_proba[audio][segm] = {}\n",
    "\n",
    "    return pred_segments, pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_segments, pred_proba = fill_pred_segments(true_segments, pred_segments, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "test_species_list = os.listdir(TEST_PATH)\n",
    "# test_species_list = [species for species in test_species_list if len(species.split('_')) > 1]\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([test_species_list])\n",
    "if DATASET_VAR == \"orig\":\n",
    "    class_names = [species for species in test_species_list if len(species.split(\"_\")) > 1]\n",
    "    mlb.fit([class_names])\n",
    "\n",
    "len(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_test_segments(mlb, true_segments, pred_segments, pred_proba):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    y_pred_proba = []\n",
    "\n",
    "    for audio in pred_segments:\n",
    "        for segment in sorted(pred_segments[audio].keys()):\n",
    "            true_labels = true_segments[audio].get(segment, [])\n",
    "            pred_labels = pred_segments[audio].get(segment, [])\n",
    "            proba_values = pred_proba[audio].get(segment, [])\n",
    "\n",
    "            y_true_vec = mlb.transform([true_labels])[0]  # 1D array\n",
    "            y_pred_vec = mlb.transform([pred_labels])[0]  # 1D array\n",
    "\n",
    "            proba_vec = np.zeros(len(mlb.classes_))\n",
    "            for label, score in zip(pred_labels, proba_values):\n",
    "                if label in mlb.classes_:\n",
    "                    idx = list(mlb.classes_).index(label)\n",
    "                    proba_vec[idx] = score\n",
    "\n",
    "            y_true.append(y_true_vec)\n",
    "            y_pred.append(y_pred_vec)\n",
    "            y_pred_proba.append(proba_vec)\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "    return y_true, y_pred, y_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred, y_pred_proba = binarize_test_segments(mlb, true_segments, pred_segments, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aeroplane</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthus trivialis_Tree Pipit</th>\n",
       "      <td>0.405882</td>\n",
       "      <td>0.413174</td>\n",
       "      <td>0.409496</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Certhia familiaris_Eurasian Treecreeper</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.563758</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coccothraustes coccothraustes_Hawfinch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Erithacus rubecula_European Robin</th>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.080935</td>\n",
       "      <td>0.118265</td>\n",
       "      <td>556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fringilla coelebs_Common Chaffinch</th>\n",
       "      <td>0.401274</td>\n",
       "      <td>0.540386</td>\n",
       "      <td>0.460554</td>\n",
       "      <td>1399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lophophanes cristatus_Crested Tit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loxia curvirostra_Common Crossbill</th>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muscicapa striata_Spotted Flycatcher</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.794983</td>\n",
       "      <td>0.663250</td>\n",
       "      <td>0.723166</td>\n",
       "      <td>4683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parus major_Great Tit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Periparus ater_Coal Tit</th>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phylloscopus collybita_Common Chiffchaff</th>\n",
       "      <td>0.671587</td>\n",
       "      <td>0.270030</td>\n",
       "      <td>0.385185</td>\n",
       "      <td>674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regulus ignicapilla_Common Firecrest</th>\n",
       "      <td>0.869333</td>\n",
       "      <td>0.566957</td>\n",
       "      <td>0.686316</td>\n",
       "      <td>575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regulus regulus_Goldcrest</th>\n",
       "      <td>0.315436</td>\n",
       "      <td>0.345588</td>\n",
       "      <td>0.329825</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sylvia atricapilla_Eurasian Blackcap</th>\n",
       "      <td>0.288580</td>\n",
       "      <td>0.364522</td>\n",
       "      <td>0.322136</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Troglodytes troglodytes_Eurasian Wren</th>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.116564</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turdus merula_Eurasian Blackbird</th>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vegetation</th>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind</th>\n",
       "      <td>0.075395</td>\n",
       "      <td>0.664948</td>\n",
       "      <td>0.135433</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.489324</td>\n",
       "      <td>0.490579</td>\n",
       "      <td>0.489951</td>\n",
       "      <td>10137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.290312</td>\n",
       "      <td>0.262931</td>\n",
       "      <td>0.241756</td>\n",
       "      <td>10137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.583168</td>\n",
       "      <td>0.490579</td>\n",
       "      <td>0.513472</td>\n",
       "      <td>10137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.439611</td>\n",
       "      <td>0.506564</td>\n",
       "      <td>0.453980</td>\n",
       "      <td>10137.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          precision    recall  f1-score  \\\n",
       "Aeroplane                                  0.100000  0.045455  0.062500   \n",
       "Anthus trivialis_Tree Pipit                0.405882  0.413174  0.409496   \n",
       "Certhia familiaris_Eurasian Treecreeper    0.600000  0.531646  0.563758   \n",
       "Coccothraustes coccothraustes_Hawfinch     0.000000  0.000000  0.000000   \n",
       "Erithacus rubecula_European Robin          0.219512  0.080935  0.118265   \n",
       "Fringilla coelebs_Common Chaffinch         0.401274  0.540386  0.460554   \n",
       "Lophophanes cristatus_Crested Tit          0.000000  0.000000  0.000000   \n",
       "Loxia curvirostra_Common Crossbill         0.152542  0.439024  0.226415   \n",
       "Muscicapa striata_Spotted Flycatcher       0.000000  0.000000  0.000000   \n",
       "None                                       0.794983  0.663250  0.723166   \n",
       "Parus major_Great Tit                      0.000000  0.000000  0.000000   \n",
       "Periparus ater_Coal Tit                    0.531250  0.146552  0.229730   \n",
       "Phylloscopus collybita_Common Chiffchaff   0.671587  0.270030  0.385185   \n",
       "Regulus ignicapilla_Common Firecrest       0.869333  0.566957  0.686316   \n",
       "Regulus regulus_Goldcrest                  0.315436  0.345588  0.329825   \n",
       "Sylvia atricapilla_Eurasian Blackcap       0.288580  0.364522  0.322136   \n",
       "Troglodytes troglodytes_Eurasian Wren      0.162393  0.090909  0.116564   \n",
       "Turdus merula_Eurasian Blackbird           0.209302  0.028571  0.050279   \n",
       "Vegetation                                 0.008772  0.066667  0.015504   \n",
       "Wind                                       0.075395  0.664948  0.135433   \n",
       "micro avg                                  0.489324  0.490579  0.489951   \n",
       "macro avg                                  0.290312  0.262931  0.241756   \n",
       "weighted avg                               0.583168  0.490579  0.513472   \n",
       "samples avg                                0.439611  0.506564  0.453980   \n",
       "\n",
       "                                          support  \n",
       "Aeroplane                                    22.0  \n",
       "Anthus trivialis_Tree Pipit                 167.0  \n",
       "Certhia familiaris_Eurasian Treecreeper      79.0  \n",
       "Coccothraustes coccothraustes_Hawfinch       87.0  \n",
       "Erithacus rubecula_European Robin           556.0  \n",
       "Fringilla coelebs_Common Chaffinch         1399.0  \n",
       "Lophophanes cristatus_Crested Tit            23.0  \n",
       "Loxia curvirostra_Common Crossbill           41.0  \n",
       "Muscicapa striata_Spotted Flycatcher        173.0  \n",
       "None                                       4683.0  \n",
       "Parus major_Great Tit                        14.0  \n",
       "Periparus ater_Coal Tit                     232.0  \n",
       "Phylloscopus collybita_Common Chiffchaff    674.0  \n",
       "Regulus ignicapilla_Common Firecrest        575.0  \n",
       "Regulus regulus_Goldcrest                   136.0  \n",
       "Sylvia atricapilla_Eurasian Blackcap        513.0  \n",
       "Troglodytes troglodytes_Eurasian Wren       209.0  \n",
       "Turdus merula_Eurasian Blackbird            315.0  \n",
       "Vegetation                                   45.0  \n",
       "Wind                                        194.0  \n",
       "micro avg                                 10137.0  \n",
       "macro avg                                 10137.0  \n",
       "weighted avg                              10137.0  \n",
       "samples avg                               10137.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "report = classification_report(y_true, y_pred, target_names=mlb.classes_, zero_division=0, output_dict=True)\n",
    "\n",
    "report_df = pd.DataFrame(report).T\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'precision': 0.4396110989731265,\n",
       "  'recall': 0.506563615177336,\n",
       "  'f1-score': 0.45398004515330276,\n",
       "  'support': 10137},\n",
       " {'precision': 0.48932401849847484,\n",
       "  'recall': 0.49057906678504487,\n",
       "  'f1-score': 0.48995073891625607,\n",
       "  'support': 10137},\n",
       " {'precision': 0.5831679401577161,\n",
       "  'recall': 0.49057906678504487,\n",
       "  'f1-score': 0.5134722025271634,\n",
       "  'support': 10137})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report[\"micro avg\"], report[\"weighted avg\"], report[\"samples avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{MODEL_PATH}/{DATASET_VAR}\", exist_ok=True)\n",
    "with open(f\"{MODEL_PATH}/{DATASET_VAR}/test_pred_segments.json\", \"w\") as f:\n",
    "    json.dump(test_pred_segments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'{MODEL_PATH}/{DATASET_VAR}/results.npz', y_true=y_true, y_pred=y_pred, y_pred_proba=y_pred_proba, class_names=mlb.classes_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
