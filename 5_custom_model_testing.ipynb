{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import torch.nn as nn\n",
    "from birdlib import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sudo modprobe nvidia_uvm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"dataset\"\n",
    "MODEL_NAME = 'VanillaCNN'\n",
    "DATASET_VAR = 'augm_final_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = f'../segments/{DATASET_NAME}'\n",
    "TRAIN_PATH = f\"{DATASET_PATH}/train\"\n",
    "TEST_PATH = f\"{DATASET_PATH}/test\"\n",
    "MODEL_PATH = f'./models/{MODEL_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./utils/{DATASET_NAME}/dataset_config_{DATASET_VAR}.json\") as f:\n",
    "    dataset_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = utils.get_dataloader(dataset_config, split=\"test\", batch_size=1, shuffle=False)\n",
    "valid_loader = utils.get_dataloader(dataset_config, split=\"valid\", batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = dataset_config[\"mappings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class = utils.load_model_class(MODEL_NAME)\n",
    "model = model_class(len(mappings))\n",
    "model.to(device)\n",
    "saving_path = f'models/{MODEL_NAME}/{DATASET_VAR}/checkpoint.pth'\n",
    "checkpoint = torch.load(saving_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Thresholds Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_conf_scores(valid_loader, model, mappings):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    conf_scores = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, _, file_path in valid_loader:\n",
    "            mel_spec = mel_spec.to(device)\n",
    "\n",
    "            # Estraggo la specie corretta dal path\n",
    "            correct_species = file_path[0].split(\"/\")[-2]\n",
    "            outputs = model(mel_spec)\n",
    "            probs = torch.sigmoid(outputs)[0].cpu().numpy()\n",
    "\n",
    "            for i, prob in enumerate(probs):\n",
    "                species_name = list(mappings.keys())[i]\n",
    "                is_correct = species_name == correct_species\n",
    "                conf_scores[species_name].append((prob, is_correct))\n",
    "\n",
    "    return conf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_best_thresholds(conf_scores, num_thresholds=200, min_thresh=0.01, max_thresh=0.95):\n",
    "    thresholds = {}\n",
    "\n",
    "    for species, values in conf_scores.items():\n",
    "        probs, truths = zip(*values)\n",
    "        probs = np.array(probs)\n",
    "        truths = np.array(truths).astype(int)\n",
    "\n",
    "        best_thresh = 0.15\n",
    "        best_f1 = 0.0\n",
    "\n",
    "        for thresh in np.linspace(min_thresh, max_thresh, num_thresholds):\n",
    "            preds = (probs >= thresh).astype(int)\n",
    "            f1 = f1_score(truths, preds, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_thresh = thresh\n",
    "\n",
    "        thresholds[species] = best_thresh\n",
    "        print(f\"ðŸ“Š {species} -> {best_thresh:.3f}, F1-score: {best_f1:.3f}\")\n",
    "\n",
    "    return thresholds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Aeroplane -> 0.237, F1-score: 0.800\n",
      "ðŸ“Š Muscicapa striata_Spotted Flycatcher -> 0.223, F1-score: 0.606\n",
      "ðŸ“Š Periparus ater_Coal Tit -> 0.827, F1-score: 0.495\n",
      "ðŸ“Š Regulus regulus_Goldcrest -> 0.515, F1-score: 0.576\n",
      "ðŸ“Š Anthus trivialis_Tree Pipit -> 0.874, F1-score: 0.606\n",
      "ðŸ“Š Vegetation -> 0.161, F1-score: 0.364\n",
      "ðŸ“Š Troglodytes troglodytes_Eurasian Wren -> 0.596, F1-score: 0.514\n",
      "ðŸ“Š Erithacus rubecula_European Robin -> 0.251, F1-score: 0.381\n",
      "ðŸ“Š None -> 0.293, F1-score: 0.714\n",
      "ðŸ“Š Parus major_Great Tit -> 0.728, F1-score: 0.200\n",
      "ðŸ“Š Certhia familiaris_Eurasian Treecreeper -> 0.912, F1-score: 0.416\n",
      "ðŸ“Š Phylloscopus collybita_Common Chiffchaff -> 0.397, F1-score: 0.524\n",
      "ðŸ“Š Coccothraustes coccothraustes_Hawfinch -> 0.265, F1-score: 0.667\n",
      "ðŸ“Š Wind -> 0.138, F1-score: 0.375\n",
      "ðŸ“Š Turdus merula_Eurasian Blackbird -> 0.520, F1-score: 0.439\n",
      "ðŸ“Š Loxia curvirostra_Common Crossbill -> 0.530, F1-score: 0.583\n",
      "ðŸ“Š Regulus ignicapilla_Common Firecrest -> 0.284, F1-score: 0.553\n",
      "ðŸ“Š Sylvia atricapilla_Eurasian Blackcap -> 0.728, F1-score: 0.519\n",
      "ðŸ“Š Lophophanes cristatus_Crested Tit -> 0.345, F1-score: 0.588\n",
      "ðŸ“Š Fringilla coelebs_Common Chaffinch -> 0.246, F1-score: 0.438\n"
     ]
    }
   ],
   "source": [
    "conf_scores = calculate_conf_scores(valid_loader, model, dataset_config[\"mappings\"])\n",
    "best_thresholds = compute_best_thresholds(conf_scores)\n",
    "# best_thresholds = compute_distribution_based_thresholds(conf_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_samplewise_mAP(y_true, y_probs):\n",
    "    \"\"\"\n",
    "    Calcola la sample-wise mAP (media delle AP per ogni sample).\n",
    "    \"\"\"\n",
    "    ap_per_sample = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if np.sum(y_true[i]) == 0:\n",
    "            continue  # Evita sample senza label positive\n",
    "        ap = average_precision_score(y_true[i], y_probs[i])\n",
    "        ap_per_sample.append(ap)\n",
    "    return np.mean(ap_per_sample)\n",
    "\n",
    "def compute_classwise_mAP(y_true, y_probs):\n",
    "    \"\"\"\n",
    "    Calcola la class-wise mAP (media delle AP per ogni classe).\n",
    "    \"\"\"\n",
    "    ap_per_class = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        if np.sum(y_true[:, i]) == 0:\n",
    "            continue  # Evita classi mai presenti\n",
    "        ap = average_precision_score(y_true[:, i], y_probs[:, i])\n",
    "        ap_per_class.append(ap)\n",
    "    return np.mean(ap_per_class)\n",
    "\n",
    "def compute_f05(y_true, y_pred):\n",
    "    _, _, f05, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, beta=0.5, average='macro', zero_division=0\n",
    "    )\n",
    "    return f05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_mappings = {value: key for key, value in mappings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def test_model(model, dataset_config, test_loader, batch_size=1, thresholds=0.2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\nðŸ§¬ Advanced testing on: {device}\")\n",
    "    test_pred_segments = {}\n",
    "\n",
    "    model.eval()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    class_names = list(dataset_config['mappings'].keys())\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    use_custom_threshold = isinstance(thresholds, dict)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels, file_path in test_loader:\n",
    "            basename = os.path.splitext(file_path[0].split(\"/\")[-1])[0]\n",
    "            date, time, segm1, segm2 = basename.split(\"_\")\n",
    "            audio_name = \"_\".join([date, time]) + \".WAV\"\n",
    "            segm = \"_\".join([segm1, segm2])\n",
    "            test_pred_segments.setdefault(audio_name, {})\n",
    "\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(mel_spec)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            if use_custom_threshold:\n",
    "                batch_preds = torch.zeros_like(probs)\n",
    "                for i, class_name in enumerate(class_names):\n",
    "                    thresh = thresholds.get(class_name, 0.5)\n",
    "                    batch_preds[:, i] = (probs[:, i] > thresh).float()\n",
    "            else:\n",
    "                batch_preds = (probs > thresholds).float()\n",
    "\n",
    "            correct_probs = probs * batch_preds\n",
    "            # already_added = False\n",
    "            if segm not in test_pred_segments:\n",
    "                test_pred_segments[audio_name][segm] = {}\n",
    "            # else:\n",
    "            #     already_added = True\n",
    "                \n",
    "            conf_scores = {\n",
    "                inverse_mappings[i]: correct_probs[0, i].item()\n",
    "                for i in range(correct_probs.size(1))\n",
    "                if correct_probs[0, i].item() != 0\n",
    "            }\n",
    "            test_pred_segments[audio_name][segm].update(conf_scores)\n",
    "\n",
    "            # if not already_added:\n",
    "            #     all_probs.append(probs.cpu())\n",
    "            #     all_preds.append(batch_preds.cpu())\n",
    "            #     all_labels.append(labels.cpu())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    # all_probs = torch.cat(all_probs).numpy()\n",
    "    # all_preds = torch.cat(all_preds).numpy()\n",
    "    # all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    # samplewise_map = compute_samplewise_mAP(all_labels, all_probs)  # chiamata mAP\n",
    "    # classwise_map = compute_classwise_mAP(all_labels, all_probs)    # chiamata cmAP\n",
    "    # f05_score = compute_f05(all_labels, all_preds)\n",
    "\n",
    "    # with open(f\"models/{MODEL_NAME}/{DATASET_VAR}/metrics_output.csv\", mode=\"w\", newline=\"\") as f:\n",
    "    #     writer = csv.writer(f)\n",
    "    #     writer.writerow([\"Metric\", \"Value\"])\n",
    "    #     writer.writerow([\"mAP (sample-wise)\", samplewise_map])\n",
    "    #     writer.writerow([\"cmAP (class-wise)\", classwise_map])\n",
    "    #     writer.writerow([\"F0.5 Score\", f05_score])\n",
    "\n",
    "    # return avg_loss, all_labels, all_preds, all_probs, test_pred_segments\n",
    "    return avg_loss, test_pred_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§¬ Advanced testing on: cuda\n"
     ]
    }
   ],
   "source": [
    "avg_loss, test_pred_segments = test_model(model, dataset_config, test_loader, thresholds=best_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "DATASET_NAME = 'dataset'\n",
    "TEST_PATH = f'/home/giacomoschiavo/segments/{DATASET_NAME}/test'\n",
    "test_species_list = os.listdir(TEST_PATH)\n",
    "true_segments = defaultdict(dict)\n",
    "for species in os.listdir(TEST_PATH):\n",
    "    for audio in os.listdir(os.path.join(TEST_PATH, species)):\n",
    "        audio = audio.split('.')[0]\n",
    "        date, time, segm1, segm2 = audio.split('_')\n",
    "        audio_name = '_'.join([date, time]) + '.WAV'\n",
    "        segm = '_'.join([segm1, segm2])\n",
    "        if segm not in true_segments[audio_name]:\n",
    "            true_segments[audio_name][segm] = []\n",
    "        true_segments[audio_name][segm].extend([species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract recognized labels\n",
    "pred_segments = {}\n",
    "pred_proba = {}\n",
    "\n",
    "for audio, segments in test_pred_segments.items():\n",
    "    pred_segments.setdefault(audio, {})\n",
    "    pred_proba.setdefault(audio, {})\n",
    "    for segm, labels in segments.items():\n",
    "        pred_segments[audio].setdefault(segm, {})\n",
    "        pred_segments[audio][segm] = list(labels.keys())\n",
    "        pred_proba[audio].setdefault(segm, {})\n",
    "        pred_proba[audio][segm] = list(labels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio in true_segments.keys():\n",
    "    if audio in pred_segments:\n",
    "        for segm in true_segments[audio].keys():\n",
    "            if segm not in pred_segments[audio]:\n",
    "                pred_segments[audio][segm] = {}\n",
    "    else:\n",
    "        print(\"ATTENZIONE!: \", audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "test_species_list = os.listdir(TEST_PATH)\n",
    "# test_species_list = [species for species in test_species_list if len(species.split('_')) > 1]\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([test_species_list])\n",
    "if DATASET_VAR == \"orig\":\n",
    "    class_names = [species for species in test_species_list if len(species.split(\"_\")) > 1]\n",
    "    mlb.fit([class_names])\n",
    "\n",
    "len(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "y_pred_proba = []\n",
    "\n",
    "for audio in pred_segments:\n",
    "    for segment in sorted(pred_segments[audio].keys()):\n",
    "        true_labels = true_segments[audio].get(segment, [])\n",
    "        pred_labels = pred_segments[audio].get(segment, [])\n",
    "        proba_values = pred_proba[audio].get(segment, [])\n",
    "\n",
    "        y_true_vec = mlb.transform([true_labels])[0]  # 1D array\n",
    "        y_pred_vec = mlb.transform([pred_labels])[0]  # 1D array\n",
    "\n",
    "        proba_vec = np.zeros(len(mlb.classes_))\n",
    "        for label, score in zip(pred_labels, proba_values):\n",
    "            if label in mlb.classes_:\n",
    "                idx = list(mlb.classes_).index(label)\n",
    "                proba_vec[idx] = score\n",
    "\n",
    "        y_true.append(y_true_vec)\n",
    "        y_pred.append(y_pred_vec)\n",
    "        y_pred_proba.append(proba_vec)\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_proba = np.array(y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aeroplane</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthus trivialis_Tree Pipit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Certhia familiaris_Eurasian Treecreeper</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coccothraustes coccothraustes_Hawfinch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Erithacus rubecula_European Robin</th>\n",
       "      <td>0.411392</td>\n",
       "      <td>0.116906</td>\n",
       "      <td>0.182073</td>\n",
       "      <td>556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fringilla coelebs_Common Chaffinch</th>\n",
       "      <td>0.322683</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.450232</td>\n",
       "      <td>1370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lophophanes cristatus_Crested Tit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loxia curvirostra_Common Crossbill</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muscicapa striata_Spotted Flycatcher</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>0.883360</td>\n",
       "      <td>0.473842</td>\n",
       "      <td>0.616817</td>\n",
       "      <td>4683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parus major_Great Tit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Periparus ater_Coal Tit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phylloscopus collybita_Common Chiffchaff</th>\n",
       "      <td>0.407809</td>\n",
       "      <td>0.278932</td>\n",
       "      <td>0.331278</td>\n",
       "      <td>674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regulus ignicapilla_Common Firecrest</th>\n",
       "      <td>0.133748</td>\n",
       "      <td>0.361345</td>\n",
       "      <td>0.195233</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regulus regulus_Goldcrest</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sylvia atricapilla_Eurasian Blackcap</th>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.365112</td>\n",
       "      <td>0.302013</td>\n",
       "      <td>493.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Troglodytes troglodytes_Eurasian Wren</th>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.117117</td>\n",
       "      <td>0.083601</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turdus merula_Eurasian Blackbird</th>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.139665</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vegetation</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind</th>\n",
       "      <td>0.069851</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>0.128471</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.386759</td>\n",
       "      <td>0.436727</td>\n",
       "      <td>0.410227</td>\n",
       "      <td>9056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.164637</td>\n",
       "      <td>0.179306</td>\n",
       "      <td>0.131225</td>\n",
       "      <td>9056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.601557</td>\n",
       "      <td>0.436727</td>\n",
       "      <td>0.453463</td>\n",
       "      <td>9056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.382528</td>\n",
       "      <td>0.442354</td>\n",
       "      <td>0.393862</td>\n",
       "      <td>9056.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          precision    recall  f1-score  \\\n",
       "Aeroplane                                  0.000000  0.000000  0.000000   \n",
       "Anthus trivialis_Tree Pipit                0.000000  0.000000  0.000000   \n",
       "Certhia familiaris_Eurasian Treecreeper    0.000000  0.000000  0.000000   \n",
       "Coccothraustes coccothraustes_Hawfinch     0.000000  0.000000  0.000000   \n",
       "Erithacus rubecula_European Robin          0.411392  0.116906  0.182073   \n",
       "Fringilla coelebs_Common Chaffinch         0.322683  0.744526  0.450232   \n",
       "Lophophanes cristatus_Crested Tit          0.000000  0.000000  0.000000   \n",
       "Loxia curvirostra_Common Crossbill         0.000000  0.000000  0.000000   \n",
       "Muscicapa striata_Spotted Flycatcher       0.000000  0.000000  0.000000   \n",
       "None                                       0.883360  0.473842  0.616817   \n",
       "Parus major_Great Tit                      0.000000  0.000000  0.000000   \n",
       "Periparus ater_Coal Tit                    0.000000  0.000000  0.000000   \n",
       "Phylloscopus collybita_Common Chiffchaff   0.407809  0.278932  0.331278   \n",
       "Regulus ignicapilla_Common Firecrest       0.133748  0.361345  0.195233   \n",
       "Regulus regulus_Goldcrest                  0.160000  0.250000  0.195122   \n",
       "Sylvia atricapilla_Eurasian Blackcap       0.257511  0.365112  0.302013   \n",
       "Troglodytes troglodytes_Eurasian Wren      0.065000  0.117117  0.083601   \n",
       "Turdus merula_Eurasian Blackbird           0.581395  0.079365  0.139665   \n",
       "Vegetation                                 0.000000  0.000000  0.000000   \n",
       "Wind                                       0.069851  0.798969  0.128471   \n",
       "micro avg                                  0.386759  0.436727  0.410227   \n",
       "macro avg                                  0.164637  0.179306  0.131225   \n",
       "weighted avg                               0.601557  0.436727  0.453463   \n",
       "samples avg                                0.382528  0.442354  0.393862   \n",
       "\n",
       "                                          support  \n",
       "Aeroplane                                    22.0  \n",
       "Anthus trivialis_Tree Pipit                  17.0  \n",
       "Certhia familiaris_Eurasian Treecreeper       3.0  \n",
       "Coccothraustes coccothraustes_Hawfinch       87.0  \n",
       "Erithacus rubecula_European Robin           556.0  \n",
       "Fringilla coelebs_Common Chaffinch         1370.0  \n",
       "Lophophanes cristatus_Crested Tit            16.0  \n",
       "Loxia curvirostra_Common Crossbill           11.0  \n",
       "Muscicapa striata_Spotted Flycatcher        173.0  \n",
       "None                                       4683.0  \n",
       "Parus major_Great Tit                         3.0  \n",
       "Periparus ater_Coal Tit                      29.0  \n",
       "Phylloscopus collybita_Common Chiffchaff    674.0  \n",
       "Regulus ignicapilla_Common Firecrest        238.0  \n",
       "Regulus regulus_Goldcrest                    16.0  \n",
       "Sylvia atricapilla_Eurasian Blackcap        493.0  \n",
       "Troglodytes troglodytes_Eurasian Wren       111.0  \n",
       "Turdus merula_Eurasian Blackbird            315.0  \n",
       "Vegetation                                   45.0  \n",
       "Wind                                        194.0  \n",
       "micro avg                                  9056.0  \n",
       "macro avg                                  9056.0  \n",
       "weighted avg                               9056.0  \n",
       "samples avg                                9056.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "report = classification_report(y_true, y_pred, target_names=mlb.classes_, zero_division=0, output_dict=True)\n",
    "\n",
    "report_df = pd.DataFrame(report).T\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{MODEL_PATH}/{DATASET_VAR}\", exist_ok=True)\n",
    "with open(f\"{MODEL_PATH}/{DATASET_VAR}/test_pred_segments.json\", \"w\") as f:\n",
    "    json.dump(test_pred_segments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f'{MODEL_PATH}/{DATASET_VAR}/results.npz', y_true=y_true, y_pred=y_pred, y_pred_proba=y_pred_proba, class_names=mlb.classes_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
