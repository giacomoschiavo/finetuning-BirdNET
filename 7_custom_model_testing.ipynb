{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sudo modprobe nvidia_uvm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"DATASET_CNN\"\n",
    "MODEL_NAME = 'DeeperCNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = f'../segments/{DATASET_NAME}'\n",
    "TRAIN_PATH = f\"{DATASET_PATH}/train\"\n",
    "TEST_PATH = f\"{DATASET_PATH}/test\"\n",
    "MODEL_PATH = f'./models/{MODEL_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = utils.get_mappings(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class = utils.load_model_class(MODEL_NAME)\n",
    "model = model_class(len(mappings))\n",
    "model.to(device)\n",
    "saving_path = f'models/{MODEL_NAME}/checkpoint.pth'\n",
    "checkpoint = torch.load(saving_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"utils/{DATASET_NAME}/dataset_config.json\") as f:\n",
    "    dataset_config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Thresholds Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_conf_scores(valid_loader, model, mappings):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    conf_scores = defaultdict(list)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, _, file_path in valid_loader:\n",
    "            mel_spec = mel_spec.to(device)\n",
    "\n",
    "            # Estraggo la specie corretta dal path\n",
    "            correct_species = file_path[0].split(\"/\")[-2]\n",
    "            outputs = model(mel_spec)\n",
    "            probs = torch.sigmoid(outputs)[0].cpu().numpy()\n",
    "\n",
    "            for i, prob in enumerate(probs):\n",
    "                species_name = list(mappings.keys())[i]\n",
    "                is_correct = (species_name == correct_species)\n",
    "                conf_scores[species_name].append((prob, is_correct))\n",
    "\n",
    "    return conf_scores\n",
    "\n",
    "# Step 2: Trova la soglia migliore per ciascuna specie\n",
    "def compute_best_thresholds(conf_scores, num_thresholds=100):\n",
    "    thresholds = {}\n",
    "\n",
    "    for species, values in conf_scores.items():\n",
    "        probs, truths = zip(*values)\n",
    "        probs = np.array(probs)\n",
    "        truths = np.array(truths).astype(int)\n",
    "\n",
    "        best_thresh = 0.5\n",
    "        best_f1 = 0.0\n",
    "\n",
    "        for thresh in np.linspace(0, 1, num_thresholds):\n",
    "            preds = (probs >= thresh).astype(int)\n",
    "            f1 = f1_score(truths, preds, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_thresh = thresh\n",
    "\n",
    "        thresholds[species] = best_thresh\n",
    "        print(f\"ðŸ“Š Specie: {species}, Best Threshold: {best_thresh:.3f}, F1-score: {best_f1:.3f}\")\n",
    "\n",
    "    return thresholds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Specie: Regulus ignicapilla_Common Firecrest, Best Threshold: 0.030, F1-score: 0.795\n",
      "ðŸ“Š Specie: Sylvia atricapilla_Eurasian Blackcap, Best Threshold: 1.000, F1-score: 0.792\n",
      "ðŸ“Š Specie: Fringilla coelebs_Common Chaffinch, Best Threshold: 0.848, F1-score: 0.670\n",
      "ðŸ“Š Specie: Troglodytes troglodytes_Eurasian Wren, Best Threshold: 0.384, F1-score: 0.964\n",
      "ðŸ“Š Specie: Muscicapa striata_Spotted Flycatcher, Best Threshold: 0.010, F1-score: 0.965\n",
      "ðŸ“Š Specie: Glaucidium passerinum_Eurasian Pygmy-Owl, Best Threshold: 0.010, F1-score: 1.000\n",
      "ðŸ“Š Specie: Pyrrhula pyrrhula_Eurasian Bullfinch, Best Threshold: 0.010, F1-score: 0.889\n",
      "ðŸ“Š Specie: Periparus ater_Coal Tit, Best Threshold: 0.263, F1-score: 0.977\n",
      "ðŸ“Š Specie: Lophophanes cristatus_Crested Tit, Best Threshold: 0.040, F1-score: 0.761\n",
      "ðŸ“Š Specie: Regulus regulus_Goldcrest, Best Threshold: 0.051, F1-score: 0.969\n",
      "ðŸ“Š Specie: Turdus merula_Eurasian Blackbird, Best Threshold: 0.141, F1-score: 0.960\n",
      "ðŸ“Š Specie: Certhia familiaris_Eurasian Treecreeper, Best Threshold: 0.010, F1-score: 0.914\n",
      "ðŸ“Š Specie: Erithacus rubecula_European Robin, Best Threshold: 0.980, F1-score: 0.961\n",
      "ðŸ“Š Specie: Turdus philomelos_Song Thrush, Best Threshold: 0.768, F1-score: 0.548\n",
      "ðŸ“Š Specie: Loxia curvirostra_Common Crossbill, Best Threshold: 0.970, F1-score: 1.000\n",
      "ðŸ“Š Specie: Dendrocopos major_Great Spotted Woodpecker, Best Threshold: 0.980, F1-score: 0.915\n",
      "ðŸ“Š Specie: Dryocopus martius_Black Woodpecker, Best Threshold: 0.040, F1-score: 0.968\n"
     ]
    }
   ],
   "source": [
    "valid_loader = utils.get_dataloader(dataset_config, split=\"valid\", batch_size=1)\n",
    "conf_scores = calculate_conf_scores(valid_loader, model, dataset_config[\"mappings\"])\n",
    "best_thresholds = compute_best_thresholds(conf_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_samplewise_mAP(y_true, y_probs):\n",
    "    \"\"\"\n",
    "    Calcola la sample-wise mAP (media delle AP per ogni sample).\n",
    "    \"\"\"\n",
    "    ap_per_sample = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if np.sum(y_true[i]) == 0:\n",
    "            continue  # Evita sample senza label positive\n",
    "        ap = average_precision_score(y_true[i], y_probs[i])\n",
    "        ap_per_sample.append(ap)\n",
    "    return np.mean(ap_per_sample)\n",
    "\n",
    "def compute_classwise_mAP(y_true, y_probs):\n",
    "    \"\"\"\n",
    "    Calcola la class-wise mAP (media delle AP per ogni classe).\n",
    "    \"\"\"\n",
    "    ap_per_class = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        if np.sum(y_true[:, i]) == 0:\n",
    "            continue  # Evita classi mai presenti\n",
    "        ap = average_precision_score(y_true[:, i], y_probs[:, i])\n",
    "        ap_per_class.append(ap)\n",
    "    return np.mean(ap_per_class)\n",
    "\n",
    "def compute_f05(y_true, y_pred):\n",
    "    _, _, f05, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, beta=0.5, average='macro', zero_division=0\n",
    "    )\n",
    "    return f05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import csv\n",
    "\n",
    "\n",
    "def test_model(model, dataset_config, batch_size=100, thresholds=0.5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\nðŸ§¬ Advanced testing on: {device}\")\n",
    "\n",
    "    test_loader = utils.get_dataloader(dataset_config, split=\"test\", batch_size=batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    class_names = list(dataset_config['mappings'].keys())\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    use_custom_threshold = isinstance(thresholds, dict)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel_spec, labels, _ in test_loader:\n",
    "            mel_spec = mel_spec.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(mel_spec)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            if use_custom_threshold:\n",
    "                batch_preds = torch.zeros_like(probs)\n",
    "                for i, class_name in enumerate(class_names):\n",
    "                    thresh = thresholds.get(class_name, 0.5)\n",
    "                    batch_preds[:, i] = (probs[:, i] > thresh).float()\n",
    "            else:\n",
    "                batch_preds = (probs > thresholds).float()\n",
    "\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_preds.append(batch_preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "    samplewise_map = compute_samplewise_mAP(all_labels, all_probs)  # chiamata mAP\n",
    "    classwise_map = compute_classwise_mAP(all_labels, all_probs)    # chiamata cmAP\n",
    "    f05_score = compute_f05(all_labels, all_preds)\n",
    "\n",
    "    with open(f\"models/{MODEL_NAME}/metrics_output.csv\", mode=\"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Metric\", \"Value\"])\n",
    "        writer.writerow([\"mAP (sample-wise)\", samplewise_map])\n",
    "        writer.writerow([\"cmAP (class-wise)\", classwise_map])\n",
    "        writer.writerow([\"F0.5 Score\", f05_score])\n",
    "\n",
    "    # ðŸ‘‡ Report\n",
    "    clf_report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True, zero_division=0)\n",
    "    return avg_loss, clf_report, samplewise_map, classwise_map, f05_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§¬ Advanced testing on: cuda\n"
     ]
    }
   ],
   "source": [
    "avg_loss, clf_report, samplewise_map, classwise_map, f05_score = test_model(model, dataset_config, thresholds=best_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP Score:  0.46221953535410715\n",
      "mcAP Score:  0.23051246445948737\n",
      "F0.5 Score:  0.17216839460921807\n"
     ]
    }
   ],
   "source": [
    "print(\"mAP Score: \", samplewise_map)\n",
    "print(\"mcAP Score: \", classwise_map)\n",
    "print(\"F0.5 Score: \", f05_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Regulus ignicapilla_Common Firecrest</th>\n",
       "      <td>0.436885</td>\n",
       "      <td>0.647631</td>\n",
       "      <td>0.521782</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sylvia atricapilla_Eurasian Blackcap</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fringilla coelebs_Common Chaffinch</th>\n",
       "      <td>0.628083</td>\n",
       "      <td>0.122502</td>\n",
       "      <td>0.205017</td>\n",
       "      <td>2702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Troglodytes troglodytes_Eurasian Wren</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muscicapa striata_Spotted Flycatcher</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glaucidium passerinum_Eurasian Pygmy-Owl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pyrrhula pyrrhula_Eurasian Bullfinch</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Periparus ater_Coal Tit</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lophophanes cristatus_Crested Tit</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regulus regulus_Goldcrest</th>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turdus merula_Eurasian Blackbird</th>\n",
       "      <td>0.031621</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.059627</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Certhia familiaris_Eurasian Treecreeper</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Erithacus rubecula_European Robin</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turdus philomelos_Song Thrush</th>\n",
       "      <td>0.434156</td>\n",
       "      <td>0.470982</td>\n",
       "      <td>0.451820</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loxia curvirostra_Common Crossbill</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dendrocopos major_Great Spotted Woodpecker</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dryocopus martius_Black Woodpecker</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.360787</td>\n",
       "      <td>0.179319</td>\n",
       "      <td>0.239567</td>\n",
       "      <td>6547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.294033</td>\n",
       "      <td>0.152278</td>\n",
       "      <td>0.137499</td>\n",
       "      <td>6547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.398515</td>\n",
       "      <td>0.179319</td>\n",
       "      <td>0.195364</td>\n",
       "      <td>6547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.190324</td>\n",
       "      <td>0.138644</td>\n",
       "      <td>0.150354</td>\n",
       "      <td>6547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            precision    recall  f1-score  \\\n",
       "Regulus ignicapilla_Common Firecrest         0.436885  0.647631  0.521782   \n",
       "Sylvia atricapilla_Eurasian Blackcap         0.000000  0.000000  0.000000   \n",
       "Fringilla coelebs_Common Chaffinch           0.628083  0.122502  0.205017   \n",
       "Troglodytes troglodytes_Eurasian Wren        0.600000  0.020134  0.038961   \n",
       "Muscicapa striata_Spotted Flycatcher         1.000000  0.094340  0.172414   \n",
       "Glaucidium passerinum_Eurasian Pygmy-Owl     0.000000  0.000000  0.000000   \n",
       "Pyrrhula pyrrhula_Eurasian Bullfinch         0.400000  0.129032  0.195122   \n",
       "Periparus ater_Coal Tit                      0.250000  0.013245  0.025157   \n",
       "Lophophanes cristatus_Crested Tit            0.000000  0.000000  0.000000   \n",
       "Regulus regulus_Goldcrest                    0.217822  0.309859  0.255814   \n",
       "Turdus merula_Eurasian Blackbird             0.031621  0.521739  0.059627   \n",
       "Certhia familiaris_Eurasian Treecreeper      0.000000  0.000000  0.000000   \n",
       "Erithacus rubecula_European Robin            0.000000  0.000000  0.000000   \n",
       "Turdus philomelos_Song Thrush                0.434156  0.470982  0.451820   \n",
       "Loxia curvirostra_Common Crossbill           0.000000  0.000000  0.000000   \n",
       "Dendrocopos major_Great Spotted Woodpecker   1.000000  0.259259  0.411765   \n",
       "Dryocopus martius_Black Woodpecker           0.000000  0.000000  0.000000   \n",
       "micro avg                                    0.360787  0.179319  0.239567   \n",
       "macro avg                                    0.294033  0.152278  0.137499   \n",
       "weighted avg                                 0.398515  0.179319  0.195364   \n",
       "samples avg                                  0.190324  0.138644  0.150354   \n",
       "\n",
       "                                            support  \n",
       "Regulus ignicapilla_Common Firecrest            823  \n",
       "Sylvia atricapilla_Eurasian Blackcap           1445  \n",
       "Fringilla coelebs_Common Chaffinch             2702  \n",
       "Troglodytes troglodytes_Eurasian Wren           149  \n",
       "Muscicapa striata_Spotted Flycatcher            159  \n",
       "Glaucidium passerinum_Eurasian Pygmy-Owl         27  \n",
       "Pyrrhula pyrrhula_Eurasian Bullfinch             31  \n",
       "Periparus ater_Coal Tit                         151  \n",
       "Lophophanes cristatus_Crested Tit                43  \n",
       "Regulus regulus_Goldcrest                       142  \n",
       "Turdus merula_Eurasian Blackbird                 46  \n",
       "Certhia familiaris_Eurasian Treecreeper          76  \n",
       "Erithacus rubecula_European Robin               194  \n",
       "Turdus philomelos_Song Thrush                   448  \n",
       "Loxia curvirostra_Common Crossbill               60  \n",
       "Dendrocopos major_Great Spotted Woodpecker       27  \n",
       "Dryocopus martius_Black Woodpecker               24  \n",
       "micro avg                                      6547  \n",
       "macro avg                                      6547  \n",
       "weighted avg                                   6547  \n",
       "samples avg                                    6547  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "clf_report_df = pd.read_json(StringIO(json.dumps(clf_report)), orient='index')\n",
    "clf_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MODEL_PATH}/classification_report.json', 'w') as f:\n",
    "    json.dump(clf_report, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
