{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['origaugm_wabadaugm', 'original', 'orig_augm', 'orig_wabad', 'orig_wabadaugm']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_folder_path = 'classifiers/official'\n",
    "model_names = os.listdir(models_folder_path)\n",
    "model_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Variation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all classification report\n",
    "classification_reports = {}\n",
    "for model_name in model_names:\n",
    "    with open(f'{models_folder_path}/{model_name}/classification_report.json') as f:\n",
    "        classification_report = json.load(f)\n",
    "        classification_reports[model_name] = classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Certhia familiaris_Eurasian Treecreeper': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 23},\n",
       " 'Dendrocopos major_Great Spotted Woodpecker': {'precision': 0.8571428571428571,\n",
       "  'recall': 0.4,\n",
       "  'f1-score': 0.5454545454545455,\n",
       "  'support': 15},\n",
       " 'Dryocopus martius_Black Woodpecker': {'precision': 1.0,\n",
       "  'recall': 0.09090909090909091,\n",
       "  'f1-score': 0.16666666666666669,\n",
       "  'support': 11},\n",
       " 'Erithacus rubecula_European Robin': {'precision': 0.7272727272727273,\n",
       "  'recall': 0.3076923076923077,\n",
       "  'f1-score': 0.43243243243243246,\n",
       "  'support': 26},\n",
       " 'Fringilla coelebs_Common Chaffinch': {'precision': 0.36538461538461536,\n",
       "  'recall': 0.7209821428571429,\n",
       "  'f1-score': 0.484984984984985,\n",
       "  'support': 448},\n",
       " 'Lophophanes cristatus_Crested Tit': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 19},\n",
       " 'Loxia curvirostra_Common Crossbill': {'precision': 0.3695652173913043,\n",
       "  'recall': 0.6296296296296297,\n",
       "  'f1-score': 0.4657534246575342,\n",
       "  'support': 27},\n",
       " 'Muscicapa striata_Spotted Flycatcher': {'precision': 1.0,\n",
       "  'recall': 0.7837837837837838,\n",
       "  'f1-score': 0.8787878787878788,\n",
       "  'support': 74},\n",
       " 'Pecking_': {'precision': 0.5833333333333334,\n",
       "  'recall': 0.5384615384615384,\n",
       "  'f1-score': 0.5599999999999999,\n",
       "  'support': 13},\n",
       " 'Periparus ater_Coal Tit': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.21052631578947367,\n",
       "  'f1-score': 0.32,\n",
       "  'support': 57},\n",
       " 'Phylloscopus collybita_Common Chiffchaff': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1030},\n",
       " 'Phylloscopus trochilus_Willow Warbler': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 5},\n",
       " 'Poecile palustris_Marsh Tit': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1},\n",
       " 'Prunella modularis_Dunnock': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 1},\n",
       " 'Pyrrhula pyrrhula_Eurasian Bullfinch': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 9},\n",
       " 'Rain_': {'precision': 0.9158878504672897,\n",
       "  'recall': 0.9245283018867925,\n",
       "  'f1-score': 0.9201877934272301,\n",
       "  'support': 106},\n",
       " 'Regulus ignicapilla_Common Firecrest': {'precision': 0.35507246376811596,\n",
       "  'recall': 0.5632183908045977,\n",
       "  'f1-score': 0.4355555555555556,\n",
       "  'support': 174},\n",
       " 'Regulus regulus_Goldcrest': {'precision': 0.5,\n",
       "  'recall': 0.171875,\n",
       "  'f1-score': 0.2558139534883721,\n",
       "  'support': 64},\n",
       " 'Sylvia atricapilla_Eurasian Blackcap': {'precision': 0.6986301369863014,\n",
       "  'recall': 0.5950991831971996,\n",
       "  'f1-score': 0.6427221172022685,\n",
       "  'support': 857},\n",
       " 'Troglodytes troglodytes_Eurasian Wren': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.21052631578947367,\n",
       "  'f1-score': 0.32,\n",
       "  'support': 285},\n",
       " 'Turdus merula_Eurasian Blackbird': {'precision': 0.4444444444444444,\n",
       "  'recall': 0.48484848484848486,\n",
       "  'f1-score': 0.463768115942029,\n",
       "  'support': 33},\n",
       " 'Turdus philomelos_Song Thrush': {'precision': 0.49572649572649574,\n",
       "  'recall': 0.40559440559440557,\n",
       "  'f1-score': 0.4461538461538461,\n",
       "  'support': 143},\n",
       " 'Turdus viscivorus_Mistle Thrush': {'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1-score': 0.0,\n",
       "  'support': 47},\n",
       " 'Vegetation_': {'precision': 1.0,\n",
       "  'recall': 0.045454545454545456,\n",
       "  'f1-score': 0.08695652173913045,\n",
       "  'support': 22},\n",
       " 'Wind_': {'precision': 0.2676056338028169,\n",
       "  'recall': 0.3584905660377358,\n",
       "  'f1-score': 0.30645161290322576,\n",
       "  'support': 53},\n",
       " 'micro avg': {'precision': 0.523924406915963,\n",
       "  'recall': 0.3677674287327124,\n",
       "  'f1-score': 0.4321724709784411,\n",
       "  'support': 3543},\n",
       " 'macro avg': {'precision': 0.43653596436214537,\n",
       "  'recall': 0.29766480010944807,\n",
       "  'f1-score': 0.30926757797582805,\n",
       "  'support': 3543},\n",
       " 'weighted avg': {'precision': 0.4056877047843607,\n",
       "  'recall': 0.3677674287327124,\n",
       "  'f1-score': 0.35863058440629303,\n",
       "  'support': 3543},\n",
       " 'samples avg': {'precision': 0.5252867080278247,\n",
       "  'recall': 0.3238766685467193,\n",
       "  'f1-score': 0.3826565143824027,\n",
       "  'support': 3543}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_reports[\"original\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variazione media per origaugm_wabadaugm:\n",
      "  precision: 0.1631\n",
      "  recall: 0.0707\n",
      "  f1-score: 0.0880\n",
      "Variazione media per orig_augm:\n",
      "  precision: 0.0092\n",
      "  recall: 0.0278\n",
      "  f1-score: 0.0251\n",
      "Variazione media per orig_wabad:\n",
      "  precision: 0.0777\n",
      "  recall: 0.0529\n",
      "  f1-score: 0.0515\n",
      "Variazione media per orig_wabadaugm:\n",
      "  precision: 0.1302\n",
      "  recall: 0.0583\n",
      "  f1-score: 0.0613\n"
     ]
    }
   ],
   "source": [
    "models_to_compare = model_names[:]\n",
    "models_to_compare.remove(\"original\")  # Rimuoviamo il modello di riferimento\n",
    "    \n",
    "# Dizionario per memorizzare i risultati\n",
    "variations = {model: {\"precision\": [], \"recall\": [], \"f1-score\": []} for model in models_to_compare}\n",
    "\n",
    "# Iterare sulle specie presenti nel modello originale\n",
    "for species in classification_reports[\"original\"].keys():\n",
    "    for model in models_to_compare:\n",
    "        if species in classification_reports[model]:  # Controllo per evitare errori\n",
    "            for metric in [\"precision\", \"recall\", \"f1-score\"]:\n",
    "                orig_value = classification_reports[\"original\"][species][metric]\n",
    "                model_value = classification_reports[model][species][metric]\n",
    "                variation = model_value - orig_value\n",
    "                variations[model][metric].append(variation)\n",
    "\n",
    "# Calcolare la variazione media per ogni metrica e modello\n",
    "mean_variations = {}\n",
    "for model, metrics in variations.items():\n",
    "    mean_variations[model] = {metric: sum(values) / len(values) if values else 0 for metric, values in metrics.items()}\n",
    "\n",
    "# Stampare i risultati\n",
    "for model, metrics in mean_variations.items():\n",
    "    print(f\"Variazione media per {model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Heatmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
